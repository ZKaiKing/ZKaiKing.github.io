<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Lambda表达式与Stream-API]]></title>
    <url>%2F2019%2F11%2F18%2FLambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%B8%8EStream-API%2F</url>
    <content type="text"><![CDATA[Java8 新特性 速度更快 更换了数据结构，内存结构（JVM） *代码更少了（Lambda表达式） * *强大的Stream API * 便于并行 fork join (串行切换并行) 最大化减少空指针异常 Optional Lambda表达式 在说 Lambda 之前，首先要说的是函数式接口。这个可以说是为了 Lambda 表达式而存在的一个东西。那么什么是函数式接口？ 函数式接口定义： 接口中只有一个抽象接口。 像 java.util.function 下的所有接口都是函数式接口。Java1.8提供@FunctionalInterface检测一个接口是否是一个函数式接口。 “-&gt;” 是 lambda 表达式的符号 左侧表示函数式接口中抽象方法的参数列表，右侧表示你对这个方法的实现 四大函数式接口我们一般对函数式接口的使用的时候，都会对其进行封装。 消费性接口​ Consumer 只有一个抽象方法名为 accept，参数列表只有一个泛型t，无返回值。参数的数据类型有类决定 1234567891011121314/** * @ClassName ConsumerTest * @Description 消费型接口， 消费字符串字段 打印输出 **/public class ConsumerTest &#123; public static void main(String[] args) &#123; test("hello",x-&gt; System.out.println(x)); &#125; public static &lt;T&gt; void test(T t, Consumer&lt;T&gt; consumer) &#123; consumer.accept(t); &#125;&#125; 输出：hello 如果需要多个参数列表的话，也可以在 java.util.function 包下找到相应的函数式接口 比如 ObjLongConsumer。其他的可以自行查看 供给型接口Supplier 只有一个抽象方法名为 get，参数列表为空，有返回值，返回值得数据类型为T。 123456789101112131415/** * @ClassName SupplerTest * @Description 供给型接口 字符串拼接 **/public class SupplerTest &#123; public static void main(String[] args) &#123; String hello = test("hello ", () -&gt; "word!"); System.out.println(hello); &#125; public static String test(String str,Supplier&lt;String&gt; supplier)&#123; return str + supplier.get(); &#125;&#125; 输出为：hello word! 如果需要返回得数据为基本数据类型，可以在 java.util.function 包下找到相应的函数式接口 比如：getAsLong 其他的可以自行查看 函数型接口​ Function&lt;T, R&gt; 只有一个抽象方法名为 apply，参数列表只有一个参数为T，有返回值，返回值的数据类型为R。（借鉴scala学习） 1234567891011121314151617/** * @ClassName FunctionTest * @Description 函数式接口 将字符串转换成大写的 **/public class FunctionTest &#123; public static void main(String[] args) &#123; String test = test("hello", x -&gt; x.toUpperCase()); System.out.println(test); &#125; public static String test(String str , Function&lt;String,String&gt; function)&#123; return function.apply(str); &#125;&#125; 输出为：HELLO 如果需要多个入参，然后又返回值的话，可以在 java.util.function 包下找到相应的函数式接口 比如 BiFunction。其他的可以自行查看 断言型接口​ 断言型又名判断型。 Predicate 只有一个抽象方法名为 test，参数列表只有一个参数为 T，有返回值，返回值类型为 boolean。 12345678910111213141516/** * @ClassName PredicateTest * @Description 断言型接口，判断字符串大小是否大于6 * @Author ouyangkang * @Date 2019-02-18 16:16 **/public class PredicateTest &#123; public static void main(String[] args) &#123; boolean hello = test("hello", x -&gt; x.length() &gt; 6); System.out.println(hello); &#125; public static boolean test(String str, Predicate&lt;String&gt; predicate)&#123; return predicate.test(str); &#125;&#125;复制代码 输出为： false Stream API​ Stream 作为 Java 8 的一大亮点，它与 java.io 包里的 InputStream 和 OutputStream 是完全不同的概念。Stream中间操作，多个中间操作可以连接起来形成一个流水线，除非流水线上触发了终止操作，否则中间不会执行任何处理！而终止操作时会一次性全部处理，称为惰性处理。要进行流操作首先要获取流。有4中方法可以获取流。 集合获取流 通过集合系列提供的stream方法和 parallelStream()（并行流）方法获取流 12345public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); // 常用获取流的方式 Stream&lt;Integer&gt; stream = list.stream();&#125; 2.通过Arrays.stream() 将数组转换成流 12345public static void main(String[] args) &#123; int[] a = new int[]&#123;1,2,3,4&#125;; IntStream stream = Arrays.stream(a); &#125; 3.通过Stream.of的方法创建流 123public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3);&#125; 4.创建无限流 123public static void main(String[] args) &#123; Stream&lt;Integer&gt; iterate = Stream.iterate(0, x -&gt; x + 2);&#125; 所有的对流的操作可以分为4种，分别为筛选与分片，映射，排序，终结（归约，收集） 中间操作主要有以下方法（此类型方法返回的都是Stream）：map (mapToInt, flatMap 等)、 filter、 distinct、 sorted、 peek、 limit、 skip、 parallel、 sequential、 unordered 终止操作主要有以下方法：forEach、 forEachOrdered、 toArray、 reduce、 collect、 min、 max、 count、 anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 iterator 筛选与分片操作有 filter ,distant,limit,skip。 filter ： 过滤操作,方法参数为*断言型接口 * 1234public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3); stream.filter(x-&gt;x != 2).forEach(x-&gt; System.out.println(x)); &#125; 输出： 1213 distinct ： 去重操作，方法无参数 limit ： 获取前几条数据，*方法参数为long * skip ： 跳过前多少条数据，然后获取后面所有的。方法参数为long 映射常用操作有 map ，flatMap。 map: 对原数据进行处理，并返回处理后的数据。 方法参数为函数型接口 1234public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3); stream.map(x-&gt;x*2).forEach(System.out::println); &#125; 输出： 123246 flatMap ： 使原来流种的原有数据一个一个整合在另一个流中。方法参数为函数型接口，但是返回值为流 12345public static void main(String[] args) &#123; List&lt;String&gt; list = Arrays.asList("a", "b", "c"); List&lt;String&gt; list2 = Arrays.asList("f","d"); list.stream().flatMap(x-&gt;list2.stream().map(y-&gt; x + y)).forEach(System.out::println);&#125; 排序常用操作有sort自然排序，合sort参数为排序器的定制排序 自然排序 1234public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3); stream.sorted().forEach(System.out::println); &#125; 输出： 123123 定制排序（(x,y)-&gt;-Integer.compare(x,y)） 12345 public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3); stream.sorted((x,y)-&gt;-Integer.compare(x,y)).forEach(System.out::println); &#125;复制代码 输出： 123321 终止操作 allMatch 检查是否匹配所有元素 方法参数为断言型接口 anyMatch 检查是否匹配所有元素 方法参数为断言型接口 noneMatch 检查是否没有匹配所有元素 方法参数为断言型接口 findFirst 返回第一个元素 无方法参数 findAny 返回当前流的任意元素 无方法参数 count 返回流中的元素总个数 无方法参数 max 返回流的最大值 无方法参数 min 返回流中的最小值 无方法参数 归约reduce : 归约 – 可以将流中的元素反复结合起来，得到一个值 12345public static void main(String[] args) &#123; List&lt;Integer&gt; list1 = Arrays.asList(1,2,3,4,5,6,7,8,9,10); Integer reduce = list1.stream().reduce(11, (x, y) -&gt; x + y); System.out.println(reduce); &#125; 输出 ： 66 收集​ 这个是非常常用的一个操作。 将流装换为其他形式。接收到一个Collector接口的实现，用于给Stream中的元素汇总的方法。用collect方法进行收集。方法参数为Collector。Collector可以由Collectors中的toList()，toSet(),toMap(Function(T,R) key,Function(T,R) value)等静态方法实现。 toList() 返回一个 Collector ，它将输入元素 List到一个新的 List 。 toMap(Function&lt;? super T,? extends K&gt; keyMapper, Function&lt;? super T,? extends U&gt; valueMapper) 返回一个 Collector ，它将元素累加到一个 Map ，其键和值是将所提供的映射函数应用于输入元素的结果。 toSet() 返回一个 Collector ，将输入元素 Set到一个新的 Set 。 eg: User类 1234567891011121314151617181920@Data@ToStringpublic class User &#123; private String name; private Integer age; private Integer salary;&#125; public static void main(String[] args) &#123; List&lt;User&gt; users = Arrays.asList(new User("张三", 19, 1000), new User("张三", 58, 2000), new User("李四", 38, 3000), new User("赵五", 48, 4000) ); List&lt;String&gt; collect = users.stream().map(x -&gt; x.getName()).collect(Collectors.toList()); Set&lt;String&gt; collect1 = users.stream().map(x -&gt; x.getName()).collect(Collectors.toSet()); Map&lt;Integer, String&gt; collect2 = users.stream().collect(Collectors.toMap(x -&gt; x.getAge(), x -&gt; x.getName())); System.out.println(collect); System.out.println(collect1); System.out.println(collect2); &#125; 输出： 123[张三, 张三, 李四, 赵五][李四, 张三, 赵五]&#123;48=赵五, 19=张三, 38=李四, 58=张三&#125; 分组​ Collectors.groupingBy()方法是 返回 Collector “由基团”上的类型的输入元件操作实现 T ，根据分类功能分组元素。这个是非常常用的操作。 比如你要对名字相同的进行分组。 groupingBy(Function&lt;? super T,? extends K&gt; classifier) eg: 123456789public static void main(String[] args) &#123; List&lt;User&gt; users = Arrays.asList(new User("张三", 19, 1000), new User("张三", 58, 2000), new User("李四", 38, 3000), new User("赵五", 48, 4000) ); Map&lt;String, List&lt;User&gt;&gt; collect3 = users.stream().collect(Collectors.groupingBy(x -&gt; x.getName())); System.out.println(collect3);&#125; 输出：{李四=[User{name=’李四’, age=38, salary=3000}], 张三=[User{name=’张三’, age=19, salary=1000}, User{name=’张三’, age=58, salary=2000}], 赵五=[User{name=’赵五’, age=48, salary=4000}]} 当然还有其他的一些比较复杂的分组操作，实际代码看业务来进行实现。 总结​ java8中的lambda表达式可能一开始用的时候还不是很熟悉，但是只要熟悉了，你会发现非常的好用，而且lambda表达式结合stream API可以进行编写自己的工具类。在平常项目中可以非常的省时间，提高写代码的效率。我现在给出一个List转Map的工具类。 123456789101112131415161718192021222324252627282930public class CollectionStream &#123; public static void main(String[] args) &#123; List&lt;User&gt; users = Arrays.asList(new User("张三", 19, 1000), new User("张三", 58, 2000), new User("李四", 38, 3000), new User("赵五", 48, 4000) ); Map&lt;Integer, Integer&gt; map = listToMap(users, x -&gt; x.getAge(), x -&gt; x.getSalary()); System.out.println(map); &#125; /** * @Description list 转map key不能相同 ，如果相同会报错。 方法对 源数据，key，value过滤null。 * @param source 源数据 * @param key * @param value * @return java.util.Map&lt;K,V&gt; **/ public static &lt;DTO, K, V&gt; Map&lt;K, V&gt; listToMap(List&lt;DTO&gt; source, Function&lt;? super DTO, ? extends K&gt; key, Function&lt;? super DTO, ? extends V&gt; value) &#123; Objects.requireNonNull(source, "source not null"); Objects.requireNonNull(key, "key not null"); Objects.requireNonNull(value, "value not null"); Map&lt;K, V&gt; map = source.stream() .filter(dto -&gt; dto != null) .filter(dto -&gt; key.apply(dto) != null) .filter(dto -&gt; value.apply(dto) != null) .collect(Collectors.toMap(key, value)); return map; &#125;&#125;]]></content>
      <tags>
        <tag>-lambda -Stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[观察者模式]]></title>
    <url>%2F2019%2F10%2F29%2F%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[模式定义观察者模式是对象行为模式，又叫发布-订阅模式（publish/subscribe）模式，源-监视器模式（source/Listener)模式。 观察者模式定义了一种一对多的依赖关系，让多个观察者对象同事监听某一个主题对象，这个主题对象在状态上发生变化时，会通知所有观察者对象，使他们能够做出相应的操作。 模式结构软件系统中，常常因为一个对象的状态发生改变时，某些其他对象做出相应的改变，做到这一点的设计方案有很多，但为了系统稳定性，选择低耦合的观察者模式，有助于系统的复用，保证高度协作。 模式描述意图：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 主要解决：一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。 何时使用：一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。 如何解决：使用面向对象技术，可以将这种依赖关系弱化。 关键代码：在抽象类里有一个 ArrayList 存放观察者们。 使用场景： 一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将这些方面封装在独立的对象中使它们可以各自独立地改变和复用。 一个对象的改变将导致其他一个或多个对象也发生改变，而不知道具体有多少对象将发生改变，可以降低对象之间的耦合度。 一个对象必须通知其他对象，而并不知道这些对象是谁。 需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 角色 抽象主题（Subject)角色：抽象主题角色把所有对观察者对象的引用保存在一个聚集（比如ArrayList)里，每一个主题都可以有任何数量的观察者。抽象主题提供一个接口（抽象类)，可以增加和删除观察者，抽象主题角色又叫抽象被观察者（Observable)角色。 具体主题（ConcreteSubject)角色：将有关状态存入具体的观察者对象；在具体主题的内部状态改变时，给所有登录订阅过的观察者发送通知。具体主题对象又叫具体被观察者（Concrete Observable）角色。 抽象观察者(Observer)角色：给所有的具体观察者定义一个接口，在得到主题的通知时更新自己，这个接口叫做更新接口。 具体观察者（Concrete Observer）角色：存储与主题的状态自恰的状态，具体观察者实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题相协调，具体观察者可以保持一个指向具体主题对象的引用。 实现代码示例： 抽象主题类 12345678910111213141516171819202122232425262728293031public abstract class Subject &#123; /** * 用来保存注册的观察者对象 */ private List&lt;Observer&gt; list = new ArrayList&lt;Observer&gt;(); /** * 注册观察者对象 * @param observer 观察者对象 */ public void attach(Observer observer)&#123; list.add(observer); System.out.println("Attached an observer"); &#125; /** * 删除观察者对象 * @param observer 观察者对象 */ public void detach(Observer observer)&#123; list.remove(observer); &#125; /** * 通知所有注册的观察者对象 */ public void nodifyObservers(String newState)&#123; for(Observer observer : list)&#123; //推模式下，需要传入状态 //拉模式下，不需要传入状态 observer.update(newState); &#125; &#125;&#125; 具体主题角色类： 1234567891011121314public class ConcreteSubject extends Subject&#123; private String state; public String getState() &#123; return state; &#125; public void change(String newState)&#123; state = newState; System.out.println("主题状态为：" + state); //状态发生改变，通知各个观察者 //在推模式下，需要传入参数 //拉模式下，不需要传入参数 this.nodifyObservers(state);//调用父类定义方法 &#125;&#125; 抽象观察者角色类： 1234567public interface Observer &#123; /** * 更新接口 * @param state 更新的状态 */ public void update(String state);&#125; 具体观察者角色类： 123456789101112public class ConcreteObserver implements Observer &#123; //观察者的状态 private String observerState; @Override public void update(String state) &#123; /** * 更新观察者的状态，使其与目标的状态保持一致 */ observerState = state; System.out.println("状态为："+observerState); &#125;&#125; 客户端： 123456789101112public class Client &#123; public static void main(String[] args) &#123; //创建主题对象 ConcreteSubject subject = new ConcreteSubject(); //创建观察者对象 Observer observer = new ConcreteObserver(); //将观察者对象登记到主题对象上 subject.attach(observer); //改变主题对象的状态 subject.change("new state"); &#125;&#125; 推模式和拉模式推模式上面的例子就是典型的推模式，主题对象向观察者推送详细信息。 拉模式主题对象在通知观察者的时候，只传递少量信息。如果观察者需要更具体的信息，由观察者主动到主题对象中获取，相当于是观察者从主题对象中拉数据。一般这种模型的实现中，会把主题对象自身通过update()方法传递给观察者，这样在观察者需要获取数据的时候，就可以通过这个引用来获取了。 调用观察者的方法时，不需要传入参数 观察者模式与订阅模式 观察者注册到目标；目标发生改变时，调用观察者方法 订阅者把自己想订阅的事件注册到调度中心，当该事件触发时候，发布者发布该事件到调度中心（顺带上下文），由调度中心统一调度订阅者注册到调度中心的处理代码 总结 从两张图片可以看到，最大的区别是调度的地方。 虽然两种模式都存在订阅者和发布者（具体观察者可认为是订阅者、具体目标可认为是发布者），但是观察者模式是由具体目标调度的，而发布/订阅模式是统一由调度中心调的，所以观察者模式的订阅者与发布者之间是存在依赖的，而发布/订阅模式则不会。 两种模式都可以用于松散耦合，改进代码管理和潜在的复用。]]></content>
      <tags>
        <tag>-设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基本注解]]></title>
    <url>%2F2019%2F10%2F28%2FJava%E5%9F%BA%E6%9C%AC%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Annotation的概念与作用元数据（MeteData）也就是Annotation，这是一种代码里的特殊标志，可在编译，类加载，运行时被读取。 Annotation就像修饰符一样，可用于修饰包，类，构造器，方法， 成员变量，参数，局部变量的声明，这些信息被存储到Annotation的“name=value”对中 Annotation是一个接口，程序通过反射来获取指定程序元素的Annotation对象，然后通过Annotation对象来获取注释里的元数据 基本Annotation 四种基本的Annotation如下： @Override @Deprecated @SuppressWarinings @SafeVarargs @Override注解的功能与用法@Override用来制定方法覆盖度，强制一个子类必须覆盖父类的方法；用于避免普通子类没覆盖父类抽象方法，方法名写错 @Deprecated注解的功能与用法@Deprecated用于表示某个程序元素（方法，类等）已过时，当使用过时类，方法时，会发出警告信息 @SuppressWarinings注解的功能与用法@SuppressWarinings指示被该Annotation修饰的程序元素（以及该程序元素的所有子元素）取消显示指定的编译器错误 @SafeVarargs注解的功能与用法@SafeVarargs用于解决“堆污染”警告 “堆污染”：当把一个不带泛型的对象赋值给一个带泛型的变量时，往往会产生堆污染 JDK的元Annotation上面四个基本注解是在java.lang包下的， 此外还在java.lang.annotation包下提供4个Meta Annotation，这四个Annotation都用于修饰其他的Annotation的定义 @Retention @Target @Document @Inherited @Retention注解的功能与用法@Retention只能用于修饰一个Annotation定义，指定被修饰的Annotation可以保留多长时间 @Retention包含一个RetentionPolicy类型的value成员变量，使用@Retention必须为改对象指定值 value值分别有： RetentionPolicy.CLASS:默认值，记录在class文件中 RetentionPolicy.RUNTIME:JVM保留该Annotation，程序可以通过反射获取该Annotation信息 RetentionPolicy.SOURCE:保留源代码中，编译器丢弃该Annotation @Target注解的功能与用法@Target用于修饰一个Annotation定义，用于指定被修饰的Annotation能用于修饰哪些程序单元 value值分别有： ElementType.ANNOTATION_TYPE:指定该策略的Annotation只能用于修饰Annotation ElementType.CONSTRUCTOR:只能修饰构造器 ElementType.FIFLD:只能修饰成员变量 ElementType.LOCAL_VARIABLE:只能修饰局部变量 ElementType.METHOD:修饰方法定义 ElementType.PACKAGE:修饰包的定义 ElementType.PARAETER:修饰参数 ElementType.TYPE:可以修饰类、接口（包括注解类型）或枚举定义 @Document注解的功能与用法@Document用于该Annotation将被javadoc工具提取成文档 @Inherited注解的功能与用法@Inherited元Annotation指定被它修饰的Annotation将具有继承性。 如果某个类用包含@Inherited的Annotation，则该子类将自动也使用该Annotation 自定义Annotation定义一个新的Annotation类型使用@interface关键字。 1234public @interface TESTAnnotation&#123; ...&#125; 可定义Annotation的成员变量，并且该变量可以指定初始值，用关键字default 12345public @interface MyTag&#123; String name() default "zhengkai"; int age() default 18; &#125; 该Annotation定义俩个成员变量，并且已经有初始值 **当开发者使用Annotation修饰类，方法，Filed等成员之后，这些Annotation并不会生效，必须有开发者提供相应的工具来提取并处理Annotation信息 运行时Annotationjava.lang.reflect包下提供了获取Annotation的AnnotationElenment接口，程序可调用如下三个方法获取Annotation信息 getAnnotation(Class annotationClass)：获得程序元素的注解，不存在返回null Annotations[]：获取程序元素上所有的注解 isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass):判断该程序元素是否存在注解]]></content>
      <tags>
        <tag>-注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive数据仓库基础知识]]></title>
    <url>%2F2019%2F10%2F22%2FHive%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[数据仓库Hive产生背景MapReduce编程门槛高，无法及时应对需求的变更 传统RDBMS（关系型数据库）人员的需求，HDFS上的文件并没有schema的概念 可通过Hive进行大数据的处理 Hive概述有Facebook开源，用于解决海量结构化日志的数据统计问题 构建在Hadoop之上的数据仓库（计算能力，存储能力，可应付数据的暴增） Hive提供的SQL查询语言：HQL 底层支撑多种不同的执行引擎 Hive底层执行引擎支持：MR/Tez/Spark（用户不感知） ###为什么要使用Hive 简单，容易上手 为超大数据集设计的计算/扩展能力 同一的元数据管理：Hive数据是存放在HDFS上，元数据信息（记录数据(HDFS数据)的数据）是存放在MySQL中 SQL on Hadoop:Hive,Spark,SQL,impala… Hive是一个离线框架，不适合实时查询 Hive体系架构Hive 在Hadoop生态中的位置 体系架构图： client：shell、thrift/jdbc(server/jdbc)、webUI(HUE/Zeppelin) metastore:==&gt;MySQL database:name/location/owner... table:name、location、owner、column、name/type...Hive：写SQL翻译成MapReduce，放入到Hadoop Hive部署架构 测试环境 客户端把SQL提交Hive引擎，元数据信息可存放在Derby中（只能进行单客户端的操作，就是单session）即使是测试环境也不推荐使用，因此只能选择MySQL 生产环境：为了防止MySQL错误导致无法进行获取元数据信息，因此得有主备MySQL，主备MySQL会进行切换。（解决MySQL单点问题） Hadoop集群：DN、NM、NN、RM Hive提交到RM上，Hadpoop集群有很多节点，Hive是一个客户端，并不涉及集群的概念 Hive与RDBMS的区别 支持的：都支持分布式 区别的：Hive不适合立马进行查询 Hive部署及快速入门包：hive-1.*.0cdh.5 *. *tar-gz *bin目录：脚本 *conf目录：配置 1 下载 2解压的 ~/app 3添加Hive-HOME到系统环境变量 4修改配置 5拷贝MySQL驱动包 6预先下载MySQL数据库 Hive DDL详解可以创建一张表，把数据加入到表中，对数据的各种维度的分析 create/delete/alter… Hive数据抽象/结构 database HDFS一个目录 table HDFS一个目录 data文件 partition分区表 HDFS一个目录 bucket分桶 HDFS一个文件 创建数据库1234CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name [COMMENT database_comment] [LOCATIO hdfs_path] [WITH DBPROPERTIES (property_name=property_value,...)]; 创建表12345678910111213CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name [(col_name data_type[COMMENT col_comment], ... [constraint_specification])] [COMMENT table_comment] [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] [ROW FORMAT row_format] [STORED AS file_format] [LOCATION hdfs_path] [TBLPROPERTIES (property_name=property_value, ...)] [AS select_statement];CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name LIKE existing_table_or_view_name [LOCATION hdfs_path]; 各项参数说明： 1CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常，一般也可以不加这个IF NOT EXISTS语句，最多抛出错误。 2 [constraint_specification]可选项： [ PRIMARY KEY|UNIQUE|NOT NULL|DEFAULT [default_value] 3 [COMMENT table_comment] 可选项：COMMENT 后面跟的字符串是给表字段或者表内容添加注释说明的 4 [PARTITIONED BY ] 可选项：PARTITIONED BY其实是给表做分区，决定了表是否是分区表。（Hive中所谓分区表就是将表里新增加一个字段，就是分区的名字，这样你在操作表中的数据时，可以按分区字段进行过滤） 5 [CLUSTERED BY ]可选项：CLUSTERED BY对于每一个表（table）或者分区， Hive可以进一步组织成桶，也就是说桶是更为细粒度的数据范围划分。Hive也针对某一列进行桶的组织。Hive采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中 6 [ROW FORMAT]可选项：存储表格式 7 [STORED AS] 可选项：hive存储的三种文件格式 8 [LOCATION AS] 可选项：LOCATION 其实是定义hive表的数据在hdfs上的存储路径，一般管理表（内部表不不要自定义），但是如果定义的是外部表，则需要直接指定一个路径。实际上不指定也没事，会使用默认路径 部分详解： 使用PARTITIONED BY子句创建分区表。一个表可以具有一个或多个分区列，并为分区列中的每个不同值组合创建一个单独的数据目录。此外，可以使用CLUSTERED BY列对表或分区进行存储，并且可以通过SORT BY列在该存储区中对数据进行排序。这样可以提高某些查询的性能。 eg: 12345678CREATE TABLE page_view(viewTime INT, userid BIGINT, page_url STRING, referrer_url STRING, ip STRING COMMENT &apos;IP Address of the User&apos;) COMMENT &apos;This is the page view table&apos; PARTITIONED BY(dt STRING, country STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\001&apos;STORED AS SEQUENCEFILE; 上面的语句创建带有viewTime，userid，page_url，referrer_url和ip列（包括注释）的page_view表。该表也被分区，数据存储在序列文件中,文件中的数据格式由ctrl-A分隔字段，由换行分隔行。 重命名表1ALTER TABLE table_name RENAME TO new_table_name; ####更改表属性 1`ALTER TABLE table_name SET TBLPROPERTIES table_properties;` `table_properties:`` ``: (property_name = property_value, property_name = property_value, ... )` table_properties : (property_name = property_value, property_name = property_value, … ) TBLPROPERTIES:允许您使用自己的元数据键/值对标记表定义;还存在一些预定义的表属性，由Hive自动添加和管理的last_modified_user和last_modified_time。 修改表注释：要更改表的注释，您必须更改的comment属性TBLPROPERTIES： 1`ALTER TABLE table_name SET TBLPROPERTIES (``&apos;comment&apos;` `= new_comment);` 重命名现有表的列1`ALTER TABLE old_table_name REPLACE COLUMNS (col1 TYPE, ...);` 将列添加到现有表1ALTER TABLE tab1 ADD COLUMNS (c1 INT COMMENT &apos;a new int column&apos;, c2 STRING DEFAULT &apos;def val&apos;); 删除表1`DROP TABLE pv_users;` 删除表分区(更改表以删除分区)：1`ALTER TABLE pv_users DROP PARTITION (ds=``&apos;2008-08-08&apos;``)` Hive查询操作记录在Select中，而插入操作记录在将数据从查询插入Hive表和从查询将数据写入文件系统中。 简单查询1`INSERT OVERWRITE TABLE user_active``SELECT user.*``FROM user``WHERE user.active = ``1``;` 请注意，与SQL不同，我们总是将结果插入表中。也可以将其转储到本地文件中。 也可以在Beeline 或Hive CLI中运行以下查询 ： 123SELECT user.*FROM userWHERE user.active = ``1``; 基于分区的查询1`INSERT OVERWRITE TABLE xyz_com_page_views``SELECT page_views.*``FROM page_views``WHERE page_views.date &gt;= ``&apos;2008-03-01&apos;` `AND page_views.date &lt;= ``&apos;2008-03-31&apos;` `AND`` ``page_views.referrer_url like ``&apos;%xyz.com&apos;``;` 系统根据分区列上的where子句条件自动确定要在查询中使用的分区。例如，为了获取域xyz.com引用的03/2008月份的所有page_views 请注意，此处使用page_views.date，因为该表（上面）是使用PARTITIONED BY（date DATETIME，country STRING）定义的；如果您给分区命名不同，请不要期望.date发挥您的想法！ 连接查询1234INSERT OVERWRITE TABLE pv_usersSELECT pv.*, u.gender, u.ageFROM user u JOIN page_view pv ON (pv.userid = u.id)WHERE pv.date = &apos;2008-03-03&apos;; 可以使用LEFT OUTER，RIGHT OUTER或FULL OUTER关键字限定联接，以指示外部联接的类型（保留的左侧，保留的右侧或两侧保留） 检查另一个表中是否存在键，用户可以使用LEFT SEMI JOIN]]></content>
      <tags>
        <tag>-Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[swagger2学习]]></title>
    <url>%2F2019%2F10%2F16%2Fswagger2%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[一、Swagger简介背景​ 在现在的开发流程中，为了最大程度实现前后端的分离，通常后端接口只提供数据接口，由前端通过Ajax请求从后端获取数据并进行渲染再展示给用户。我们用的最多的方式就是后端会返回给前端一个JSON字符串，前端解析JSON字符串生成JavaScript的对象，然后再做处理。 演化非Restful接口的支持 一个方法对应于一个端口方法映射，通常只有GET/POST方法对应CRUD，后期维护成本大，通常标签有： ​ @Controller 标识一个类为控制器。 @RequestMapping URL的映射。 @ResponseBody 返回结果转换为JSON字符串。 @RequestBody 表示接收JSON格式字符串参数。 Restful API设计 Restful API是一种编程风格，比起传统的通过get/post方法的接口设计，Restful API的设计则通过HTTP的方法来表示CRUD相关的操作。 123456接口URL | HTTP方法 | 接口说明-------| -------- |-------/article | POST | 保存文章/article/&#123;id&#125; | GET | 查询文章列表/article/&#123;id&#125; | DELETE | 删除文章/article/&#123;id&#125; | PUT | 修改文章 区别： ​ ①类上通常使用@RestController注解（spring4提供），表示返回Json数据的注解，支持Restful控制器。 ​ ②/article/{id}具有三个相同的URL映射，这在@Controller标识的类中是不允许出现的，而这通过method来进行区分，produces的作用是表示返回结果的类型是JSON。 ③@PathVariable这个注解（Spring MVC提供），作用是表示该变量的值是从访问路径中获取。 简介Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。总体目标是使客户端和文件系统作为服务器以同样的速度来更新。文件的方法，参数和模型紧密集成到服务器端的代码，允许API来始终保持同步。Swagger 让部署管理和使用功能强大的API从未如此简单。 二、Swagger与Spring boot集成①、导入相应jar包12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt; ②、基本信息配置12345678910111213141516171819202122232425262728293031323334353637@Configuration@EnableSwagger2public class SwaggerConfig &#123; @Bean public Docket docket()&#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() //当前包路径 .apis(RequestHandlerSelectors.basePackage("com.bmsoft.dc.dodp")) .paths(PathSelectors.any()).build(); &#125; @Bean public Docket docket1()&#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .groupName("caozifu") .select() .apis(RequestHandlerSelectors.basePackage("com.bmsoft.dc.dodp")) .paths(PathSelectors.any()).build(); &#125; /** * 构建api文档的详细信息函数 * */ private ApiInfo apiInfo()&#123; return new ApiInfoBuilder() //页面标题 .title("离线开发平台Restful接口管理") //版本号 .version("1.0") //描述 .description("API 描述") .build(); &#125;&#125; 标签说明： @Configuration是表示这是一个配置类，是JDK自带的注解 @EnableSwagger2的作用是启用Swagger2相关功能。 ​ 配置类里面我么实例化了一个Docket对象，这个对象主要包括三个方面的信息： ​ （1）整个API的描述信息，即ApiInfo对象包括的信息，这 部分信息会在页面上展示。 （2）指定生成API文档的包名。 （3）指定生成API的路径。按路径生成API可支持四种模式：任何路径都生成(any)、任何路径都不生成 (none)以及正则匹配(regex)和ant 模式匹配四种方式 ③、编写方法及其参数描述​ 编写相应的方法，并应方法中做出相应的参数描述，具体标签有： @ApiOperation 用在方法上，说明方法的作用，每一个url资源的定义,使用方式： 属性名称 备注 value url的路径值 ​ *tags 接口的标签，相同标签的接口会在一个标签页下展示。 notes 接口详细说明，展示在接口的详情页。 httpMethod 支持的HTTP的方法。 @ApiImplicitParams，@ApiImplicitParam的容器，可包含多个@ApiImplicitParam注解 @ApiImplicitParam，请求参数属性配置： 属性名称 备注 name 参数名称 value 参数说明 required 是否必须 dataType 数据类型 @ApiResponse，返回结果属性配置： 属性名称 备注 code 返回结果的编码 message 返回结果的说明 response 返回结果对应的类 示例 12345678910111213@ApiOperation(value = &quot;更新文章&quot;, notes = &quot;更新文章内容&quot;, tags = &quot;Article&quot;,httpMethod = &quot;PUT&quot;) @ApiImplicitParams(&#123; @ApiImplicitParam(name = &quot;id&quot;, value = &quot;文章ID&quot;, required = true, dataType = &quot;Long&quot;), @ApiImplicitParam(name = &quot;title&quot;, value = &quot;文章标题&quot;, required = false, dataType = &quot;String&quot;), @ApiImplicitParam(name = &quot;summary&quot;, value = &quot;文章摘要&quot;, required = false, dataType = &quot;String&quot;), @ApiImplicitParam(name = &quot;status&quot;, value = &quot;发布状态&quot;, required = false, dataType = &quot;Integer&quot;) &#125;) @RequestMapping(value = &quot;/article/&#123;id&#125;&quot;, method = PUT, produces = &quot;application/json&quot;) public WebResponse&lt;?&gt; updateArticle(@PathVariable Long id,@RequestBody Article article)&#123; article.setId(id); articleService.updateArticle(article); return WebResponse.getSuccessResponse(new HashMap&lt;&gt;()); &#125; 启动Spring boot，然后访问：http://127.0.0.1:8080/swagger-ui.html即可看到如下结果 页面显示： 其他常用标签 @API注解:用在类上，说明该类的作用。可以标记一个Controller类做为swagger 文档资源 12&gt; @Api(value = "/user", description = "Operations about user")&gt; 属性名称 备注 value url的路径值 tags 如果设置这个值、value的值会被覆盖 description 对api资源的描述 description 对api资源的描述 @ApiModel：描述一个Model的信息（这种一般用在post创建的时候，使用@RequestBody这样的场景，请求参数无法使用 @ApiModelProperty：描述一个model的属性]]></content>
      <tags>
        <tag>-swagger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis-plus学习]]></title>
    <url>%2F2019%2F10%2F14%2Fmybatis-plus%E4%B8%AA%E4%BA%BA%E8%A7%81%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[MyBatis-Plus（简称 MP）是一个 MyBatis 的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。mybatis-plus的特性​ ①无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑​ ②损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作​ ③强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求​ ④支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错​ ⑤支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题​ ⑥支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作​ ⑦支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ）​ ⑧内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用​ ⑨内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询​ ⑩分页插件支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer2005、SQLServer 等多种数据库 主要核心知识：Mapper CRUD接口说明: 通用 CRUD 封装BaseMapper接口，为 Mybatis-Plus 启动时自动解析实体表关系映射转换为 Mybatis 内部对象注入容器 泛型 T 为任意实体对象 参数 Serializable 为任意类型主键 Mybatis-Plus 不推荐使用复合主键约定每一张表都有自己的唯一 id 主键 对象 Wrapper 为 条件构造器 实际上是在Mybatis的mapper扫描文件进行了CURD增强， CRUD方法基本是insert、delete（ById,ByMap、BatchIds)、 update（ById)、select（ById、BathchIds、ByMap、One、Count、List、Maps、Objs、Page、MapsPage) 基本是通过Id,条件进行CRUD Service CRUD接口说明: 通用 Service CRUD 封装IService接口，进一步封装 CRUD 采用 get 查询单行 remove 删除 list 查询集合 page 分页 前缀命名方式区分 Mapper 层避免混淆， 泛型 T 为任意实体对象 建议如果存在自定义通用 Service 方法的可能，请创建自己的 IBaseService 继承 Mybatis-Plus 提供的基类 对象 Wrapper 为 条件构造器 条件构造器说明: 介绍 上图绿色框为抽象类abstract 蓝色框为正常class类，可new对象 黄色箭头指向为父子类关系，箭头指向为父类 方法入参boolean condition表示该条件是否加入最后生成的sql中 方法均为从上往下补全个别boolean类型的入参,默认为true 出现的泛型Param均为Wrapper的子类实例(均具有AbstractWrapper的所有方法) 方法在入参中出现的R为泛型,在普通wrapper中是String,在LambdaWrapper中是函数(例:Entity::getId,Entity为实体类,getId为字段id的getMethod) 方法入参中的R column均表示数据库字段,当R具体类型为String时则为数据库字段名(字段名是数据库关键字的自己用转义符包裹!)!而不是实体类数据字段名!!!,另当R具体类型为SFunction时项目runtime不支持eclipse自家的编译器!!! 举例均为使用普通wrapper,入参为Map和List的均以json形式表现! 使用中如果入参的Map或者List为空,则不会加入最后生成的sql中!!! 有任何疑问就点开源码看,看不懂函数的lambda 表达式详解 QueryWrapper###说明:继承自 AbstractWrapper ,自身的内部属性 entity 也用于生成 where 条件及 LambdaQueryWrapper, 可以通过 new QueryWrapper().lambda() 方法获取 SELECT 123select(String... sqlSelect)select(Predicate&lt;TableFieldInfo&gt; predicate)select(Class&lt;T&gt; entityClass, Predicate&lt;TableFieldInfo&gt; predicate) 设置查询字段 说明: 以上方分法为两类.第二类方法为:过滤查询字段(主键除外),入参不包含 class 的调用前需要wrapper内的entity属性有值! 这两类方法重复调用以最后一次为准 例: select(&quot;id&quot;, &quot;name&quot;, &quot;age&quot;) 例: select(i -&gt; i.getProperty().startsWith(&quot;test&quot;)) 使用MP入门： ①定义一个JavaBean对象，用于封装数据库信息 ②定义一个（BeanName)Mapper接口，该接口继承BaseMapper 并传入相对应的Bean对象 ③可直接在查询地方定义一个查询构造器Wrapper实现类（QueryWrapper或LambdaQueryWrapper）用于复杂查询，将其传入实例化（容器中拿）的mapper的方法条件中，获取查询后的数据。]]></content>
      <tags>
        <tag>-mybatis-plus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virtualBox 进行Net后SSH注意事项]]></title>
    <url>%2F2019%2F10%2F05%2FvirtualBox-%E8%BF%9B%E8%A1%8CNet%E5%90%8ESSH%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[因为学习需要，为了更加便捷，抛弃了使用笨重的VMware，而选择了轻携的Oracle virtualBox，但是恶梦也是从这里开始了，倒腾了半天，也总算解决了这个问题！ 首先声明：这个问题针对校园网锐捷客户端而言，锐捷不允许多IP，在倒腾了一会后，发现如果选择桥接模式，再进行不同物理网卡与虚拟网卡进行Internet网络共享后，锐捷客户端总是抛断网搞破坏，因此只能选择，Net连接（在VMware中也是选择Net连接 的我，对Net方式较为熟悉） 恶性循环： 如果选择桥接模式，只能ping通主机，无法ping通其他IP与域名 如果选择 桥接，且进行物理网卡与虚拟网卡（需下载）进行Internet网络共享，则锐捷断网警告 如果选择Net连接，网络正常ping通，但主机ssh访问虚拟机受限。 本着熟悉入手，减少配置，选择了第三点，用Net进行网络配置 在virtualBox NAT 模式下，主机ssh访问虚拟机配置,总是显示失败 选择虚拟机-&gt;设置-&gt;网络-&gt;高级-&gt;端口转发： 协议：TCP 主机IP:127.0.0.1 主机端口：1234 子系统IP：（虚拟机IP） 子系统端口：22（SSH监听端口） 完成配置后，在主机上确认是否已启动1234端口监听： 登录成功：]]></content>
      <tags>
        <tag>-virtualBox -知识漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leecodede_139单词拆分]]></title>
    <url>%2F2019%2F10%2F04%2FLeecodede-139%E5%8D%95%E8%AF%8D%E6%8B%86%E5%88%86%2F</url>
    <content type="text"><![CDATA[给定一个非空字符串 s 和一个包含非空单词列表的字典 wordDict*，判定 *s 是否可以被空格拆分为一个或多个在字典中出现的单词。 说明： 拆分时可以重复使用字典中的单词。 你可以假设字典中没有重复的单词。 示例 1： 输入: s = “leetcode”, wordDict = [“leet”, “code”]输出: true*解释: 返回 true 因为 “leetcode” 可以被拆分成 “leet code” 示例 2： 输入: s = “applepenapple”, wordDict = [“apple”, “pen”]输出: true解释: 返回 true 因为 “applepenapple” 可以被拆分成 “apple pen apple”。 注意你可以重复使用字典中的单词。 示例 3： 输入: s = “catsandog”, wordDict = [“cats”, “dog”, “sand”, “and”, “cat”]输出: false-* 该题可以采用暴力法 、广度优先搜索、动态规划 实际上三者都有一个共同点，即：应该先找出前半部分是否含有，再进行递归或者递推 动态规划三要素：（初始）状态，状态转移方程，终止条件 其实动态规划套路就是记忆存储，自底递推，找到状态转移 但是这道题，可以想象其实可以把一个单词（而不是一个下标），当初一个状态，来进行状态的转移 eg: catdog—&gt;cat(true)+dog(exit) 12345678910111213141516171819class Solution &#123; public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123; Set&lt;String&gt; set=new HashSet(wordDict); boolean[] dp=new boolean[s.length()+1]; dp[0]=true; //注意界限：i&lt;=s.length() for(int i=0;i&lt;=s.length();i++)&#123; for(int j=0;j&lt;i;j++)&#123; //想象成：dp[leet]+contains(code) ? true if(dp[j] &amp;&amp; set.contains(s.substring(j,i)))&#123; dp[i]=true; break; &#125; &#125; &#125; return dp[s.length()]; &#125; &#125; Leecode官方： 这个方法的想法是对于给定的字符串（ss）可以被拆分成子问题 s1s1 和 s2s2 。如果这些子问题都可以独立地被拆分成符合要求的子问题，那么整个问题 ss 也可以满足。也就是，如果 “\text{catsanddog}catsanddog” 可以拆分成两个子字符串 “\text{catsand}catsand” 和 “\text{dog}dog” 。子问题 “\text{catsand}catsand” 可以进一步拆分成 “\text{cats}cats” 和 “\text{and}and” ，这两个独立的部分都是字典的一部分，所以 “\text{catsand}catsand” 满足题意条件，再往前， “\text{catsand}catsand” 和 “\text{dog}dog” 也分别满足条件，所以整个字符串 “\text{catsanddog}catsanddog” 也满足条件。 现在，我们考虑 \text{dp}dp 数组求解的过程。我们使用 n+1n+1 大小数组的 \text{dp}dp ，其中 nn 是给定字符串的长度。我们也使用 2 个下标指针 ii 和 jj ，其中 ii 是当前字符串从头开始的子字符串（s’s）的长度， jj 是当前子字符串（s’s ′）的拆分位置，拆分成 s’(0,j)s ′ (0,j) 和 s’(j+1,i)s ′ (j+1,i) 。 为了求出 \text{dp}dp 数组，我们初始化 \text{dp}[0]dp[0] 为 \text{true}true ，这是因为空字符串总是字典的一部分。 \text{dp}dp 数组剩余的元素都初始化为 \text{false}false 。 我们用下标 ii 来考虑所有从当前字符串开始的可能的子字符串。对于每一个子字符串，我们通过下标 jj 将它拆分成 s1’s1 ′ 和 s2’s2 ′ （注意 ii 现在指向 s2’s2 ′ 的结尾）。为了将 \text{dp}[i]dp[i] 数组求出来，我们依次检查每个 \text{dp}[j]dp[j] 是否为 \text{true}true ，也就是子字符串 s1’s1 ′ 是否满足题目要求。如果满足，我们接下来检查 s2’s2 ′ 是否在字典中。如果包含，我们接下来检查 s2’s2 ′是否在字典中，如果两个字符串都满足要求，我们让 \text{dp}[i]dp[i] 为 \text{true}true ，否则令其为 \text{false}false 。]]></content>
      <tags>
        <tag>-Leecode -算法思路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二篇博客]]></title>
    <url>%2F2019%2F10%2F04%2F%E7%AC%AC%E4%BA%8C%E7%AF%87%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[第一次写博客，希望能记录学习的点点滴滴 来年春招力争大厂offer上岸 第二篇博客]]></content>
      <tags>
        <tag>-hexo</tag>
      </tags>
  </entry>
</search>
