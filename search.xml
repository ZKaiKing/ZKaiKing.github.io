<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[从线程到线程池的进阶之路]]></title>
    <url>%2F2019%2F11%2F20%2F%E4%BB%8E%E7%BA%BF%E7%A8%8B%E5%88%B0%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E8%BF%9B%E9%98%B6%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[从线程到线程池的进阶之路Thread与Runnable介绍Runnable 是一个接口，该接口中只包含了一个run()方法 123public interface Runnable &#123; public abstract void run();&#125; Thread 是一个类。Thread本身就实现了Runnable接口。 1public class Thread implements Runnable &#123;&#125; Thread 是类，而Runnable是接口；Thread本身是实现了Runnable接口的类。我们知道“一个类只能有一个父类，但是却能实现多个接口”，因此Runnable具有更好的扩展性。此外，Runnable还可以用于“资源的共享”。即，多个线程都是基于某一个Runnable对象建立的，它们会共享Runnable对象上的资源。通常，建议通过“Runnable”实现多线程！ Future介绍Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。 Future类位于java.util.concurrent包下；在Future接口中声明了5个方法，下面依次解释每个方法的作用： cancel方法用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务，如果设置true，则表示可以取消正在执行过程中的任务。如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false；如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true。 isCancelled方法表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true。 isDone方法表示任务是否已经完成，若任务完成，则返回true； get()方法用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回； get(long timeout, TimeUnit unit)用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null。 也就是说Future提供了三种功能： 1）判断任务是否完成； 2）能够中断任务； 3）能够获取任务执行结果。 因为Future只是一个接口，所以是无法直接用来创建对象使用的，因此就有了下面的FutureTask。 FutureTask介绍FutureTask是一种可以取消的异步的计算任务。它的计算是通过Callable实现的，可以把它理解为是可以返回结果的Runnable。 使用FutureTask的优势有： 可以获取线程执行后的返回结果； 提供了超时控制功能。 它实现了Runnable接口和Future接口 什么是异步计算呢？也就是说，在让该任务执行时，不需要一直等待其运行结束返回结果，而是可以先去处理其他的事情，然后再获取返回结果。例如你想下载一个很大的文件，这时很耗时的操作，没必要一直等待着文件下载完，你可以先去吃个饭，然后再回来看下文件是否下载完成，如果下载完成就可以使用了，否则还需要继续等待。 FutureTask的状态FutureTask内部有这样几种状态： 1234567private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6; 看名字应该很好理解了，当创建一个FutureTask对象是，初始的状态是NEW，在运行时状态会转换，有4中状态的转换过程： NEW -&gt; COMPLETING -&gt; NORMAL：正常执行并返回； NEW -&gt; COMPLETING -&gt; EXCEPTIONAL：执行过程中出现了异常； NEW -&gt; CANCELLED；执行前被取消； NEW -&gt; INTERRUPTING -&gt; INTERRUPTED：取消时被中断。 使用FutureTask下面看一下具体的使用过程：FutureTask实现了Runnable接口，所以需要实现run方法 1234567891011121314151617public class FutureTaskTest &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ExecutorService executor = Executors.newSingleThreadExecutor(); FutureTask&lt;Integer&gt; future = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; int result = 0; for (int i = 0; i &lt; 100; i++) &#123; result += i; &#125; return result; &#125; &#125;); executor.execute(future); System.out.println(future.get()); &#125;&#125; FutureTask构造方法FutureTask有两个构造方法： 12345678910public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable&#125;public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable&#125; 第二种构造方法传入一个Runnable对象和一个返回值对象，因为Runnable是没有返回值的，所以要通过result参数在执行完之后返回结果。 run方法FutureTask实现了Runnable接口，所以需要实现run方法。 run方法的执行过程 只有state为NEW的时候才执行任务； 执行前要设置runner为当前线程，使用CAS来设置是为了防止竞争； 如果任务执行成功，任务状态从NEW转换为COMPLETING，如果执行正常，设置最终状态为NORMAL；如果执行中出现了异常，设置最终状态为EXCEPTIONAL； 唤醒并删除Treiber Stack中的所有节点； 如果调用了cancel(true)方法进行了中断，要确保在run方法执行结束前的状态是INTERRUPTED。 这里涉及到3个比较重要的方法：setException，set和handlePossibleCancellationInterrupt。 get方法12345678910111213141516public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125;public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; if (unit == null) throw new NullPointerException(); int s = state; if (s &lt;= COMPLETING &amp;&amp; (s = awaitDone(true, unit.toNanos(timeout))) &lt;= COMPLETING) throw new TimeoutException(); return report(s);&#125; 这两个方法类似，首先判断状态，如果s &lt;= COMPLETING，说明任务已经执行完毕，但set方法或setException方法还未执行结束（还未设置状态为NORMAL或EXCEPTIONAL），这时需要将当前线程添加到waiters中并阻塞。 第二种get提供了超时功能，如果在规定时间内任务还未执行完毕或者状态还是COMPLETING，则获取结果超时，抛出TimeoutException。而第一种get会一直阻塞直到state &gt; COMPLETING。 FutureTask总结FutureTask的执行过程和获取返回值的过程，要注意以下几个地方： FutureTask是线程安全的，在多线程下任务也只会被执行一次； 注意在执行时各种状态的切换； get方法调用时，如果任务没有结束，要阻塞当前线程，法阻塞的线程会保存在一个Treiber Stack中； get方法超时功能如果超时未获取成功，会抛出TimeoutException； 注意在取消时的线程中断，在run方法中一定要保证结束时的状态是INTERRUPTED，否则在cancel方法中可能没有执行interrupt，造成中断的泄露。 Executor框架接口Executor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架，目的是提供一种将”任务提交”与”任务如何运行”分离开来的机制。 J.U.C中有三个Executor接口： Executor：一个运行新任务的简单接口； ExecutorService：扩展了Executor接口。添加了一些用来管理执行器生命周期和任务生命周期的方法； ScheduledExecutorService：扩展了ExecutorService。支持Future和定期执行任务。 Executor接口123public interface Executor &#123; void execute(Runnable command);&#125; Executor接口只有一个execute方法，用来替代通常创建或启动线程的方法。例如，使用Thread来创建并启动线程的代码如下： 12Thread t = new Thread();t.start(); 使用Executor来启动线程执行任务的代码如下： 12Thread t = new Thread();executor.execute(t); 对于不同的Executor实现，execute()方法可能是创建一个新线程并立即启动，也有可能是使用已有的工作线程来运行传入的任务，也可能是根据设置线程池的容量或者阻塞队列的容量来决定是否要将传入的线程放入阻塞队列中或者拒绝接收传入的线程。 ExecutorService接口ExecutorService接口继承自Executor接口，提供了管理终止的方法，以及可为跟踪一个或多个异步任务执行状况而生成 Future 的方法。增加了shutDown()，shutDownNow()，invokeAll()，invokeAny()和submit()等方法。如果需要支持即时关闭，也就是shutDownNow()方法，则任务需要正确处理中断。 ScheduledExecutorService接口ScheduledExecutorService扩展ExecutorService接口并增加了schedule方法。调用schedule方法可以在指定的延时后执行一个Runnable或者Callable任务。ScheduledExecutorService接口还定义了按照指定时间间隔定期执行任务的scheduleAtFixedRate()方法和scheduleWithFixedDelay()方法。 Java线程池：ThreadPoolExecutorThreadPoolExecutor继承自AbstractExecutorService，也是实现了ExecutorService接口。 线程池的运行状态线程池一共有五种状态, 分别是: RUNNING ：能接受新提交的任务，并且也能处理阻塞队列中的任务； SHUTDOWN：关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务。在线程池处于 RUNNING 状态时，调用 shutdown()方法会使线程池进入到该状态。（finalize() 方法在执行过程中也会调用shutdown()方法进入该状态）； STOP：不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程。在线程池处于 RUNNING 或 SHUTDOWN 状态时，调用 shutdownNow() 方法会使线程池进入到该状态； TIDYING：如果所有的任务都已终止了，workerCount (有效线程数) 为0，线程池进入该状态后会调用 terminated() 方法进入TERMINATED 状态。 TERMINATED：在terminated() 方法执行完后进入该状态，默认terminated()方法中什么也没有做。 进入TERMINATED的条件如下： 线程池不是RUNNING状态； 线程池状态不是TIDYING状态或TERMINATED状态； 如果线程池状态是SHUTDOWN并且workerQueue为空； workerCount为0； 设置TIDYING状态成功。 下图为线程池的状态转换过程： ThreadPoolExecutor构造方法123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 构造方法中的字段含义如下： corePoolSize：核心线程数量，当有新任务在execute()方法提交时，会执行以下判断： 如果运行的线程少于 corePoolSize，则创建新线程来处理任务，即使线程池中的其他线程是空闲的； 如果线程池中的线程数量大于等于 corePoolSize 且小于 maximumPoolSize，则只有当workQueue满时才创建新的线程去处理任务； 如果设置的corePoolSize 和 maximumPoolSize相同，则创建的线程池的大小是固定的，这时如果有新任务提交，若workQueue未满，则将请求放入workQueue中，等待有空闲的线程去从workQueue中取任务并处理； 如果运行的线程数量大于等于maximumPoolSize，这时如果workQueue已经满了，则通过handler所指定的策略来处理任务； 所以，任务提交时，判断的顺序为 corePoolSize –&gt; workQueue –&gt; maximumPoolSize。 maximumPoolSize：最大线程数量； workQueue：等待队列，当任务提交时，如果线程池中的线程数量大于等于corePoolSize的时候，把该任务封装成一个Worker对象放入等待队列； workQueue ：保存等待执行的任务的阻塞队列，当提交一个新的任务到线程池以后, 线程池会根据当前线程池中正在运行着的线程的数量来决定对该任务的处理方式，主要有以下几种处理方式: 直接切换：这种方式常用的队列是SynchronousQueue，但现在还没有研究过该队列，这里暂时还没法介绍； 使用无界队列：一般使用基于链表的阻塞队列LinkedBlockingQueue。如果使用这种方式，那么线程池中能够创建的最大线程数就是corePoolSize，而maximumPoolSize就不会起作用了。当线程池中所有的核心线程都是RUNNING状态时，这时一个新的任务提交就会放入等待队列中。 使用有界队列 ：一般使用ArrayBlockingQueue。使用该方式可以将线程池的最大线程数量限制为maximumPoolSize，这样能够降低资源的消耗，但同时这种方式也使得线程池对线程的调度变得更困难，因为线程池和队列的容量都是有限的值，所以要想使线程池处理任务的吞吐率达到一个相对合理的范围，又想使线程调度相对简单，并且还要尽可能的降低线程池对资源的消耗，就需要合理的设置这两个数量。 如果要想降低系统资源的消耗（包括CPU的使用率，操作系统资源的消耗，上下文环境切换的开销等）, 可以设置较大的队列容量和较小的线程池容量, 但这样也会降低线程处理任务的吞吐量。 如果提交的任务经常发生阻塞，那么可以考虑通过调用 setMaximumPoolSize() 方法来重新设定线程池的容量。 如果队列的容量设置的较小，通常需要将线程池的容量设置大一点，这样CPU的使用率会相对的高一些。但如果线程池的容量设置的过大，则在提交的任务数量太多的情况下，并发量会增加，那么线程之间的调度就是一个要考虑的问题，因为这样反而有可能降低处理任务的吞吐量。 keepAliveTime：线程池维护线程所允许的空闲时间。当线程池中的线程数量大于corePoolSize的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了keepAliveTime； threadFactory：它是ThreadFactory类型的变量，用来创建新线程。默认使用Executors.defaultThreadFactory() 来创建线程。使用默认的ThreadFactory来创建线程时，会使新创建的线程具有相同的NORM_PRIORITY优先级并且是非守护线程，同时也设置了线程的名称。 handler ：它是RejectedExecutionHandler类型的变量，表示线程池的饱和策略。如果阻塞队列满了并且没有空闲的线程，这时如果继续提交任务，就需要采取一种策略处理该任务。线程池提供了4种策略： AbortPolicy：直接抛出异常，这是默认策略； CallerRunsPolicy：用调用者所在的线程来执行任务； DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务； DiscardPolicy：直接丢弃任务； execute方法execute()方法用来提交任务 在执行execute()方法时如果状态一直是RUNNING时，执行过程如下： 如果workerCount &lt; corePoolSize，则创建并启动一个线程来执行新提交的任务； 如果workerCount &gt;= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中； 如果workerCount &gt;= corePoolSize &amp;&amp; workerCount &lt; maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务； 如果workerCount &gt;= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。 这里要注意一下addWorker(null, false);，也就是创建一个线程，但并没有传入任务，因为任务已经被添加到workQueue中了，所以worker在执行的时候，会直接从workQueue中获取任务。所以，在workerCountOf(recheck) == 0时执行addWorker(null, false);也是为了保证线程池在RUNNING状态下必须要有一个线程来执行任务。 execute方法执行流程如下： addWorker方法addWorker方法的主要工作是在线程池中创建一个新的线程并执行，firstTask参数 用于指定新增的线程执行的第一个任务，core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize 123private boolean addWorker(Runnable firstTask, boolean core) &#123; ...&#125; 启动时会调用Worker类中的run方法，Worker本身实现了Runnable接口，所以一个Worker类型的对象也是一个线程。 Worker类（这是一个类）线程池中的每一个线程被封装成一个Worker对象，ThreadPool维护的其实就是一组Worker对象 123456789101112private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; //构造方法 Worker(Runnable firstTask) &#123; setState(-1); // -1：禁止在执行任务前对线程进行中断 this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; /** 运行方法*/ public void run() &#123; runWorker(this); &#125;&#125; Worker类继承了AQS，并实现了Runnable接口，注意其中的firstTask和thread属性：firstTask用它来保存传入的任务；thread是在调用构造方法时通过ThreadFactory来创建的线程，是用来处理任务的线程。 在调用构造方法时，需要把任务传入，这里通过getThreadFactory().newThread(this);来新建一个线程，newThread方法传入的参数是this，因为Worker本身继承了Runnable接口，也就是一个线程，所以一个Worker对象在启动的时候会调用Worker类中的run方法。 Worker继承了AQS，使用AQS来实现独占锁的功能。为什么不使用ReentrantLock来实现呢？可以看到tryAcquire方法，它是不允许重入的，而ReentrantLock是允许重入的： lock方法一旦获取了独占锁，表示当前线程正在执行任务中； 如果正在执行任务，则不应该中断线程； 如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断； 线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态； 之所以设置为不可重入，是因为我们不希望任务在调用像setCorePoolSize这样的线程池控制方法时重新获取锁。如果使用ReentrantLock，它是可重入的，这样如果在任务中调用了如setCorePoolSize这类线程池控制的方法，会中断正在运行的线程。 所以，Worker继承自AQS，用于判断线程是否空闲以及是否可以被中断。 线程池的监控通过线程池提供的参数进行监控。线程池里有一些属性在监控线程池的时候可以使用 getTaskCount：线程池已经执行的和未执行的任务总数； getCompletedTaskCount：线程池已完成的任务数量，该值小于等于taskCount； getLargestPoolSize：线程池曾经创建过的最大线程数量。通过这个数据可以知道线程池是否满过，也就是达到了maximumPoolSize； getPoolSize：线程池当前的线程数量； getActiveCount：当前线程池中正在执行任务的线程数量。 通过这些方法，可以对线程池进行监控，在ThreadPoolExecutor类中提供了几个空方法，如beforeExecute方法，afterExecute方法和terminated方法，可以扩展这些方法在执行前或执行后增加一些新的操作，例如统计线程池的执行任务的时间等，可以继承自ThreadPoolExecutor来进行扩展。 线程池进阶：ScheduledThreadPoolExecutor自JDK1.5开始，JDK提供了ScheduledThreadPoolExecutor类来支持周期性任务的调度。在这之前的实现需要依靠Timer和TimerTask或者其它第三方工具来完成。但Timer有不少的缺陷： Timer是单线程模式； 如果在执行任务期间某个TimerTask耗时较久，那么就会影响其它任务的调度； Timer的任务调度是基于绝对时间的，对系统时间敏感； Timer不会捕获执行TimerTask时所抛出的异常，由于Timer是单线程，所以一旦出现异常，则线程就会终止，其他任务也得不到执行。 ScheduledThreadPoolExecutor继承ThreadPoolExecutor来重用线程池的功能，它的实现方式如下： 将任务封装成ScheduledFutureTask对象，ScheduledFutureTask基于相对时间，不受系统时间的改变所影响； ScheduledFutureTask实现了java.lang.Comparable接口和java.util.concurrent.Delayed接口，所以有两个重要的方法：compareTo和getDelay。compareTo方法用于比较任务之间的优先级关系，如果距离下次执行的时间间隔较短，则优先级高；getDelay方法用于返回距离下次任务执行时间的时间间隔； ScheduledThreadPoolExecutor定义了一个DelayedWorkQueue，它是一个有序队列，会通过每个任务按照距离下次执行时间间隔的大小来排序； ScheduledFutureTask继承自FutureTask，可以通过返回Future对象来获取执行的结果。 通过如上的介绍，可以对比一下Timer和ScheduledThreadPoolExecutor： Timer ScheduledThreadPoolExecutor 单线程 多线程 单个任务执行时间影响其他任务调度 多线程，不会影响 基于绝对时间 基于相对时间 一旦执行任务出现异常不会捕获，其他任务得不到执行 多线程，单个任务的执行不会影响其他线程 所以，在JDK1.5之后，应该没什么理由继续使用Timer进行任务调度了。 ScheduledThreadPoolExecutor的构造方法ScheduledThreadPoolExecutor有3中构造方法： 12345678910111213141516public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), handler);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler);&#125; 因为ScheduledThreadPoolExecutor继承自ThreadPoolExecutor，所以这里都是调用的ThreadPoolExecutor类的构造方法。 第一种构造方法示例： 123scheduler = new ScheduledThreadPoolExecutor(20, threadFactory("BDP-Default-Scheduler-Thread-", true)) scheduler.setMaximumPoolSize(20) scheduler.setKeepAliveTime(5, TimeUnit.MINUTES) scheduleAtFixedRate方法该方法设置了执行周期，下一次执行时间相当于是上一次的执行时间加上period，它是采用已固定的频率来执行任务： 123456public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) &#123; ...&#125; 总结ScheduedThreadPoolExecutor的实现，主要介绍了以下方面： ScheduledThreadPoolExecutor继承自ThreadPoolExecutor，所以它也是一个线程池，也有coorPoolSize和workQueue，ScheduledThreadPoolExecutor特殊的地方在于，自己实现了优先工作队列DelayedWorkQueue； ScheduedThreadPoolExecutor实现了ScheduledExecutorService，所以就有了任务调度的方法，如schedule，scheduleAtFixedRate和scheduleWithFixedDelay，同时注意他们之间的区别； 内部类ScheduledFutureTask继承自FutureTask，实现了任务的异步执行并且可以获取返回结果。同时也实现了Delayed接口，可以通过getDelay方法获取将要执行的时间间隔； 周期任务的执行其实是调用了FutureTask类中的runAndReset方法，每次执行完不设置结果和状态。 详细分析了DelayedWorkQueue的数据结构，它是一个基于最小堆结构的优先队列，并且每次出队时能够保证取出的任务是当前队列中下次执行时间最小的任务。同时注意一下优先队列中堆的顺序，堆中的顺序并不是绝对的，但要保证子节点的值要比父节点的值要大，这样就不会影响出队的顺序。 总体来说，ScheduedThreadPoolExecutor的重点是要理解下次执行时间的计算，以及优先队列的出队、入队和删除的过程，这两个是理解ScheduedThreadPoolExecutor的关键。]]></content>
      <tags>
        <tag>-Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tcp-http-socket区别]]></title>
    <url>%2F2019%2F11%2F19%2Ftcp-http-socket%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[HTTP、TCP和Socket的概念和原理及其区别一、HTTPHTTP简介 ①HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。②HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。③HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。它于1990年提出，经过几年的使用与发展，得到不断地完善和扩展。目前在WWW中使用的是HTTP/1.0的第六版，HTTP/1.1的规范化工作正在进行之中，而且HTTP-NG(Next Generation of HTTP)的建议已经提出。④HTTP协议工作于客户端-服务端架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。 HTTP的主要特点主要特点 1、简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 2、灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 3.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 4.无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 5、支持B/S及C/S模式。 HTTP的理解（此段摘抄于 Http协议与TCP协议简单理解后续）一、 TCP协议对应于传输层，而HTTP协议对应于应用层，从本质上来说，二者没有可比性。Http协议是建立在TCP协议基础之上的，当浏览器需要从服务器获取网页数据的时候，会发出一次Http请求。Http会通过TCP建立起一个到服务器的连接通道，当本次请求的数据完毕后，Http会立即将TCP连接断开，这个过程是很短的。所以Http连接是一种短连接，是一种无状态的连接。所谓的无状态，是指浏览器每次向服务器发起请求的时候，不是通过一个连接，而是每次都建立一个新的连接。如果是一个连接的话，服务器进程中就能保持住这个连接并且在内存中记住一些信息状态。而每次请求结束后，连接就关闭，相关的内容就释放了，所以记不住任何状态，成为无状态连接。 二、 随着时间的推移，html页面变得复杂了，里面可能嵌入了很多图片，这时候每次访问图片都需要建立一次tcp连接就显得低效了。因此Keep-Alive被提出用来解决效率低的问题。从HTTP/1.1起，默认都开启了Keep-Alive，保持连接特性，简单地说，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。虽然这里使用TCP连接保持了一段时间，但是这个时间是有限范围的，到了时间点依然是会关闭的，所以我们还把其看做是每次连接完成后就会关闭。后来，通过Session, Cookie等相关技术，也能保持一些用户的状态。但是还是每次都使用一个连接，依然是无状态连接 三、 为什么Http是无状态的短连接呢？而TCP是有状态的长连接？Http不是建立在TCP的基础上吗，为什么还能是短连接？现在明白了，Http就是在每次请求完成后就把TCP连接关了，所以是短连接。而我们直接通过Socket编程使用TCP协议的时候，因为我们自己可以通过代码区控制什么时候打开连接什么时候关闭连接，只要我们不通过代码把连接关闭，这个连接就会在客户端和服务端的进程中一直存在，相关状态数据会一直保存着。 四、 比较形象的描述：HTTP是轿车，提供了封装或者显示数据的具体形式;Socket是发动机，提供了网络通信的能力。对于从C#编程的角度来讲，为了方便，你可以直接选择已经制造好的轿车Http来与服务器交互。但是有时候往往因为环境因素或者其他的一些定制的请求，必须要使用TCP协议，这时就需要使用Socket编程，然后自己去处理获取的数据。就像是你用已有的发动机，自己造了一辆卡车，去从服务器交互。 HTTP都把TCP作为底层的传输协议。HTTP客户首先发起建立与服务器TCP连接。一旦建立连接，浏览器进程和服务器进程就可以通过各自的套接字来访问TCP。如前所述，客户端套接字是客户进程和TCP连接之间的“门”，服务器端套接字是服务器进程和同一TCP连接之间的“门”。客户往自己的套接字发送HTTP请求消息，也从自己的套接字接收HTTP响应消息。类似地，服务器从自己的套接字接收HTTP请求消息，也往自己的套接字发送HTTP响应消息。客户或服务器一旦把某个消息送入各自的套接字，这个消息就完全落入TCP的控制之中。TCP给HTTP提供一个可靠的数据传输服务;这意味着由客户发出的每个HTTP请求消息最终将无损地到达服务器，由服务器发出的每个HTTP响应消息最终也将无损地到达客户。 HTTP的请求方法根据HTTP标准，HTTP请求可以使用多种请求方法。 HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法。 HTTP1.1新增了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT 方法。 12345678GET 请求指定的页面信息，并返回实体主体。HEAD 类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。PUT 从客户端向服务器传送的数据取代指定的文档的内容。DELETE 请求服务器删除指定的页面。CONNECT HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。OPTIONS 允许客户端查看服务器的性能。TRACE 回显服务器收到的请求，主要用于测试或诊断。 HTTP的工作原理HTTP协议定义Web客户端如何从Web服务器请求Web页面，以及服务器如何把Web页面传送给客户端。HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。 以下是 HTTP 请求/响应的步骤： 123456789101112131415161718192021221、客户端连接到Web服务器 一个HTTP客户端，通常是浏览器，与Web服务器的HTTP端口（默认为80）建立一个TCP套接字连接。2、发送HTTP请求 通过TCP套接字，客户端向Web服务器发送一个文本的请求报文，一个请求报文由请求行、请求头部、空行和请求数据 四部分组成。3、服务器接受请求并返回HTTP响应 Web服务器解析请求，定位请求资源。服务器将资源复本写到TCP套接字，由客户端读取。一个响应由状态行、响应头部、 空行和响应数据4部分组成。4、释放连接[TCP连接](http://www.jianshu.com/p/ef892323e68f) 若connection 模式为close，则服务器主动关闭[TCP连接](http://www.jianshu.com/p/ef892323e68f)， 客户端被动关闭连接，释放[TCP连接](http://www.jianshu.com/p/ef892323e68f);若connection 模式为 keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求;5、客户端浏览器解析HTML内容 客户端浏览器首先解析状态行，查看表明请求是否成功的状态代码。然后解析每一个响应头，响应头告知以下为若干字节的 HTML文档和文档的字符集。客户端浏览器读取响应数据HTML，根据HTML的语法对其进行格式化，并在浏览器窗口中显示。 例如：在浏览器地址栏键入URL，按下回车之后会经历以下流程： 1、浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址; 2、解析出 IP 地址后，根据该 IP 地址和默认端口 80，和服务器建立[TCP连接] (http://www.jianshu.com/p/ef892323e68f); 3、浏览器发出读取文件(URL 中域名后面部分对应的文件)的HTTP 请求，该请求报文作为 [TCP 三次握手](http://www.jianshu.com/p/ef892323e68f)的第三个报文的数据发送给服务器; 4、服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器; 5、释放 [TCP连接](http://www.jianshu.com/p/ef892323e68f); 6、浏览器将该 html 文本并显示内容; 二、TCP协议TCP协议主要是在传输层，三次握手四次挥手①三次握手在TCP/IP协议中，TCP协议通过三次握手建立一个可靠的连接 三次握手 123456第一次握手：客户端尝试连接服务器，向服务器发送syn包（同步序列编号Synchronize Sequence Numbers）， syn=j，客户端进入SYN_SEND状态等待服务器确认第二次握手：服务器接收客户端syn包并确认（ack=j+1），同时向客户端发送一个SYN包（syn=k），即SYN+ACK包， 此时服务器进入SYN_RECV状态第三次握手：第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕， 客户端和服务器进入ESTABLISHED状态，完成三次握手 ②四次挥手由于TCP连接时全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭，下图描述的即是如此。 123456第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。 第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号）， Server进入CLOSE_WAIT状态。 第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。 第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1， Server进入CLOSED状态，完成四次挥手。 四次挥手 三、Scoket1、socket概念套接字（socket）是通信的基石，是支持TCP/IP协议的网络通信的基本操作单元。它是网络通信过程中端点的抽象表示，包含进行网络通信必须的五种信息：连接使用的协议，本地主机的IP地址，本地进程的协议端口，远地主机的IP地址，远地进程的协议端口。 一个Socket是一对IP地址和端口。 Socket可以看成在两个程序进行通讯连接中的一个端点，一个程序将一段信息写入Socket中，该Socket将这段信息发送给另外一个Socket中，使这段信息能传送到其他程序中。 2、socket的作用应用层通过传输层进行数据通信时，TCP和UDP会遇到同时为多个应用程序进程提供并发服务的问题。为了区别不同的应用程序进程和连接，许多计算机操作系统为应用程序与TCP／IP协议交互提供了称为套接字(Socket)的接口，区分不同应用程序进程间的网络通信和连接。 3、socket的原理3.1 socket的实现方式生成套接字，主要有3个参数：通信的目的IP地址、使用的传输层协议(TCP或UDP)和使用的端口号。Socket原意是“插座”。通过将这3个参数结合起来，与一个“插座”Socket绑定，应用层就可以和传输层通过套接字接口，区分来自不同应用程序进程或网络连接的通信，实现数据传输的并发服务。 Host A上的程序A将一段信息写入Socket中，Socket的内容被Host A的网络管理软件访问，并将这段信息通过Host A的网络接口卡发送到Host B，Host B的网络接口卡接收到这段信息后，传送给Host B的网络管理软件，网络管理软件将这段信息保存在Host B的Socket中，然后程序B才能在Socket中阅读这段信息。 3.2 Socket连接的实现方式要通过互联网进行通信，至少需要一对套接字，一个运行于客户机端，称之为ClientSocket，另一个运行于服务器端，称之为serverSocket。 根据连接启动的方式以及本地套接字要连接的目标，套接字之间的连接过程可以分为三个步骤：服务器监听，客户端请求，连接确认。 123456服务器监听：是服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态。客户端请求：是指由客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须 首先描述它要连接的服务器的套接字，指出服务器端套接字的地址和端口号，然后就向服务器端套接字提出连接请求。连接确认 ：是指当服务器端套接字监听到或者说接收到客户端套接字的连接请求，它就响应客户端套接字的请求， 建立一个新的线程，把服务器端套接字的描述发给客户端，一旦客户端确认了此描述，连接就建立好了。 而服务器端套接字继续处于监听状态，继续接收其他客户端套接字的连接请求。 3.3 Socket与TCP/IP的关系 创建Socket连接时，可以指定使用的传输层协议，Socket可以支持不同的传输层协议（TCP或UDP），当使用TCP协议进行连接时，该Socket连接就是一个TCP连接。socket则是对TCP/IP协议的封装和应用（程序员层面上）。也可以说，TPC/IP协议是传输层协议，主要解决数据 如何在网络中传输，而HTTP是应用层协议，主要解决如何包装数据。关于TCP/IP和HTTP协议的关系，网络有一段比较容易理解的介绍：“我们在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如 果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议，应用层协议有很多，比如HTTP、FTP、TELNET等，也 可以自己定义应用层协议。WEB使用HTTP协议作应用层协议，以封装HTTP文本信息，然后使用TCP/IP做传输层协议将它发到网络上。”我们平时说的最多的socket是什么呢，实际上socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口（API），通过Socket，我们才能使用TCP/IP协议。 实际上，Socket跟TCP/IP协议没有必然的联系。Socket编程接口在设计的时候，就希望也能适应其他的网络协议。所以说，Socket的出现 只是使得程序员更方便地使用TCP/IP协议栈而已，是对TCP/IP协议的抽象，从而形成了我们知道的一些最基本的函数接口，比如create、 listen、connect、accept、send、read和write等等。网络有一段关于socket和TCP/IP协议关系的说法比较容易理解：“TCP/IP只是一个协议栈，就像操作系统的运行机制一样，必须要具体实现，同时还要提供对外的操作接口。这个就像操作系统会提供标准的编程接口，比如win32编程接口一样，TCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口。”实际上，传输层的TCP是基于网络层的IP协议的，而应用层的HTTP协议又是基于传输层的TCP协议的，而Socket本身不算是协议，就像上面所说，它只是提供了一个针对TCP或者UDP编程的接口。socket是对端口通信开发的工具,它要更底层一些. 3.4 Socket与HTTP的关系 由于通常情况下Socket连接就是TCP连接，因此Socket连接一旦建立，通信双方即可开始相互发送数据内容，直到双方连接断开。但在实际网络应用中，客户端到服务器之间的通信往往需要穿越多个中间节点，例如路由器、网关、防火墙等，大部分防火墙默认会关闭长时间处于非活跃状态的连接而导致 Socket 连接断连，因此需要通过轮询告诉网络，该连接处于活跃状态。而HTTP连接使用的是“请求—响应”的方式，不仅在请求时需要先建立连接，而且需要客户端向服务器发出请求后，服务器端才能回复数据。 很多情况下，需要服务器端主动向客户端推送数据，保持客户端与服务器数据的实时与同步。此时若双方建立的是Socket连接，服务器就可以直接将数据传送给客户端；若双方建立的是HTTP连接，则服务器需要等到客户端发送一次请求后才能将数据传回给客户端，因此，客户端定时向服务器端发送连接请求，不仅可以保持在线，同时也是在“询问”服务器是否有新的数据，如果有就将数据传给客户端。 http协议是应用层的协义 有个比较形象的描述：HTTP是轿车，提供了封装或者显示数据的具体形式；Socket是发动机，提供了网络通信的能力。 总结：从上面的详细了解HTTP、TCP和Socket的概念和原理及其区别，相信对这三者有一个了解和熟悉。]]></content>
      <tags>
        <tag>-协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新特征-Lambda表达式与Stream-API]]></title>
    <url>%2F2019%2F11%2F18%2FJava8%E6%96%B0%E7%89%B9%E5%BE%81-Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%B8%8EStream-API%2F</url>
    <content type="text"><![CDATA[Java8 新特性 速度更快 更换了数据结构，内存结构（JVM） *代码更少了（Lambda表达式） * *强大的Stream API * 便于并行 fork join (串行切换并行) 最大化减少空指针异常 Optional Lambda表达式 在说 Lambda 之前，首先要说的是函数式接口。这个可以说是为了 Lambda 表达式而存在的一个东西。那么什么是函数式接口？ 函数式接口定义： 接口中只有一个抽象接口。 像 java.util.function 下的所有接口都是函数式接口。Java1.8提供@FunctionalInterface检测一个接口是否是一个函数式接口。 “-&gt;” 是 lambda 表达式的符号 左侧表示函数式接口中抽象方法的参数列表，右侧表示你对这个方法的实现 四大函数式接口我们一般对函数式接口的使用的时候，都会对其进行封装。 消费性接口​ Consumer 只有一个抽象方法名为 accept，参数列表只有一个泛型t，无返回值。参数的数据类型有类决定 1234567891011121314/** * @ClassName ConsumerTest * @Description 消费型接口， 消费字符串字段 打印输出 **/public class ConsumerTest &#123; public static void main(String[] args) &#123; test("hello",x-&gt; System.out.println(x)); &#125; public static &lt;T&gt; void test(T t, Consumer&lt;T&gt; consumer) &#123; consumer.accept(t); &#125;&#125; 输出：hello 如果需要多个参数列表的话，也可以在 java.util.function 包下找到相应的函数式接口 比如 ObjLongConsumer。其他的可以自行查看 供给型接口Supplier 只有一个抽象方法名为 get，参数列表为空，有返回值，返回值得数据类型为T。 123456789101112131415/** * @ClassName SupplerTest * @Description 供给型接口 字符串拼接 **/public class SupplerTest &#123; public static void main(String[] args) &#123; String hello = test("hello ", () -&gt; "word!"); System.out.println(hello); &#125; public static String test(String str,Supplier&lt;String&gt; supplier)&#123; return str + supplier.get(); &#125;&#125; 输出为：hello word! 如果需要返回得数据为基本数据类型，可以在 java.util.function 包下找到相应的函数式接口 比如：getAsLong 其他的可以自行查看 函数型接口​ Function&lt;T, R&gt; 只有一个抽象方法名为 apply，参数列表只有一个参数为T，有返回值，返回值的数据类型为R。（借鉴scala学习） 1234567891011121314151617/** * @ClassName FunctionTest * @Description 函数式接口 将字符串转换成大写的 **/public class FunctionTest &#123; public static void main(String[] args) &#123; String test = test("hello", x -&gt; x.toUpperCase()); System.out.println(test); &#125; public static String test(String str , Function&lt;String,String&gt; function)&#123; return function.apply(str); &#125;&#125; 输出为：HELLO 如果需要多个入参，然后又返回值的话，可以在 java.util.function 包下找到相应的函数式接口 比如 BiFunction。其他的可以自行查看 断言型接口​ 断言型又名判断型。 Predicate 只有一个抽象方法名为 test，参数列表只有一个参数为 T，有返回值，返回值类型为 boolean。 12345678910111213141516/** * @ClassName PredicateTest * @Description 断言型接口，判断字符串大小是否大于6 * @Author ouyangkang * @Date 2019-02-18 16:16 **/public class PredicateTest &#123; public static void main(String[] args) &#123; boolean hello = test("hello", x -&gt; x.length() &gt; 6); System.out.println(hello); &#125; public static boolean test(String str, Predicate&lt;String&gt; predicate)&#123; return predicate.test(str); &#125;&#125;复制代码 输出为： false Stream API​ Stream 作为 Java 8 的一大亮点，它与 java.io 包里的 InputStream 和 OutputStream 是完全不同的概念。Stream中间操作，多个中间操作可以连接起来形成一个流水线，除非流水线上触发了终止操作，否则中间不会执行任何处理！而终止操作时会一次性全部处理，称为惰性处理。要进行流操作首先要获取流。有4中方法可以获取流。 集合获取流 通过集合系列提供的stream方法和 parallelStream()（并行流）方法获取流 12345public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); // 常用获取流的方式 Stream&lt;Integer&gt; stream = list.stream();&#125; 2.通过Arrays.stream() 将数组转换成流 12345public static void main(String[] args) &#123; int[] a = new int[]&#123;1,2,3,4&#125;; IntStream stream = Arrays.stream(a); &#125; 3.通过Stream.of的方法创建流 123public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3);&#125; 4.创建无限流 123public static void main(String[] args) &#123; Stream&lt;Integer&gt; iterate = Stream.iterate(0, x -&gt; x + 2);&#125; 所有的对流的操作可以分为4种，分别为筛选与分片，映射，排序，终结（归约，收集） 中间操作主要有以下方法（此类型方法返回的都是Stream）：map (mapToInt, flatMap 等)、 filter、 distinct、 sorted、 peek、 limit、 skip、 parallel、 sequential、 unordered 终止操作主要有以下方法：forEach、 forEachOrdered、 toArray、 reduce、 collect、 min、 max、 count、 anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 iterator 筛选与分片操作有 filter ,distant,limit,skip。 filter ： 过滤操作,方法参数为*断言型接口 * 1234public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3); stream.filter(x-&gt;x != 2).forEach(x-&gt; System.out.println(x)); &#125; 输出： 1213 distinct ： 去重操作，方法无参数 limit ： 获取前几条数据，*方法参数为long * skip ： 跳过前多少条数据，然后获取后面所有的。方法参数为long 映射常用操作有 map ，flatMap。 map: 对原数据进行处理，并返回处理后的数据。 方法参数为函数型接口 1234public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3); stream.map(x-&gt;x*2).forEach(System.out::println); &#125; 输出： 123246 flatMap ： 使原来流种的原有数据一个一个整合在另一个流中。方法参数为函数型接口，但是返回值为流 12345public static void main(String[] args) &#123; List&lt;String&gt; list = Arrays.asList("a", "b", "c"); List&lt;String&gt; list2 = Arrays.asList("f","d"); list.stream().flatMap(x-&gt;list2.stream().map(y-&gt; x + y)).forEach(System.out::println);&#125; 排序常用操作有sort自然排序，合sort参数为排序器的定制排序 自然排序 1234public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3); stream.sorted().forEach(System.out::println); &#125; 输出： 123123 定制排序（(x,y)-&gt;-Integer.compare(x,y)） 12345 public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3); stream.sorted((x,y)-&gt;-Integer.compare(x,y)).forEach(System.out::println); &#125;复制代码 输出： 123321 终止操作 allMatch 检查是否匹配所有元素 方法参数为断言型接口 anyMatch 检查是否匹配所有元素 方法参数为断言型接口 noneMatch 检查是否没有匹配所有元素 方法参数为断言型接口 findFirst 返回第一个元素 无方法参数 findAny 返回当前流的任意元素 无方法参数 count 返回流中的元素总个数 无方法参数 max 返回流的最大值 无方法参数 min 返回流中的最小值 无方法参数 归约reduce : 归约 – 可以将流中的元素反复结合起来，得到一个值 12345public static void main(String[] args) &#123; List&lt;Integer&gt; list1 = Arrays.asList(1,2,3,4,5,6,7,8,9,10); Integer reduce = list1.stream().reduce(11, (x, y) -&gt; x + y); System.out.println(reduce); &#125; 输出 ： 66 收集​ 这个是非常常用的一个操作。 将流装换为其他形式。接收到一个Collector接口的实现，用于给Stream中的元素汇总的方法。用collect方法进行收集。方法参数为Collector。Collector可以由Collectors中的toList()，toSet(),toMap(Function(T,R) key,Function(T,R) value)等静态方法实现。 toList() 返回一个 Collector ，它将输入元素 List到一个新的 List 。 toMap(Function&lt;? super T,? extends K&gt; keyMapper, Function&lt;? super T,? extends U&gt; valueMapper) 返回一个 Collector ，它将元素累加到一个 Map ，其键和值是将所提供的映射函数应用于输入元素的结果。 toSet() 返回一个 Collector ，将输入元素 Set到一个新的 Set 。 eg: User类 1234567891011121314151617181920@Data@ToStringpublic class User &#123; private String name; private Integer age; private Integer salary;&#125; public static void main(String[] args) &#123; List&lt;User&gt; users = Arrays.asList(new User("张三", 19, 1000), new User("张三", 58, 2000), new User("李四", 38, 3000), new User("赵五", 48, 4000) ); List&lt;String&gt; collect = users.stream().map(x -&gt; x.getName()).collect(Collectors.toList()); Set&lt;String&gt; collect1 = users.stream().map(x -&gt; x.getName()).collect(Collectors.toSet()); Map&lt;Integer, String&gt; collect2 = users.stream().collect(Collectors.toMap(x -&gt; x.getAge(), x -&gt; x.getName())); System.out.println(collect); System.out.println(collect1); System.out.println(collect2); &#125; 输出： 123[张三, 张三, 李四, 赵五][李四, 张三, 赵五]&#123;48=赵五, 19=张三, 38=李四, 58=张三&#125; 分组​ Collectors.groupingBy()方法是 返回 Collector “由基团”上的类型的输入元件操作实现 T ，根据分类功能分组元素。这个是非常常用的操作。 比如你要对名字相同的进行分组。 groupingBy(Function&lt;? super T,? extends K&gt; classifier) eg: 123456789public static void main(String[] args) &#123; List&lt;User&gt; users = Arrays.asList(new User("张三", 19, 1000), new User("张三", 58, 2000), new User("李四", 38, 3000), new User("赵五", 48, 4000) ); Map&lt;String, List&lt;User&gt;&gt; collect3 = users.stream().collect(Collectors.groupingBy(x -&gt; x.getName())); System.out.println(collect3);&#125; 输出：{李四=[User{name=’李四’, age=38, salary=3000}], 张三=[User{name=’张三’, age=19, salary=1000}, User{name=’张三’, age=58, salary=2000}], 赵五=[User{name=’赵五’, age=48, salary=4000}]} 当然还有其他的一些比较复杂的分组操作，实际代码看业务来进行实现。 总结​ java8中的lambda表达式可能一开始用的时候还不是很熟悉，但是只要熟悉了，你会发现非常的好用，而且lambda表达式结合stream API可以进行编写自己的工具类。在平常项目中可以非常的省时间，提高写代码的效率。我现在给出一个List转Map的工具类。 123456789101112131415161718192021222324252627282930public class CollectionStream &#123; public static void main(String[] args) &#123; List&lt;User&gt; users = Arrays.asList(new User("张三", 19, 1000), new User("张三", 58, 2000), new User("李四", 38, 3000), new User("赵五", 48, 4000) ); Map&lt;Integer, Integer&gt; map = listToMap(users, x -&gt; x.getAge(), x -&gt; x.getSalary()); System.out.println(map); &#125; /** * @Description list 转map key不能相同 ，如果相同会报错。 方法对 源数据，key，value过滤null。 * @param source 源数据 * @param key * @param value * @return java.util.Map&lt;K,V&gt; **/ public static &lt;DTO, K, V&gt; Map&lt;K, V&gt; listToMap(List&lt;DTO&gt; source, Function&lt;? super DTO, ? extends K&gt; key, Function&lt;? super DTO, ? extends V&gt; value) &#123; Objects.requireNonNull(source, "source not null"); Objects.requireNonNull(key, "key not null"); Objects.requireNonNull(value, "value not null"); Map&lt;K, V&gt; map = source.stream() .filter(dto -&gt; dto != null) .filter(dto -&gt; key.apply(dto) != null) .filter(dto -&gt; value.apply(dto) != null) .collect(Collectors.toMap(key, value)); return map; &#125;&#125;]]></content>
      <tags>
        <tag>-lambda -Stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[观察者模式]]></title>
    <url>%2F2019%2F10%2F29%2F%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[模式定义观察者模式是对象行为模式，又叫发布-订阅模式（publish/subscribe）模式，源-监视器模式（source/Listener)模式。 观察者模式定义了一种一对多的依赖关系，让多个观察者对象同事监听某一个主题对象，这个主题对象在状态上发生变化时，会通知所有观察者对象，使他们能够做出相应的操作。 模式结构软件系统中，常常因为一个对象的状态发生改变时，某些其他对象做出相应的改变，做到这一点的设计方案有很多，但为了系统稳定性，选择低耦合的观察者模式，有助于系统的复用，保证高度协作。 模式描述意图：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 主要解决：一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。 何时使用：一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。 如何解决：使用面向对象技术，可以将这种依赖关系弱化。 关键代码：在抽象类里有一个 ArrayList 存放观察者们。 使用场景： 一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将这些方面封装在独立的对象中使它们可以各自独立地改变和复用。 一个对象的改变将导致其他一个或多个对象也发生改变，而不知道具体有多少对象将发生改变，可以降低对象之间的耦合度。 一个对象必须通知其他对象，而并不知道这些对象是谁。 需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 角色 抽象主题（Subject)角色：抽象主题角色把所有对观察者对象的引用保存在一个聚集（比如ArrayList)里，每一个主题都可以有任何数量的观察者。抽象主题提供一个接口（抽象类)，可以增加和删除观察者，抽象主题角色又叫抽象被观察者（Observable)角色。 具体主题（ConcreteSubject)角色：将有关状态存入具体的观察者对象；在具体主题的内部状态改变时，给所有登录订阅过的观察者发送通知。具体主题对象又叫具体被观察者（Concrete Observable）角色。 抽象观察者(Observer)角色：给所有的具体观察者定义一个接口，在得到主题的通知时更新自己，这个接口叫做更新接口。 具体观察者（Concrete Observer）角色：存储与主题的状态自恰的状态，具体观察者实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题相协调，具体观察者可以保持一个指向具体主题对象的引用。 实现代码示例： 抽象主题类 12345678910111213141516171819202122232425262728293031public abstract class Subject &#123; /** * 用来保存注册的观察者对象 */ private List&lt;Observer&gt; list = new ArrayList&lt;Observer&gt;(); /** * 注册观察者对象 * @param observer 观察者对象 */ public void attach(Observer observer)&#123; list.add(observer); System.out.println("Attached an observer"); &#125; /** * 删除观察者对象 * @param observer 观察者对象 */ public void detach(Observer observer)&#123; list.remove(observer); &#125; /** * 通知所有注册的观察者对象 */ public void nodifyObservers(String newState)&#123; for(Observer observer : list)&#123; //推模式下，需要传入状态 //拉模式下，不需要传入状态 observer.update(newState); &#125; &#125;&#125; 具体主题角色类： 1234567891011121314public class ConcreteSubject extends Subject&#123; private String state; public String getState() &#123; return state; &#125; public void change(String newState)&#123; state = newState; System.out.println("主题状态为：" + state); //状态发生改变，通知各个观察者 //在推模式下，需要传入参数 //拉模式下，不需要传入参数 this.nodifyObservers(state);//调用父类定义方法 &#125;&#125; 抽象观察者角色类： 1234567public interface Observer &#123; /** * 更新接口 * @param state 更新的状态 */ public void update(String state);&#125; 具体观察者角色类： 123456789101112public class ConcreteObserver implements Observer &#123; //观察者的状态 private String observerState; @Override public void update(String state) &#123; /** * 更新观察者的状态，使其与目标的状态保持一致 */ observerState = state; System.out.println("状态为："+observerState); &#125;&#125; 客户端： 123456789101112public class Client &#123; public static void main(String[] args) &#123; //创建主题对象 ConcreteSubject subject = new ConcreteSubject(); //创建观察者对象 Observer observer = new ConcreteObserver(); //将观察者对象登记到主题对象上 subject.attach(observer); //改变主题对象的状态 subject.change("new state"); &#125;&#125; 推模式和拉模式推模式上面的例子就是典型的推模式，主题对象向观察者推送详细信息。 拉模式主题对象在通知观察者的时候，只传递少量信息。如果观察者需要更具体的信息，由观察者主动到主题对象中获取，相当于是观察者从主题对象中拉数据。一般这种模型的实现中，会把主题对象自身通过update()方法传递给观察者，这样在观察者需要获取数据的时候，就可以通过这个引用来获取了。 调用观察者的方法时，不需要传入参数 观察者模式与订阅模式 观察者注册到目标；目标发生改变时，调用观察者方法 订阅者把自己想订阅的事件注册到调度中心，当该事件触发时候，发布者发布该事件到调度中心（顺带上下文），由调度中心统一调度订阅者注册到调度中心的处理代码 总结 从两张图片可以看到，最大的区别是调度的地方。 虽然两种模式都存在订阅者和发布者（具体观察者可认为是订阅者、具体目标可认为是发布者），但是观察者模式是由具体目标调度的，而发布/订阅模式是统一由调度中心调的，所以观察者模式的订阅者与发布者之间是存在依赖的，而发布/订阅模式则不会。 两种模式都可以用于松散耦合，改进代码管理和潜在的复用。]]></content>
      <tags>
        <tag>-设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基本注解]]></title>
    <url>%2F2019%2F10%2F28%2FJava%E5%9F%BA%E6%9C%AC%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Annotation的概念与作用元数据（MeteData）也就是Annotation，这是一种代码里的特殊标志，可在编译，类加载，运行时被读取。 Annotation就像修饰符一样，可用于修饰包，类，构造器，方法， 成员变量，参数，局部变量的声明，这些信息被存储到Annotation的“name=value”对中 Annotation是一个接口，程序通过反射来获取指定程序元素的Annotation对象，然后通过Annotation对象来获取注释里的元数据 基本Annotation 四种基本的Annotation如下： @Override @Deprecated @SuppressWarinings @SafeVarargs @Override注解的功能与用法@Override用来制定方法覆盖度，强制一个子类必须覆盖父类的方法；用于避免普通子类没覆盖父类抽象方法，方法名写错 @Deprecated注解的功能与用法@Deprecated用于表示某个程序元素（方法，类等）已过时，当使用过时类，方法时，会发出警告信息 @SuppressWarinings注解的功能与用法@SuppressWarinings指示被该Annotation修饰的程序元素（以及该程序元素的所有子元素）取消显示指定的编译器错误 @SafeVarargs注解的功能与用法@SafeVarargs用于解决“堆污染”警告 “堆污染”：当把一个不带泛型的对象赋值给一个带泛型的变量时，往往会产生堆污染 JDK的元Annotation上面四个基本注解是在java.lang包下的， 此外还在java.lang.annotation包下提供4个Meta Annotation，这四个Annotation都用于修饰其他的Annotation的定义 @Retention @Target @Document @Inherited @Retention注解的功能与用法@Retention只能用于修饰一个Annotation定义，指定被修饰的Annotation可以保留多长时间 @Retention包含一个RetentionPolicy类型的value成员变量，使用@Retention必须为改对象指定值 value值分别有： RetentionPolicy.CLASS:默认值，记录在class文件中 RetentionPolicy.RUNTIME:JVM保留该Annotation，程序可以通过反射获取该Annotation信息 RetentionPolicy.SOURCE:保留源代码中，编译器丢弃该Annotation @Target注解的功能与用法@Target用于修饰一个Annotation定义，用于指定被修饰的Annotation能用于修饰哪些程序单元 value值分别有： ElementType.ANNOTATION_TYPE:指定该策略的Annotation只能用于修饰Annotation ElementType.CONSTRUCTOR:只能修饰构造器 ElementType.FIFLD:只能修饰成员变量 ElementType.LOCAL_VARIABLE:只能修饰局部变量 ElementType.METHOD:修饰方法定义 ElementType.PACKAGE:修饰包的定义 ElementType.PARAETER:修饰参数 ElementType.TYPE:可以修饰类、接口（包括注解类型）或枚举定义 @Document注解的功能与用法@Document用于该Annotation将被javadoc工具提取成文档 @Inherited注解的功能与用法@Inherited元Annotation指定被它修饰的Annotation将具有继承性。 如果某个类用包含@Inherited的Annotation，则该子类将自动也使用该Annotation 自定义Annotation定义一个新的Annotation类型使用@interface关键字。 1234public @interface TESTAnnotation&#123; ...&#125; 可定义Annotation的成员变量，并且该变量可以指定初始值，用关键字default 12345public @interface MyTag&#123; String name() default "zhengkai"; int age() default 18; &#125; 该Annotation定义俩个成员变量，并且已经有初始值 **当开发者使用Annotation修饰类，方法，Filed等成员之后，这些Annotation并不会生效，必须有开发者提供相应的工具来提取并处理Annotation信息 运行时Annotationjava.lang.reflect包下提供了获取Annotation的AnnotationElenment接口，程序可调用如下三个方法获取Annotation信息 getAnnotation(Class annotationClass)：获得程序元素的注解，不存在返回null Annotations[]：获取程序元素上所有的注解 isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass):判断该程序元素是否存在注解]]></content>
      <tags>
        <tag>-注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive数据仓库基础知识]]></title>
    <url>%2F2019%2F10%2F22%2FHive%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[数据仓库Hive产生背景MapReduce编程门槛高，无法及时应对需求的变更 传统RDBMS（关系型数据库）人员的需求，HDFS上的文件并没有schema的概念 可通过Hive进行大数据的处理 Hive概述有Facebook开源，用于解决海量结构化日志的数据统计问题 构建在Hadoop之上的数据仓库（计算能力，存储能力，可应付数据的暴增） Hive提供的SQL查询语言：HQL 底层支撑多种不同的执行引擎 Hive底层执行引擎支持：MR/Tez/Spark（用户不感知） ###为什么要使用Hive 简单，容易上手 为超大数据集设计的计算/扩展能力 同一的元数据管理：Hive数据是存放在HDFS上，元数据信息（记录数据(HDFS数据)的数据）是存放在MySQL中 SQL on Hadoop:Hive,Spark,SQL,impala… Hive是一个离线框架，不适合实时查询 Hive体系架构Hive 在Hadoop生态中的位置 体系架构图： client：shell、thrift/jdbc(server/jdbc)、webUI(HUE/Zeppelin) metastore:==&gt;MySQL database:name/location/owner... table:name、location、owner、column、name/type...Hive：写SQL翻译成MapReduce，放入到Hadoop Hive部署架构 测试环境 客户端把SQL提交Hive引擎，元数据信息可存放在Derby中（只能进行单客户端的操作，就是单session）即使是测试环境也不推荐使用，因此只能选择MySQL 生产环境：为了防止MySQL错误导致无法进行获取元数据信息，因此得有主备MySQL，主备MySQL会进行切换。（解决MySQL单点问题） Hadoop集群：DN、NM、NN、RM Hive提交到RM上，Hadpoop集群有很多节点，Hive是一个客户端，并不涉及集群的概念 Hive与RDBMS的区别 支持的：都支持分布式 区别的：Hive不适合立马进行查询 Hive部署及快速入门包：hive-1.*.0cdh.5 *. *tar-gz *bin目录：脚本 *conf目录：配置 1 下载 2解压的 ~/app 3添加Hive-HOME到系统环境变量 4修改配置 5拷贝MySQL驱动包 6预先下载MySQL数据库 Hive DDL详解可以创建一张表，把数据加入到表中，对数据的各种维度的分析 create/delete/alter… Hive数据抽象/结构 database HDFS一个目录 table HDFS一个目录 data文件 partition分区表 HDFS一个目录 bucket分桶 HDFS一个文件 创建数据库1234CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name [COMMENT database_comment] [LOCATIO hdfs_path] [WITH DBPROPERTIES (property_name=property_value,...)]; 创建表12345678910111213CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name [(col_name data_type[COMMENT col_comment], ... [constraint_specification])] [COMMENT table_comment] [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] [ROW FORMAT row_format] [STORED AS file_format] [LOCATION hdfs_path] [TBLPROPERTIES (property_name=property_value, ...)] [AS select_statement];CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name LIKE existing_table_or_view_name [LOCATION hdfs_path]; 各项参数说明： 1CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常，一般也可以不加这个IF NOT EXISTS语句，最多抛出错误。 2 [constraint_specification]可选项： [ PRIMARY KEY|UNIQUE|NOT NULL|DEFAULT [default_value] 3 [COMMENT table_comment] 可选项：COMMENT 后面跟的字符串是给表字段或者表内容添加注释说明的 4 [PARTITIONED BY ] 可选项：PARTITIONED BY其实是给表做分区，决定了表是否是分区表。（Hive中所谓分区表就是将表里新增加一个字段，就是分区的名字，这样你在操作表中的数据时，可以按分区字段进行过滤） 5 [CLUSTERED BY ]可选项：CLUSTERED BY对于每一个表（table）或者分区， Hive可以进一步组织成桶，也就是说桶是更为细粒度的数据范围划分。Hive也针对某一列进行桶的组织。Hive采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中 6 [ROW FORMAT]可选项：存储表格式 7 [STORED AS] 可选项：hive存储的三种文件格式 8 [LOCATION AS] 可选项：LOCATION 其实是定义hive表的数据在hdfs上的存储路径，一般管理表（内部表不不要自定义），但是如果定义的是外部表，则需要直接指定一个路径。实际上不指定也没事，会使用默认路径 部分详解： 使用PARTITIONED BY子句创建分区表。一个表可以具有一个或多个分区列，并为分区列中的每个不同值组合创建一个单独的数据目录。此外，可以使用CLUSTERED BY列对表或分区进行存储，并且可以通过SORT BY列在该存储区中对数据进行排序。这样可以提高某些查询的性能。 eg: 12345678CREATE TABLE page_view(viewTime INT, userid BIGINT, page_url STRING, referrer_url STRING, ip STRING COMMENT &apos;IP Address of the User&apos;) COMMENT &apos;This is the page view table&apos; PARTITIONED BY(dt STRING, country STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\001&apos;STORED AS SEQUENCEFILE; 上面的语句创建带有viewTime，userid，page_url，referrer_url和ip列（包括注释）的page_view表。该表也被分区，数据存储在序列文件中,文件中的数据格式由ctrl-A分隔字段，由换行分隔行。 重命名表1ALTER TABLE table_name RENAME TO new_table_name; ####更改表属性 1`ALTER TABLE table_name SET TBLPROPERTIES table_properties;` `table_properties:`` ``: (property_name = property_value, property_name = property_value, ... )` table_properties : (property_name = property_value, property_name = property_value, … ) TBLPROPERTIES:允许您使用自己的元数据键/值对标记表定义;还存在一些预定义的表属性，由Hive自动添加和管理的last_modified_user和last_modified_time。 修改表注释：要更改表的注释，您必须更改的comment属性TBLPROPERTIES： 1`ALTER TABLE table_name SET TBLPROPERTIES (``&apos;comment&apos;` `= new_comment);` 重命名现有表的列1`ALTER TABLE old_table_name REPLACE COLUMNS (col1 TYPE, ...);` 将列添加到现有表1ALTER TABLE tab1 ADD COLUMNS (c1 INT COMMENT &apos;a new int column&apos;, c2 STRING DEFAULT &apos;def val&apos;); 删除表1`DROP TABLE pv_users;` 删除表分区(更改表以删除分区)：1`ALTER TABLE pv_users DROP PARTITION (ds=``&apos;2008-08-08&apos;``)` Hive查询操作记录在Select中，而插入操作记录在将数据从查询插入Hive表和从查询将数据写入文件系统中。 简单查询1`INSERT OVERWRITE TABLE user_active``SELECT user.*``FROM user``WHERE user.active = ``1``;` 请注意，与SQL不同，我们总是将结果插入表中。也可以将其转储到本地文件中。 也可以在Beeline 或Hive CLI中运行以下查询 ： 123SELECT user.*FROM userWHERE user.active = ``1``; 基于分区的查询1`INSERT OVERWRITE TABLE xyz_com_page_views``SELECT page_views.*``FROM page_views``WHERE page_views.date &gt;= ``&apos;2008-03-01&apos;` `AND page_views.date &lt;= ``&apos;2008-03-31&apos;` `AND`` ``page_views.referrer_url like ``&apos;%xyz.com&apos;``;` 系统根据分区列上的where子句条件自动确定要在查询中使用的分区。例如，为了获取域xyz.com引用的03/2008月份的所有page_views 请注意，此处使用page_views.date，因为该表（上面）是使用PARTITIONED BY（date DATETIME，country STRING）定义的；如果您给分区命名不同，请不要期望.date发挥您的想法！ 连接查询1234INSERT OVERWRITE TABLE pv_usersSELECT pv.*, u.gender, u.ageFROM user u JOIN page_view pv ON (pv.userid = u.id)WHERE pv.date = &apos;2008-03-03&apos;; 可以使用LEFT OUTER，RIGHT OUTER或FULL OUTER关键字限定联接，以指示外部联接的类型（保留的左侧，保留的右侧或两侧保留） 检查另一个表中是否存在键，用户可以使用LEFT SEMI JOIN]]></content>
      <tags>
        <tag>-Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[swagger2学习]]></title>
    <url>%2F2019%2F10%2F16%2Fswagger2%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[一、Swagger简介背景​ 在现在的开发流程中，为了最大程度实现前后端的分离，通常后端接口只提供数据接口，由前端通过Ajax请求从后端获取数据并进行渲染再展示给用户。我们用的最多的方式就是后端会返回给前端一个JSON字符串，前端解析JSON字符串生成JavaScript的对象，然后再做处理。 演化非Restful接口的支持 一个方法对应于一个端口方法映射，通常只有GET/POST方法对应CRUD，后期维护成本大，通常标签有： ​ @Controller 标识一个类为控制器。 @RequestMapping URL的映射。 @ResponseBody 返回结果转换为JSON字符串。 @RequestBody 表示接收JSON格式字符串参数。 Restful API设计 Restful API是一种编程风格，比起传统的通过get/post方法的接口设计，Restful API的设计则通过HTTP的方法来表示CRUD相关的操作。 123456接口URL | HTTP方法 | 接口说明-------| -------- |-------/article | POST | 保存文章/article/&#123;id&#125; | GET | 查询文章列表/article/&#123;id&#125; | DELETE | 删除文章/article/&#123;id&#125; | PUT | 修改文章 区别： ​ ①类上通常使用@RestController注解（spring4提供），表示返回Json数据的注解，支持Restful控制器。 ​ ②/article/{id}具有三个相同的URL映射，这在@Controller标识的类中是不允许出现的，而这通过method来进行区分，produces的作用是表示返回结果的类型是JSON。 ③@PathVariable这个注解（Spring MVC提供），作用是表示该变量的值是从访问路径中获取。 简介Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。总体目标是使客户端和文件系统作为服务器以同样的速度来更新。文件的方法，参数和模型紧密集成到服务器端的代码，允许API来始终保持同步。Swagger 让部署管理和使用功能强大的API从未如此简单。 二、Swagger与Spring boot集成①、导入相应jar包12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt; ②、基本信息配置12345678910111213141516171819202122232425262728293031323334353637@Configuration@EnableSwagger2public class SwaggerConfig &#123; @Bean public Docket docket()&#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() //当前包路径 .apis(RequestHandlerSelectors.basePackage("com.bmsoft.dc.dodp")) .paths(PathSelectors.any()).build(); &#125; @Bean public Docket docket1()&#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .groupName("caozifu") .select() .apis(RequestHandlerSelectors.basePackage("com.bmsoft.dc.dodp")) .paths(PathSelectors.any()).build(); &#125; /** * 构建api文档的详细信息函数 * */ private ApiInfo apiInfo()&#123; return new ApiInfoBuilder() //页面标题 .title("离线开发平台Restful接口管理") //版本号 .version("1.0") //描述 .description("API 描述") .build(); &#125;&#125; 标签说明： @Configuration是表示这是一个配置类，是JDK自带的注解 @EnableSwagger2的作用是启用Swagger2相关功能。 ​ 配置类里面我么实例化了一个Docket对象，这个对象主要包括三个方面的信息： ​ （1）整个API的描述信息，即ApiInfo对象包括的信息，这 部分信息会在页面上展示。 （2）指定生成API文档的包名。 （3）指定生成API的路径。按路径生成API可支持四种模式：任何路径都生成(any)、任何路径都不生成 (none)以及正则匹配(regex)和ant 模式匹配四种方式 ③、编写方法及其参数描述​ 编写相应的方法，并应方法中做出相应的参数描述，具体标签有： @ApiOperation 用在方法上，说明方法的作用，每一个url资源的定义,使用方式： 属性名称 备注 value url的路径值 ​ *tags 接口的标签，相同标签的接口会在一个标签页下展示。 notes 接口详细说明，展示在接口的详情页。 httpMethod 支持的HTTP的方法。 @ApiImplicitParams，@ApiImplicitParam的容器，可包含多个@ApiImplicitParam注解 @ApiImplicitParam，请求参数属性配置： 属性名称 备注 name 参数名称 value 参数说明 required 是否必须 dataType 数据类型 @ApiResponse，返回结果属性配置： 属性名称 备注 code 返回结果的编码 message 返回结果的说明 response 返回结果对应的类 示例 12345678910111213@ApiOperation(value = &quot;更新文章&quot;, notes = &quot;更新文章内容&quot;, tags = &quot;Article&quot;,httpMethod = &quot;PUT&quot;) @ApiImplicitParams(&#123; @ApiImplicitParam(name = &quot;id&quot;, value = &quot;文章ID&quot;, required = true, dataType = &quot;Long&quot;), @ApiImplicitParam(name = &quot;title&quot;, value = &quot;文章标题&quot;, required = false, dataType = &quot;String&quot;), @ApiImplicitParam(name = &quot;summary&quot;, value = &quot;文章摘要&quot;, required = false, dataType = &quot;String&quot;), @ApiImplicitParam(name = &quot;status&quot;, value = &quot;发布状态&quot;, required = false, dataType = &quot;Integer&quot;) &#125;) @RequestMapping(value = &quot;/article/&#123;id&#125;&quot;, method = PUT, produces = &quot;application/json&quot;) public WebResponse&lt;?&gt; updateArticle(@PathVariable Long id,@RequestBody Article article)&#123; article.setId(id); articleService.updateArticle(article); return WebResponse.getSuccessResponse(new HashMap&lt;&gt;()); &#125; 启动Spring boot，然后访问：http://127.0.0.1:8080/swagger-ui.html即可看到如下结果 页面显示： 其他常用标签 @API注解:用在类上，说明该类的作用。可以标记一个Controller类做为swagger 文档资源 12&gt; @Api(value = "/user", description = "Operations about user")&gt; 属性名称 备注 value url的路径值 tags 如果设置这个值、value的值会被覆盖 description 对api资源的描述 description 对api资源的描述 @ApiModel：描述一个Model的信息（这种一般用在post创建的时候，使用@RequestBody这样的场景，请求参数无法使用 @ApiModelProperty：描述一个model的属性]]></content>
      <tags>
        <tag>-swagger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis-plus学习]]></title>
    <url>%2F2019%2F10%2F14%2Fmybatis-plus%E4%B8%AA%E4%BA%BA%E8%A7%81%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[MyBatis-Plus（简称 MP）是一个 MyBatis 的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。mybatis-plus的特性​ ①无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑​ ②损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作​ ③强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求​ ④支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错​ ⑤支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题​ ⑥支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作​ ⑦支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ）​ ⑧内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用​ ⑨内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询​ ⑩分页插件支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer2005、SQLServer 等多种数据库 主要核心知识：Mapper CRUD接口说明: 通用 CRUD 封装BaseMapper接口，为 Mybatis-Plus 启动时自动解析实体表关系映射转换为 Mybatis 内部对象注入容器 泛型 T 为任意实体对象 参数 Serializable 为任意类型主键 Mybatis-Plus 不推荐使用复合主键约定每一张表都有自己的唯一 id 主键 对象 Wrapper 为 条件构造器 实际上是在Mybatis的mapper扫描文件进行了CURD增强， CRUD方法基本是insert、delete（ById,ByMap、BatchIds)、 update（ById)、select（ById、BathchIds、ByMap、One、Count、List、Maps、Objs、Page、MapsPage) 基本是通过Id,条件进行CRUD Service CRUD接口说明: 通用 Service CRUD 封装IService接口，进一步封装 CRUD 采用 get 查询单行 remove 删除 list 查询集合 page 分页 前缀命名方式区分 Mapper 层避免混淆， 泛型 T 为任意实体对象 建议如果存在自定义通用 Service 方法的可能，请创建自己的 IBaseService 继承 Mybatis-Plus 提供的基类 对象 Wrapper 为 条件构造器 条件构造器说明: 介绍 上图绿色框为抽象类abstract 蓝色框为正常class类，可new对象 黄色箭头指向为父子类关系，箭头指向为父类 方法入参boolean condition表示该条件是否加入最后生成的sql中 方法均为从上往下补全个别boolean类型的入参,默认为true 出现的泛型Param均为Wrapper的子类实例(均具有AbstractWrapper的所有方法) 方法在入参中出现的R为泛型,在普通wrapper中是String,在LambdaWrapper中是函数(例:Entity::getId,Entity为实体类,getId为字段id的getMethod) 方法入参中的R column均表示数据库字段,当R具体类型为String时则为数据库字段名(字段名是数据库关键字的自己用转义符包裹!)!而不是实体类数据字段名!!!,另当R具体类型为SFunction时项目runtime不支持eclipse自家的编译器!!! 举例均为使用普通wrapper,入参为Map和List的均以json形式表现! 使用中如果入参的Map或者List为空,则不会加入最后生成的sql中!!! 有任何疑问就点开源码看,看不懂函数的lambda 表达式详解 QueryWrapper###说明:继承自 AbstractWrapper ,自身的内部属性 entity 也用于生成 where 条件及 LambdaQueryWrapper, 可以通过 new QueryWrapper().lambda() 方法获取 SELECT 123select(String... sqlSelect)select(Predicate&lt;TableFieldInfo&gt; predicate)select(Class&lt;T&gt; entityClass, Predicate&lt;TableFieldInfo&gt; predicate) 设置查询字段 说明: 以上方分法为两类.第二类方法为:过滤查询字段(主键除外),入参不包含 class 的调用前需要wrapper内的entity属性有值! 这两类方法重复调用以最后一次为准 例: select(&quot;id&quot;, &quot;name&quot;, &quot;age&quot;) 例: select(i -&gt; i.getProperty().startsWith(&quot;test&quot;)) 使用MP入门： ①定义一个JavaBean对象，用于封装数据库信息 ②定义一个（BeanName)Mapper接口，该接口继承BaseMapper 并传入相对应的Bean对象 ③可直接在查询地方定义一个查询构造器Wrapper实现类（QueryWrapper或LambdaQueryWrapper）用于复杂查询，将其传入实例化（容器中拿）的mapper的方法条件中，获取查询后的数据。]]></content>
      <tags>
        <tag>-mybatis-plus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virtualBox 进行Net后SSH注意事项]]></title>
    <url>%2F2019%2F10%2F05%2FvirtualBox-%E8%BF%9B%E8%A1%8CNet%E5%90%8ESSH%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[因为学习需要，为了更加便捷，抛弃了使用笨重的VMware，而选择了轻携的Oracle virtualBox，但是恶梦也是从这里开始了，倒腾了半天，也总算解决了这个问题！ 首先声明：这个问题针对校园网锐捷客户端而言，锐捷不允许多IP，在倒腾了一会后，发现如果选择桥接模式，再进行不同物理网卡与虚拟网卡进行Internet网络共享后，锐捷客户端总是抛断网搞破坏，因此只能选择，Net连接（在VMware中也是选择Net连接 的我，对Net方式较为熟悉） 恶性循环： 如果选择桥接模式，只能ping通主机，无法ping通其他IP与域名 如果选择 桥接，且进行物理网卡与虚拟网卡（需下载）进行Internet网络共享，则锐捷断网警告 如果选择Net连接，网络正常ping通，但主机ssh访问虚拟机受限。 本着熟悉入手，减少配置，选择了第三点，用Net进行网络配置 在virtualBox NAT 模式下，主机ssh访问虚拟机配置,总是显示失败 选择虚拟机-&gt;设置-&gt;网络-&gt;高级-&gt;端口转发： 协议：TCP 主机IP:127.0.0.1 主机端口：1234 子系统IP：（虚拟机IP） 子系统端口：22（SSH监听端口） 完成配置后，在主机上确认是否已启动1234端口监听： 登录成功：]]></content>
      <tags>
        <tag>-virtualBox -知识漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leecodede_139单词拆分]]></title>
    <url>%2F2019%2F10%2F04%2FLeecodede-139%E5%8D%95%E8%AF%8D%E6%8B%86%E5%88%86%2F</url>
    <content type="text"><![CDATA[给定一个非空字符串 s 和一个包含非空单词列表的字典 wordDict*，判定 *s 是否可以被空格拆分为一个或多个在字典中出现的单词。 说明： 拆分时可以重复使用字典中的单词。 你可以假设字典中没有重复的单词。 示例 1： 输入: s = “leetcode”, wordDict = [“leet”, “code”]输出: true*解释: 返回 true 因为 “leetcode” 可以被拆分成 “leet code” 示例 2： 输入: s = “applepenapple”, wordDict = [“apple”, “pen”]输出: true解释: 返回 true 因为 “applepenapple” 可以被拆分成 “apple pen apple”。 注意你可以重复使用字典中的单词。 示例 3： 输入: s = “catsandog”, wordDict = [“cats”, “dog”, “sand”, “and”, “cat”]输出: false-* 该题可以采用暴力法 、广度优先搜索、动态规划 实际上三者都有一个共同点，即：应该先找出前半部分是否含有，再进行递归或者递推 动态规划三要素：（初始）状态，状态转移方程，终止条件 其实动态规划套路就是记忆存储，自底递推，找到状态转移 但是这道题，可以想象其实可以把一个单词（而不是一个下标），当初一个状态，来进行状态的转移 eg: catdog—&gt;cat(true)+dog(exit) 12345678910111213141516171819class Solution &#123; public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123; Set&lt;String&gt; set=new HashSet(wordDict); boolean[] dp=new boolean[s.length()+1]; dp[0]=true; //注意界限：i&lt;=s.length() for(int i=0;i&lt;=s.length();i++)&#123; for(int j=0;j&lt;i;j++)&#123; //想象成：dp[leet]+contains(code) ? true if(dp[j] &amp;&amp; set.contains(s.substring(j,i)))&#123; dp[i]=true; break; &#125; &#125; &#125; return dp[s.length()]; &#125; &#125; Leecode官方： 这个方法的想法是对于给定的字符串（ss）可以被拆分成子问题 s1s1 和 s2s2 。如果这些子问题都可以独立地被拆分成符合要求的子问题，那么整个问题 ss 也可以满足。也就是，如果 “\text{catsanddog}catsanddog” 可以拆分成两个子字符串 “\text{catsand}catsand” 和 “\text{dog}dog” 。子问题 “\text{catsand}catsand” 可以进一步拆分成 “\text{cats}cats” 和 “\text{and}and” ，这两个独立的部分都是字典的一部分，所以 “\text{catsand}catsand” 满足题意条件，再往前， “\text{catsand}catsand” 和 “\text{dog}dog” 也分别满足条件，所以整个字符串 “\text{catsanddog}catsanddog” 也满足条件。 现在，我们考虑 \text{dp}dp 数组求解的过程。我们使用 n+1n+1 大小数组的 \text{dp}dp ，其中 nn 是给定字符串的长度。我们也使用 2 个下标指针 ii 和 jj ，其中 ii 是当前字符串从头开始的子字符串（s’s）的长度， jj 是当前子字符串（s’s ′）的拆分位置，拆分成 s’(0,j)s ′ (0,j) 和 s’(j+1,i)s ′ (j+1,i) 。 为了求出 \text{dp}dp 数组，我们初始化 \text{dp}[0]dp[0] 为 \text{true}true ，这是因为空字符串总是字典的一部分。 \text{dp}dp 数组剩余的元素都初始化为 \text{false}false 。 我们用下标 ii 来考虑所有从当前字符串开始的可能的子字符串。对于每一个子字符串，我们通过下标 jj 将它拆分成 s1’s1 ′ 和 s2’s2 ′ （注意 ii 现在指向 s2’s2 ′ 的结尾）。为了将 \text{dp}[i]dp[i] 数组求出来，我们依次检查每个 \text{dp}[j]dp[j] 是否为 \text{true}true ，也就是子字符串 s1’s1 ′ 是否满足题目要求。如果满足，我们接下来检查 s2’s2 ′ 是否在字典中。如果包含，我们接下来检查 s2’s2 ′是否在字典中，如果两个字符串都满足要求，我们让 \text{dp}[i]dp[i] 为 \text{true}true ，否则令其为 \text{false}false 。]]></content>
      <tags>
        <tag>-Leecode -算法思路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二篇博客]]></title>
    <url>%2F2019%2F10%2F04%2F%E7%AC%AC%E4%BA%8C%E7%AF%87%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[第一次写博客，希望能记录学习的点点滴滴 来年春招力争大厂offer上岸 第二篇博客]]></content>
      <tags>
        <tag>-hexo</tag>
      </tags>
  </entry>
</search>
