<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Multipartfile深度分析]]></title>
    <url>%2F2020%2F03%2F30%2FMultipartfile%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[什么是Multipartfile MultipartFile是spring框架中的一个接口，为了便于接收客户端上传文件信息进行封装，其代表HTML中form data方式上传的文件，包含二进制数据+文件名称 实际生产中，通常我们可以在controller定义方法使用MultipartFile接收form表单提交的文件，然后将MultipartFile可以转化成一个文件。 1、Multipartfile工作原理按照Multipart规定的格式将文件名和文件内容在请求中发送到服务器中 服务器从请求流中得到文件名和文件内容放入到Multipart定义的类中，服务器处理请求中再在服务器生成相关的文件目录，并将内容保存到服务器中去 该文件内容储在内存中或临时存储在磁盘上。在任何一种情况下，如果需要，用户负责将文件内容复制到会话级或持久性存储。临时存储将在请求处理结束时清除。 2、Multipartfile方法 3、Multipartfile与File相互转化3.1、File转MultipartFile(了解即可)1、使用org.springframework.mock.web.MockMultipartFile 需要导入spring-test.jar 12345678910public static void main(String[] args) throws Exception &#123; String filePath = "F:\\test.txt"; File file = new File(filePath); FileInputStream fileInputStream = new FileInputStream(file); // MockMultipartFile(String name, @Nullable String originalFilename, @Nullable String contentType, InputStream contentStream) // 其中originalFilename,String contentType 旧名字，类型 可为空 // ContentType.APPLICATION_OCTET_STREAM.toString() 需要使用HttpClient的包 MultipartFile multipartFile = new MockMultipartFile("copy"+file.getName(),file.getName(),ContentType.APPLICATION_OCTET_STREAM.toString(),fileInputStream); System.out.println(multipartFile.getName()); // 输出copytest.txt &#125; 直接用MultipartFile的初始化方法即可将File转化为Multipartfile（实际就是对输入字节流进行转化） 2、使用CommonsMultipartFile 123456789101112131415161718public static void main(String[] args) throws Exception &#123; String filePath = "F:\\test.txt"; File file = new File(filePath); // 需要导入commons-fileupload的包 FileItem fileItem = new DiskFileItem("copyfile.txt", Files.probeContentType(file.toPath()),false,file.getName(),(int)file.length(),file.getParentFile()); byte[] buffer = new byte[4096]; int n; try (InputStream inputStream = new FileInputStream(file); OutputStream os = fileItem.getOutputStream())&#123; while ( (n = inputStream.read(buffer,0,4096)) != -1)&#123; os.write(buffer,0,n); &#125; //也可以用IOUtils.copy(inputStream,os); MultipartFile multipartFile = new CommonsMultipartFile(fileItem); System.out.println(multipartFile.getName()); &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; &#125; 当我们需要操作File类方法时，我们需要将Multipartfile转化为File类型， 3.2、MultipartFile转FileMultipartFile转File有几种方法，通过上面的转化可知，可利用逆向方法转化，最终会在目录下生成一个文件，需要对文件进行删除，也可以利用MultipartFile中的方法transferTo (本质上还是使用了流 只不过是封装了步骤)会生成文件，最后如果不需要文件该文件，要进行删除。 1、使用File转MultipartFile的逆过程，这个方法会在根目录生成一个文件，需要删除该文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public static void main(String[] args) throws Exception &#123; int n; // 得到MultipartFile文件，实际生产中是文件上传中获得即可 MultipartFile multipartFile = getFile(); File f = null; // 输出文件的新name 就是指上传后的文件名称 System.out.println("getName:"+multipartFile.getName()); // 输出源文件名称 就是指上传前的文件名称 System.out.println("Oriname:"+multipartFile.getOriginalFilename()); // 创建文件 f = new File(multipartFile.getOriginalFilename()); try ( InputStream in = multipartFile.getInputStream(); OutputStream os = new FileOutputStream(f))&#123; // 得到文件流。以文件流的方式输出到新文件 // 可以使用byte[] ss = multipartFile.getBytes();代替while byte[] buffer = new byte[4096]; while ((n = in.read(buffer,0,4096)) != -1)&#123; os.write(buffer,0,n); &#125; // 读取文件第一行 BufferedReader bufferedReader = new BufferedReader(new FileReader(f)); System.out.println(bufferedReader.readLine()); // 输出路径 bufferedReader.close(); &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; // 输出file的URL System.out.println(f.toURI().toURL().toString()); // 输出文件的绝对路径 System.out.println(f.getAbsolutePath()); // 操作完上的文件 需要删除在根目录下生成的文件 File file = new File(f.toURI()); if (file.delete())&#123; System.out.println("删除成功"); &#125;else &#123; System.out.println("删除失败"); &#125; &#125; /** *为了测试需要，实际生产中是文件上传后的MultipartFile文件即可 * @Description 返回MultipartFile文件 * @return org.springframework.web.multipart.MultipartFile */ public static MultipartFile getFile() throws IOException &#123; String filePath = "F:\\test.txt"; File file = new File(filePath); FileItem fileItem = new DiskFileItem("copyfile.txt", Files.probeContentType(file.toPath()),false,file.getName(),(int)file.length(),file.getParentFile()); byte[] buffer = new byte[4096]; int n; try (InputStream inputStream = new FileInputStream(file); OutputStream os = fileItem.getOutputStream())&#123; while ( (n = inputStream.read(buffer,0,4096)) != -1)&#123; os.write(buffer,0,n); &#125; //也可以用IOUtils.copy(inputStream,os); MultipartFile multipartFile = new CommonsMultipartFile(fileItem); System.out.println(multipartFile.getName()); return multipartFile; &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; return null; &#125; 2、使用transferTo (本质上还是使用了流 只不过是封装了步骤)会生成文件，最后不需要文件要删除 123456789101112131415161718public static void main(String[] args) throws Exception &#123; String path = "F:\\demo\\"; File file = new File(path,"demo.txt"); // 得到MultipartFile文件 MultipartFile multipartFile = getFile(); /*byte[] ss = multipartFile.getBytes(); OutputStream os = new FileOutputStream(file); os.write(ss); os.close();*/ multipartFile.transferTo(file); // 读取文件第一行 BufferedReader bufferedReader = new BufferedReader(new FileReader(file)); System.out.println(bufferedReader.readLine()); // 输出绝对路径 System.out.println(file.getAbsolutePath()); bufferedReader.close(); // 操作完上的文件 需要删除在根目录下生成的文件 &#125; 常见配置 MultipartResolver其中属性详解： defaultEncoding=”UTF-8” 是请求的编码格式，默认为iso-8859-1 maxUploadSize=”5400000” 是上传文件的大小，单位为字节 uploadTempDir=”fileUpload/temp” 为上传文件的临时路径 3.3、一切皆流深层次来讲，文件的上下传问题都是流的问题，当我们需要上传文件时，我们需要将上传文件流进行获取，spring框架为了方便开发，将文件信息进行二进制封装为Multipartfile，而且如果上传的文件数据过大，我们需要对上传文件大小进行限制，因此，文件的上传下载说到底就是对流知识的了解，我们需要对不同的流进行转化， 因此需要用到字节转化的编码知识。最终，文件上下传就是靠我们对字节流的熟悉程度。]]></content>
      <tags>
        <tag>-基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rpc详解]]></title>
    <url>%2F2020%2F03%2F30%2Frpc%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[一、 什么是RPC RPC是指远程过程调用，指计算机 A 上的进程，调用另外一台计算机 B 上的进程，其中 A 上的调用进程被挂起，而 B 上的被调用进程开始执行，当值返回给 A 时，A 进程继续执行。调用方可以通过使用参数将信息传送给被调用方，而后可以通过传回的结果得到信息。而这一过程，对于开发人员来说是透明的。也就是说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。 二PRC需要解决的问题1、Call ID映射 我们怎么告诉远程机器我们要调用funA，而不是funB或者funC呢？在本地调用中，函数体是直接通过函数指针来指定的，我们调用funA，编译器就自动帮我们调用它相应的函数指针。但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。 所以，在RPC中，所有的函数都必须有自己的一个ID。这个ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个ID。然后我们还需要在客户端和服务端分别维护一个 {函数 &lt;–&gt; Call ID} 的对应表。两者的表不一定需要完全相同，但相同的函数对应的Call ID必须相同。 【Note】当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。 2、序列化和反序列化 客户端怎么把参数值传给远程的函数呢？在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。 但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。甚至有时候客户端和服务端使用的都不是同一种语言（比如服务端用C++，客户端用Java或者Python）。 【Note】这时候就需要客户端把参数先转成一个字节流（编码），传给服务端后，再把字节流转成自己能读取的格式（解码）。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。 为什么需要序列化？ 转换为字节流方便进行网络传输。 实现跨平台、跨语言；如果是跨平台的序列化，则发送方序列化后，接收方可以用任何其支持的平台反序列化成相应的版本，比如 Java序列化后， 用.net、phython等反序列化。 3、网络传输 远程调用往往用在网络上，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。 【Note】网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。 所以，要实现一个RPC框架，其实只需要把以上三点实现了就基本完成了。Call ID映射可以直接使用函数字符串，也可以使用整数ID。映射表一般就是一个哈希表。序列化反序列化可以自己写，也可以使用Protobuf或者FlatBuffers之类的。网络传输库可以自己写socket，或者用asio，ZeroMQ，Netty之类。 总结一下，RPC要解决的两个问题： 解决分布式系统中，服务之间的调用问题。 远程调用时，要能够像本地调用一样方便，让调用者感知不到远程调用的逻辑。 三、PRC分析1、RPC vs Restful在微服务中，使用什么协议来构建服务体系，一直是个热门话题。 争论的焦点集中在两个候选技术： (binary) RPC or Restful。 以Apache Thrift为代表的二进制RPC，支持多种语言（但不是所有语言），四层通讯协议，性能高，节省带宽。相对Restful协议，使用Thrifpt RPC，在同等硬件条件下，带宽使用率仅为前者的20%，性能却提升一个数量级。但是这种协议最大的问题在于，无法穿透防火墙。 以Spring Cloud为代表所支持的Restful 协议，优势在于能够穿透防火墙，使用方便，语言无关，基本上可以使用各种开发语言实现的系统，都可以接受Restful 的请求。 但性能和带宽占用上有劣势。 所以，业内对微服务的实现，基本是确定一个组织边界，在该边界内，使用RPC; 边界外，使用Restful。这个边界，可以是业务、部门，甚至是全公司。 其实这两者并不是一个维度的概念，总得来说RPC涉及的维度更广。 使用RPC远程服务调用方式与传统http接口直接调用方式的差别在于：RPC是面向过程，Restful是面向资源 从使用方面看，Http接口只关注服务提供方，对于客户端怎么调用，调用方式怎样并不关心，通常情况下，我们使用Http方式进行调用时，只要将内容进行传输即可，这样客户端在使用时，需要更关注网络方面的传输，比较不适用与业务方面的开发；而RPC服务则需要客户端接口与服务端保持一致，服务端提供一个方法，客户端通过接口直接发起调用，业务开发人员仅需要关注业务方法的调用即可，不再关注网络传输的细节，在开发上更为高效。 从性能角度看，使用Http时，Http本身提供了丰富的状态功能与扩展功能，但也正由于Http提供的功能过多，导致在网络传输时，需要携带的信息更多，从性能角度上讲，较为低效。而RPC服务网络传输上仅传输与业务内容相关的数据，传输数据更小，性能更高。 从运维角度看，使用Http接口时，常常使用一个前端代理，来进行Http转发代理请求的操作，需要进行扩容时，则需要去修改代理服务器的配置，较为繁琐，也容易出错。而使用RPC方式的微服务，则只要增加一个服务节点即可，注册中心可自动感知到节点的变化，通知调用客户端进行负载的动态控制，更为智能，省去运维的操作。 比如你提供一个查询订单的接口，用RPC风格，你可能会这样写： 1/queryOrder?orderId=123 用Restful风格呢？ 12Get /order?orderId=123 2、RPC vs RMI 1、什么是RMI RMI:远程方法调用(Remote Method Invocation)。能够让在客户端Java虚拟机上的对象像调用本地对象一样调用服务端java 虚拟机中的对象上的方法。 RMI对服务器的IP地址和端口依赖很紧密，但是在开发的时候不知道将来的服务器IP和端口如何，但是客户端程序依赖这个IP和端口。这也是RMI的局限性之一。 这个问题有两种解决途径：一是通过DNS来解决，二是通过封装将IP暴露到程序代码之外。 RMI的局限性之二是RMI是Java语言的远程调用，两端的程序语言必须是Java实现，对于不同语言间的通讯可以考虑用Web Service或者公用对象请求代理体系（CORBA）来实现。 2、RPC与RMI的区别 （1）：方法调用方式不同： RPC（远程过程调用）和RMI（远程方法调用）是两种可以让用户从一台电脑调用不同电脑上面的方法的的机制（也可以称作规范、协议）。两者的主要不同是他们的使用方式或者称作范式，RMI使用面向对象的范式，也就是用户需要知道他调用的对象和对象中的方法；RPC不是面向对象也不能处理对象，而是调用具体的子程序。 RPC中是通过网络服务协议向远程主机发送请求，请求包含了一个参数集和一个文本值，通常形成“classname.methodname(参数集)”的形式。RPC远程主机就去搜索与之相匹配的类和方法，找到后就执行方法并把结果编码，通过网络协议发回。 （2）：适用语言范围不同： RPC是一个基于C语言的相对较旧的协议，因此也就继承了C语言的范式，使用RPC，你可以像调用一个本地方法一样调用远程的方法，由RPC处理调用过程的复杂操作，RMI的功能和RPC基本一样。但是和RPC只传输一个过程调用不同，RMI需要传输对象的引用以及调用的方法。RMI是用Java开发的，运行在Java虚拟机上，因此它的用途是调用远程计算机上的java应用程序。 （3）：调用结果的返回形式不同： RPC和RMI只是处理同一个问题的不同方式，这一切都归结于你所使用的语言和你所使用的范式。使用面向对象的RMI是两者之间的更好的方法，特别是大型程序，使用RMI代码更简洁，更容易追踪bug。RPC目前依然是被广泛接受的，尤其是当无法选择任何的可替代的远程程序协议时候。 Java是面向对象的，所以RMI的调用结果可以是对象类型或者基本数据类型； RMI的结果统一由外部数据表示 (External Data Representation, XDR) 语言表示，这种语言抽象了字节序类和数据类型结构之间的差异。 四常见的RPC框架常用的RPC框架 gRPC是Google公布的开源软件，基于最新的HTTP2.0协议，并支持常见的众多编程语言。 我们知道HTTP2.0是基于二进制的HTTP协议升级版本，目前各大浏览器都在快马加鞭的加以支持。 这个RPC框架是基于HTTP协议实现的，底层使用到了Netty框架的支持。 Thrift是Facebook的一个开源项目，主要是一个跨语言的服务开发框架。它有一个代码生成器来对它所定义的IDL定义文件自动生成服务代码框架。用户只要在其之前进行二次开发就行，对于底层的RPC通讯等都是透明的。不过这个对于用户来说的话需要学习特定领域语言这个特性，还是有一定成本的。 Dubbo是阿里集团开源的一个极为出名的RPC框架，在很多互联网公司和企业应用中广泛使用。协议和序列化框架都可以插拔是及其鲜明的特色。同样的远程接口是基于Java Interface，并且依托于spring框架方便开发。可以方便的打包成单一文件，独立进程运行，和现在的微服务概念一致。]]></content>
      <tags>
        <tag>-基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springMVC知识点回顾]]></title>
    <url>%2F2020%2F03%2F20%2FspringMVC%E7%9F%A5%E8%AF%86%E7%82%B9%E5%9B%9E%E9%A1%BE%2F</url>
    <content type="text"></content>
      <tags>
        <tag>-知识回顾</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins发布小清单]]></title>
    <url>%2F2019%2F12%2F16%2FJenkins%E5%8F%91%E5%B8%83%E5%B0%8F%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[Jenkins部署应公司项目所需，用Jenkins进行实时的部署到服务器，因公司已进行系统等相应配置，因此本文只讲解对一个微服务中一个小服务进行部署的基本步骤。 将data-center项目中的子项目部署到服务器中的方式有很多种，下面示例利用Jenkins将子项目（maven项目）进行Jenkins自动部署。 （已配置系统环境管理） 步骤一在Jenkins首页点击新建任务，输入项目中的任务名称，并点击maven项目（因data-center中的子项目都是利用pom.xml引入maven依赖） 步骤二在General中可添加参数化构建过程参数（后续步骤中可获取该参数，类型全局变量设置） 1、添加一个Git Parameter参数（源码管理类型时，可提前设置分支信息） Name填写为branch（参数名称，填写一目了然的名称） Description可填写分支（后续维护时防止忘记） Parameter Type选择Branch类型 Default Value填写子项目中Remote Branch的名称，例如离线开发填写origin/feature/data-offline-dev-platform（可在IDEA或者GitLab中查看子项目规定维护的分支） 2、添加一个字符参数（Jenkins后续操作的全局字符替换） 以离线开发平台为例 名称填写WORK_DIR 默认值填写data-offline-dev-platform 描述填写项目路径 勾选（√清除空白字符） 步骤三因data-center项目用git仓库管理，选择Git（以离线开发平台为例）在源码管理中 Repositories中 Repository URL填写http://10.194.186.226:13333/data-center/data-center-parent.git（在GitLab中获取子项目中git路径） Credentials选择Jenkins用户（已设置系统参数的用户最佳） Branches to build填写${branch}（获取前面的Git参数即可） 在构建触发器中勾选√Build whenever a SNAPSHOT dependency is built 在构建环境中选择Add timestamps to the Console Output 步骤四在Build中 Root POM填写pom.xml Goals and options填写clean install -pl $WORK_DIR -am -amd -Pdev -Dmaven.test.skip=true(打包命令，打包命令见附录) 步骤五在构建后操作中，添加一个SSH Server：表示远程SSH连接服务器 在Transfers的中 Source files表示：需要上传的文件（注意：相对于工作区的路径;看后面的配置可以填写多个，默认用,分隔） Remove prefix表示：移除目录（只能指定Transfer Set Source files中的目录） Remote directory表示：远程目录（根据你的需求填写，默认会继承系统配置） Exec command表示: 执行的命令 以离线开发为例： Name选择bmsoft228(系统设置中已设置) 添加一个Transfers Source files填写$WORK_DIR/target/*.jar,$WORK_DIR/target/build.sh,$WORK_DIR/target/Dockerfile Remove prefix填写$WORK_DIR/target Remote directory填写${JOB_NAME} Exec command填写 123cd /home/docker/$&#123;JOB_NAME&#125;chmod u+x ./build.sh./build.sh 附录 命令参数 备注 mvn -v –version 显示版本信息; mvn -V –show-version 显示版本信息后继续执行Maven其他目标; mvn -h –help 显示帮助信息; mvn -e –errors 控制Maven的日志级别,产生执行错误相关消息; mvn -X –debug 控制Maven的日志级别,产生执行调试信息; mvn -q –quiet 控制Maven的日志级别,仅仅显示错误; mvn -Pxxx 激活 id 为 xxx的profile (如有多个，用逗号隔开); mvn -Dxxx=yyy 指定Java全局属性; mvn -o –offline 运行offline模式,不联网更新依赖; mvn -N –non-recursive 仅在当前项目模块执行命令,不构建子模块; mvn -pl –module_name 在指定模块上执行命令; mvn -ff –fail-fast 遇到构建失败就直接退出; mvn -fn –fail-never 无论项目结果如何,构建从不失败; mvn -fae –fail-at-end 仅影响构建结果,允许不受影响的构建继续; mvn -C –strict-checksums 如果校验码不匹配的话,构建失败; mvn -c –lax-checksums 如果校验码不匹配的话,产生告警; mvn -U 强制更新snapshot类型的插件或依赖库(否则maven一天只会更新一次snapshot依赖); mvn -npu –no-plugin-s 对任何相关的注册插件,不进行最新检查(使用该选项使Maven表现出稳定行为，该稳定行为基于本地仓库当前可用的所有插件版本); mvn -cpu –check-plugin-updates 对任何相关的注册插件,强制进行最新检查(即使项目POM里明确规定了Maven插件版本,还是会强制更新); mvn -up –update-plugins [mvn -cpu]的同义词; mvn -B –batch-mode 在非交互（批处理）模式下运行(该模式下,当Mven需要输入时,它不会停下来接受用户的输入,而是使用合理的默认值); mvn -f –file 强制使用备用的POM文件; mvn -s –settings 用户配置文件的备用路径; mvn -gs –global-settings 全局配置文件的备用路径; mvn -emp –encrypt-master-password 加密主安全密码,存储到Maven settings文件里; mvn -ep –encrypt-password 加密服务器密码,存储到Maven settings文件里; mvn -npr –no-plugin-registry 对插件版本不使用~/.m2/plugin-registry.xml(插件注册表)里的配置; 因为项目中用到了-pl，特贴上-pl信息 参数 全称 释义 说明 -pl –projects Build specified reactor projects instead of all projects 选项后可跟随{groupId}:{artifactId}或者所选模块的相对路径(多个模块以逗号分隔) -am –also-make If project list is specified, also build projects required by the list 表示同时处理选定模块所依赖的模块 -amd –also-make-dependents If project list is specified, also build projects that depend on projects on the list 表示同时处理依赖选定模块的模块 -N –Non-recursive Build projects without recursive 表示不递归子模块 -rf –resume-from Resume reactor from specified project 表示从指定模块开始继续处理 -Dmaven.test.skip=true – – 表示不执行测试用例，也不编译测试用例类 -DskipTests – – 表示不执行测试用例，但编译测试用例类生成相应的class文件至target/test-classes下 案例解析:clean install -pl $WORK_DIR -am -amd -Pdev -Dmaven.test.skip=true 清除存在的jar包，再重新选择 $WORK_DIR的模块路径并同时处理该模块所依赖的模块与处理依赖选定的模板的模板（在springcloud项目多模块中子模块独立部署测试时多选择该打包方式），并激活 id 为 dev的profile,不执行测试用例也不编译测试用例进行打包。]]></content>
      <tags>
        <tag>-Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring基础知识]]></title>
    <url>%2F2019%2F11%2F26%2Fspring%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[spring容器Spring容器并不是只有一个。 Spring自带了多个容器实现， 可以归为两种不同的类型。 1、bean工厂（由org.springframework. beans. factory.eanFactory接口定义） 是最简单的容器， 提供基本的DI支持。 2、应用上下文（由org.springframework.context.ApplicationContext接口定义） 基于BeanFactory构建， 并提供应用框架级别的服务， 例如从属性文件解析文本信息以及发布应用事件给感兴趣的事件监听者 在bean工厂和应用上下文之间任选一种， 但bean工厂对大多数应用来说往往太低级了， 因此， 应用上下文要比bean工厂更受欢迎。 我们会把精力集中在应用上下文的使用上， 不再浪费时间讨论bean工厂 常见应用上下文： AnnotationConfigApplicationContext:从一个或多个基于Java的配置类中加载Spring应用上下文。 AnnotationConfigWebApplicationContext:从一个或多个基于Java的配置类中加载Spring Web应用上下文。 ClassPathXmlApplicationContext:从类路径下的一个或多个XML配置文件中加载上下文定义， 把应用上下文的定义文件作为类资源 。 FileSystemXmlApplicationContext:从文件系统下的一个或多个XML配置文件中加载上下文定义 XmlWebApplicationContext:从Web应用下的一个或多个XML配置文件中加载上下文定义。 如果你想从Java配置中加载应用上下文， 那么可以使用AnnotationConfigApplicationContext： 1ApplicationContext context=new AnnotationConfiApplicationContext(com.springination.zhangzhengkaiConfig.class); 应用上下文准备就绪之后， 我们就可以调用上下文的getBean()方法从Spring容器中获取bean。 Bean的生命周期 在bean准备就绪之前， bean工厂执行了若干启动步骤。 我们对图1.5进行详细描述： 1． Spring对bean进行实例化；2． Spring将值和bean的引用注入到bean对应的属性中；3． 如果bean实现了BeanNameAware接口， Spring将bean的ID传递给setBean-Name()方法；4． 如果bean实现了BeanFactoryAware接口， Spring将调用setBeanFactory()方法， 将BeanFactory容器实例传入；5． 如果bean实现了ApplicationContextAware接口， Spring将调用setApplicationContext()方法， 将bean所在的应用上下文的引用传入进来；6． 如果bean实现了BeanPostProcessor接口， Spring将调用它们的postProcessBeforeInitialization()方法；7． 如果bean实现了InitializingBean接口， Spring将调用它们的afterPropertiesSet()方法。 类似地， 如果bean使用init-method声明了初始化方法， 该方法也会被调用；8． 如果bean实现了BeanPostProcessor接口， Spring将调用它们的postProcessAfterInitialization()方法；9． 此时， bean已经准备就绪， 可以被应用程序使用了， 它们将一直驻留在应用上下文中，直到该应用上下文被销毁；10． 如果bean实现了DisposableBean接口， Spring将调用它的destroy()接口方法。 同样， 如果bean使用destroy-method声明了销毁方法， 该方法也会被调用。 IoC容器BeanDefinition对象：容器中的每一个bean都会有一个对应的BeanDefinition实例，该实例负责保存bean对象的所有必要信息，包括bean对象的class类型、是否是抽象类、构造方法和参数、其它属性等等。当客户端向容器请求相应对象时，容器就会通过这些信息为客户端返回一个完整可用的bean实例。BeanDefinitionRegistry和BeanFactory：BeanDefinitionRegistry抽象出bean的注册逻辑，而BeanFactory则抽象出了bean的管理逻辑，而各个BeanFactory的实现类就具体承担了bean的注册以及管理工作。它们之间的关系就如下图： IoC容器负责管理容器中所有bean的生命周期，而在bean生命周期的不同阶段，Spring提供了不同的扩展点来改变bean的命运。 1、在容器的启动阶段，BeanFactoryPostProcessor允许我们在容器实例化相应对象之前，对注册到容器的BeanDefinition所保存的信息做一些额外的操作，比如修改bean定义的某些属性或者增加其他信息等。如果要自定义扩展类，通常需要实现org.springframework.beans.factory.config.BeanFactoryPostProcessor接口，与此同时，因为容器中可能有多个BeanFactoryPostProcessor，可能还需要实现org.springframework.core.Ordered接口，以保证BeanFactoryPostProcessor按照顺序执行。Spring提供了为数不多的BeanFactoryPostProcessor实现 我们以PropertyPlaceholderConfigurer来说明其大致的工作流程： 在Spring项目的XML配置文件中，经常可以看到许多配置项的值使用占位符，而将占位符所代表的值单独配置到独立的properties文件，这样可以将散落在不同XML文件中的配置集中管理，而且也方便运维根据不同的环境进行配置不同的值。这个非常实用的功能就是由PropertyPlaceholderConfigurer负责实现的。 根据前文，当BeanFactory在第一阶段加载完所有配置信息时，BeanFactory中保存的对象的属性还是以占位符方式存在的，比如${jdbc.mysql.url}。当PropertyPlaceholderConfigurer作为BeanFactoryPostProcessor被应用时，它会使用properties配置文件中的值来替换相应的BeanDefinition中占位符所表示的属性值。当需要实例化bean时，bean定义中的属性值就已经被替换成我们配置的值。当然其实现比上面描述的要复杂一些。 2、BeanPostProcessor，其存在于对象实例化阶段。跟BeanFactoryPostProcessor类似，它会处理容器内所有符合条件并且已经实例化后的对象。 总结：BeanFactoryPostProcessor处理bean的定义，而BeanPostProcessor则处理bean完成实例化后的对象。 BeanPostProcessor定义了两个接口： 123456public interface BeanPostProcessor &#123; // 前置处理 Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; // 后置处理 Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125; postProcessBeforeInitialization()方法与postProcessAfterInitialization()分别对应图中前置处理和后置处理两个步骤将执行的方法。这两个方法中都传入了bean对象实例的引用，为扩展容器的对象实例化过程提供了很大便利，在这儿几乎可以对传入的实例执行任何操作。注解、AOP等功能的实现均大量使用了BeanPostProcessor，比如有一个自定义注解，你完全可以实现BeanPostProcessor的接口，在其中判断bean对象的脑袋上是否有该注解，如果有，你可以对这个bean实例执行任何操作。 再来看一个更常见的例子，在Spring中经常能够看到各种各样的Aware接口，其作用就是在对象实例化完成以后将Aware接口定义中规定的依赖注入到当前实例中。比如最常见的ApplicationContextAware接口，实现了这个接口的类都可以获取到一个ApplicationContext对象。当容器中每个对象的实例化过程走到BeanPostProcessor前置处理这一步时，容器会检测到之前注册到容器的ApplicationContextAwareProcessor，然后就会调用其postProcessBeforeInitialization()方法，检查并设置Aware相关依赖。看看代码吧，是不是很简单： 1234567891011// 代码来自：org.springframework.context.support.ApplicationContextAwareProcessor// 其postProcessBeforeInitialization方法调用了invokeAwareInterfaces方法private void invokeAwareInterfaces(Object bean) &#123; if (bean instanceof EnvironmentAware) &#123; ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); &#125; if (bean instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); &#125; // ......&#125; 装配Bean装配：创建应用组件之间协作的行为称为装配 Spring容器负责创建应用程序中的bean并通过DI来协调这些对象之间的关系。 Spring具有非常大的灵活性， 它提供了三种主要的装配机制： 在XML中进行显式配置。 在Java中进行显式配置 隐式的bean发现机制和自动装配。 自动化装配BeanSpring从两个角度来实现自动化装配：组件扫描（component scanning）：Spring会自动发现应用上下文中所创建的bean。自动装配（autowiring）：Spring自动满足bean之间的依赖 。 注解详解： @Component注解。 这个简单的注解表明该类会作为组件类， 并告知Spring要为这个类创建bean 不过， 组件扫描默认是不启用的。 我们还需要显式配置一下Spring， 从而命令它去寻找带有@Component注解的类， 并为其创建bean。 @ComponentScan注解， 这个注解能够在Spring中启用组件扫描。 @ComponentScan注解下没有其他配置的话， @ComponentScan默认会扫描与配置类相同的包以及子包 —对应Xml配置中的：&lt; context:component-scan &gt;元素 @Autowired注解：在满足依赖的过程中， 会在Spring应用上下文中寻找匹配某个bean需求的其他bean。 为了声明要进行自动装配， 我们可以借助Spring的@Autowired注解 ；@Autowired注解可以用在类的任何方法上 特别注意：bean装载到容器中时，如果没有指定名称，会自动的将其名称作为bean名称(首字母大写会变成小写) 通过Java装配Bean尽管在很多场景下通过组件扫描和自动装配实现Spring的自动化配置是更为推荐的方式， 但有时候自动化配置的方案行不通， 因此需要明确配置Spring。 比如说， 你想要将第三方库中的组件装配到你的应用中， 在这种情况下， 是没有办法在它的类上添加@Component和@Autowired注解的， 因此就不能使用自动化装配的方案了。 显式配置有俩种方案： 在XML中进行显式配置 在Java中进行显式配置 注解详解： @Configuration注解：表明这个类是一个配置类， 该类应该包含在Spring应用上下文中如何创建bean的细节。 @Bean注解：会告诉Spring这个方法将会返回一个对象， 该对象要注册为Spring应用上下文中的bean。 通过Xml装配Bean&lt; beans &gt;是该模式中的一个元素， 它是所有Spring配置文件的根元素。 &lt; bean &gt;元素类似于JavaConfig中的@Bean注解 ；创建这个bean的类通过class属性来指定的， 并且要使用全限定的类名。 &lt; constructor-arg &gt;元素 ;使用构造器注入到bean的引用；用ref属性引用其他bean，也可以通过value属性，通过该属性表明给定的值要以字面量的形式注入到构造器中 &lt; set &gt;和&lt; list &gt;元素的区别不大， 其中最重要的不同在于当Spring创建要装配的集合时，所创建的是java.util.Set还是java.util.List。 如果是Set的话， 所有重复的值都会被忽略掉 &lt; property &gt;元素为属性的Setter方法所提供的功能与&lt; constructor-arg &gt;元素为构造器所提供的功能是一样的。 Bean的作用域作用域 单例（Singleton） ： 在整个应用中， 只创建bean的一个实例。（默认） 原型（Prototype） ： 每次注入或者通过Spring应用上下文获取的时候， 都会创建一个新的bean实例。 会话（Session） ： 在Web应用中， 为每个会话创建一个bean实例。 请求（Rquest） ： 在Web应用中， 为每个请求创建一个bean实例。 如果选择其他的作用域， 要使用@Scope注解， 它可以与@Component或@Bean一起使用。 使用ConfigurableBeanFactory类的SCOPE_PROTOTYPE常量设置了原型作用域。 你当然也可以使@Scope(“prototype”)， 但是使用SCOPE_PROTOTYPE常量更加安全并且不易出错。 123@Component@Scope(ConfigurableBeaanFactory.SCOPE.PROTOTYPE)public class zzkai&#123;...&#125; 如果你使用XML来配置bean的话， 可以使用&lt; bean &gt;元素的scope属性来设置作用域： 会话作用域bean的作用示例： 在典型的电子商务应用中， 可能会有一个bean代表用户的购物车。 如果购物车是单例的话， 那么将会导致所有的用户都会向同一个购物车中添加商品。 另一方面， 如果购物车是原型作用域的， 那么在应用中某一个地方往购物车中添加商品， 在应用的另外一个地方可能就不可用了， 因为在这里注入的是另外一个原型作用域的购物车。就购物车bean来说， 会话作用域是最为合适的， 因为它与给定的用户关联性最大。 作用域代理问题@Scope同时还有一个proxyMode属性， 它被设置成了ScopedProxyMode.INTERFACES。 这个属性解决了将会话或请求作用域的bean注入到单例bean中所遇到的问题。 proxyMode属性解决的问题假设我们要将ShoppingCart bean注入到单例StoreService bean的Setter方法中， 如下所示： 1234567@Componentpublic class StoreService&#123; @AutoWired public void setShoppingCart(ShoppingCart shoppingCart)&#123; this.shoppingCart=shoppingCart; &#125;&#125; 因为StoreService是一个单例的bean， 会在Spring应用上下文加载的时候创建。 当它创建的时候， Spring会试图将ShoppingCart bean注入到setShoppingCart()方法中。 但是ShoppingCart bean是会话作用域的， 此时并不存在。 直到某个用户进入系统， 创建了会话之后， 才会出现ShoppingCart实例。另外， 系统中将会有多个ShoppingCart实例： 每个用户一个。 我们并不想让Spring注入某个固定的ShoppingCart实例到StoreService中。 我们希望的是当StoreService处理购物车功能时， 它所使用的ShoppingCart实例恰好是当前会话所对应的那一个。Spring并不会将实际的ShoppingCart bean注入到StoreService中， Spring会注入一个到ShoppingCart bean的代理， 这个代理会暴露与ShoppingCart相同的方法， 所以StoreService会认为它就是一个购物车。 但是， 当StoreService调用ShoppingCart的方法时， 代理会对其进行懒解析并将调用委托给会话作用域内真正的ShoppingCart bean。 proxyMode作用proxyMode属性被设置成了ScopedProxyMode.INTERFACES， 这表明这个代理要实现ShoppingCart接口， 并将调用委托给实现bean。 注意点如果ShoppingCart是接口而不是类的话， 这是可以的（也是最为理想的代理模式） 。 但如果ShoppingCart是一个具体的类的话， Spring就没有办法创建基于接口的代理了。 此时， 它必须使用CGLib来生成基于类的代理。 所以， 如果bean类型是具体类的话， 我们必须要将proxyMode属性设为ScopedProxyMode.TARGET_CLASS，以此来表明要以生成目标类扩展的方式创建代理。 运行时注入注入方式注入方式有： 构造器注入 Setter注入 为了避免硬编码问题，Spring提供了两种在运行时求值的方式 属性占位符(Property placeholder) spring表达式语言(spEL) 在Spring装配中， 占位符的形式为使用“${ … }”包装的属性名称 如果我们依赖于组件扫描和自动装配来创建和初始化应用组件的话， 那么就没有指定占位符的配置文件或类了。 在这种情况下， 我们可以使用@Value注解 1234public zhangkai&#123; @Value("$&#123;linkis.ip&#125;") String ip; ...&#125;]]></content>
      <tags>
        <tag>-spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springCloud-Feign知识清单]]></title>
    <url>%2F2019%2F11%2F26%2FspringCloud-Feign%E7%9F%A5%E8%AF%86%E6%B8%85%E5%8D%95%2F</url>
    <content type="text"><![CDATA[Feign简介背景如果使用RestTemplat实现REST API 调用，是使用拼接字符串的方式构建URL,如果URL中有多个请求参数，那将非常痛苦，因此，可使用Feign进行服务间的调用 简介Feign是Netflix开发的声明式，模板化的HTTP客户端，其灵感来自Retrofit,JAXRS-2.0以及WebSocket. Feign可帮助我们更加便捷，优雅的调用HTTP API。 在SpringCloud中，使用Feign非常简单——创建一个接口，并在接口上添加一些注解，代码就完成了。 Feign支持多种注解，例如Feign自带的注解或者JAX-RS注解等。 SpringCloud对Feign进行了增强，使Feign支持了SpringMVC注解，并整合了Ribbon和Eureka，从而让Feign的使用更加方便。 工作流程引入依赖在服务消费者中添加Feign依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.1.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; 开启功能启动类添加Feign支持:添加注解@EnableFeignClients开启Spring Cloud Feign的支持功能 12345678910@MapperScan("com.bmsoft.dc.dodp.mapper")@EnableSwagger2@EnableEurekaClient@SpringBootApplication@EnableFeignClientspublic class DataOfflineDevPlatformApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DataOfflineDevPlatformApplication.class); &#125;&#125; 封装接口对所需要进行远程（其他微服务）进行调用的http请求进行封装 创建一个Feign接口，此接口是在Feign中调用微服务的核心接口 12345678910111213@Service(value = "linkisService")@FeignClient(url = "$&#123;linkis.ip&#125;", name = "cloud-publicservice", configuration = FeignMultipartSupportConfig.class)public interface LinkisService &#123; @RequestMapping(value = "/api/rest_j/v1/publicservice/createNewDir", method = RequestMethod.POST, consumes = MediaType.APPLICATION_JSON) JSONObject createNewDir(@RequestBody String json); @RequestMapping(value = "/api/rest_j/v1/publicservice/isExist", method = RequestMethod.GET) JSONObject isExist(@RequestParam("path") String path); @RequestMapping(value = "/api/rest_j/v1/publicservice/getUserRootPath", method = RequestMethod.GET) JSONObject getUserRootPath(@RequestParam("pathType") String pathType);&#125; 说明： ①、@Service(value = &quot;linkisService&quot;)将该接口放入该Feign客户端的应用上下文中成为bean,后期可进行调用 ②、@FeignClient()指定该接口是Feign客户端，其中： url：被调用微服务的url,可写成${}形式去配置文件中获取该值 name:被调用远程微服务的名称：–在远程微服务配置文件中spring.application.name中的值；用于创建Ribbon的负载均衡器。所以Ribbon会把name的值解析为注册中心的服务 configuration:该接口进行调用时配置文件信息—可对请求信息进行再封装等 ③、RequestMapping中必须写出value，并指定远程http信息，必须写出method进行指定远程方法，如果没有将报405错误；consumes是请求头中的Content-Type,特别要注意，如果进行POST请求，是application/json类型数据，请求中的信息应该写成String，而不应该写成JsonNode类型，类型错误报415错误 ④、定义各参数绑定时，@PathVariable、@RequestParam、@RequestHeader等可以指定参数属性，在Feign中绑定参数必须通过value属性来指明具体的参数名，不然会抛出异常 服务调用本服务调用远程服务 1234567891011121314@AutowiredLinkisService linkisService; @Override public List&lt;Process&gt; getProcessPage(String enName, String themeId, Integer pageNum, Integer pageSize) &#123; String jsonString = methodpre + "file:///tmp/linkis/hadoop/" + enName + "\"&#125;"; String isExist = linkisService.isExist("file:///tmp/linkis/hadoop/" + enName) .getJSONObject("data") .getString("isExist"); if(!enName.isEmpty()&amp;&amp;"false".equals(isExist))&#123; //调用远程服务 JSONObject newDir = linkisService.createNewDir(jsonString); &#125; &#125; 接口配置有时候接口中默认配置并不能满足需求，因此需要对接口配置进行重配置；需要在接口配置中写出配置文件位置；借鉴上面的例子中 1234@FeignClient(url = "$&#123;linkis.ip&#125;", name = "cloud-publicservice", configuration = FeignMultipartSupportConfig.class)public interface LinkisService &#123; ...&#125; 指定该接口配置信息在FeignMultipartSupportConfig这个类中 该类的配置信息需放入服务应用上下文容器中，因此是一个配置类，配置信息需封装成bean 1234567891011121314151617181920@Configurationpublic class FeignMultipartSupportConfig &#123; @Autowired private ObjectFactory&lt;HttpMessageConverters&gt; messageConverters; @Bean @Primary @Scope("prototype") public Encoder multipartFormEncoder() &#123; return new SpringFormEncoder(new SpringEncoder(messageConverters)); &#125; @Bean public feign.Logger.Level multipartLoggerLevel() &#123; return Logger.Level.FULL; &#125; /** feign请求拦截器*/ @Bean public RequestInterceptor requestInterceptor()&#123; return new FeignBasicAuthRequestInterceptor(); &#125;&#125; 该配置类中，用于创建bean放入应用上下文容器中，例如该项目中feign请求拦截器对请求信息进行再封装，将cookie与token写入，调用另一个微服务时刻成功实现另一个微服务的鉴权 123456789101112131415161718public class FeignBasicAuthRequestInterceptor implements RequestInterceptor &#123; @Override public void apply(RequestTemplate requestTemplate) &#123; //ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder // .getRequestAttributes(); //将token、cookie信息放入header中 requestTemplate.header("Cookie","bdp-user-ticket-id=M7UZXQP9Ld12SURe+cZYD34G9B3piEba2HLiVea4FcQ="); //Enumeration&lt;String&gt; headerNames = request.getHeaderNames(); //if (headerNames != null) &#123; // while (headerNames.hasMoreElements()) &#123; // String name = headerNames.nextElement(); // String values = request.getHeader(name); // requestTemplate.header(name, values); // &#125; //&#125; &#125;&#125; 服务调用Feign高级Feign和Ribbon的联系Ribbon是一个基于 HTTP 和 TCP 客户端 的负载均衡的工具。它可以 在客户端 配置RibbonServerList（服务端列表），使用 HttpClient 或 RestTemplate 模拟http请求，步骤相当繁琐。 Feign 是在 Ribbon的基础上进行了一次改进，是一个使用起来更加方便的 HTTP 客户端。采用接口的方式，只需要创建一个接口，然后在上面添加注解即可 ，将需要调用的其他服务的方法定义成抽象方法即可， 不需要自构建http请求。然后就像是调用自身工程的方法调用，而感觉不到是调用远程方法，使得编写客户端变得非常容易 负载均衡Feign中本身已经集成了Ribbon依赖和自动配置，因此我们不需要额外引入依赖，也不需要再注册RestTemplate 对象。另外，我们可以去配置Ribbon，可以通过 ribbon.xx 来进行全局配置。也可以通过 服务名.ribbon.xx 来对指定服务配置 Feign中默认Hystrix负载均衡不开启，如果要开启只需要在配置文件中加入 123feign: hystrix: enabled: true 自定义Feign从Spring Cloud Edgware开始，Feign支持使用属性自定义Feign。对于一个指定名称的FeignClient（例如该Feign Client的名称为 feignName ），Feign支持如下配置项： 1234567891011121314151617feign: client: config: feignName: ##定义FeginClient的名称 connectTimeout: 5000 # 相当于Request.Options:建立链接的超时时长 readTimeout: 5000 # 相当于Request.Options:读取超长时间# 配置Feign的日志级别，相当于代码配置方式中的Logger loggerLevel: full# Feign的错误解码器，相当于代码配置方式中的ErrorDecoder errorDecoder: com.example.SimpleErrorDecoder# 配置重试，相当于代码配置方式中的Retryer retryer: com.example.SimpleRetryer# 配置拦截器，相当于代码配置方式中的RequestInterceptor requestInterceptors: - com.example.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false #配置熔断不处理404异常 日记级别在开发或者运行阶段往往希望看到Feign请求过程的日志记录，默认情况下Feign的日志是没有开启的。要想用属性配置方式来达到日志效果，只需在 application.yml 中添加如下内容即可 ： 12345678feign: client: config: shop-service-product: loggerLevel: FULLlogging: level: cn.itcast.order.fegin.ProductFeginClient: debug logging.level.xx : debug : Feign日志只会对日志级别为debug的做出响应 feign.client.config.shop-service-product.loggerLevel : 配置Feign的日志Feign有四种日志级别： NONE【性能最佳，适用于生产】：不记录任何日志（默认值） BASIC【适用于生产环境追踪问题】：仅记录请求方法、URL、响应状态代码以及执行时间 HEADERS：记录BASIC级别的基础上，记录请求和响应的header。 FULL【比较适用于开发及测试环境定位问题】：记录请求和响应的header、body和元数据。]]></content>
      <tags>
        <tag>-springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从线程到线程池的进阶之路]]></title>
    <url>%2F2019%2F11%2F20%2F%E4%BB%8E%E7%BA%BF%E7%A8%8B%E5%88%B0%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E8%BF%9B%E9%98%B6%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[Thread与Runnable介绍Runnable 是一个接口，该接口中只包含了一个run()方法 123public interface Runnable &#123; public abstract void run();&#125; Thread 是一个类。Thread本身就实现了Runnable接口。 1public class Thread implements Runnable &#123;&#125; Thread 是类，而Runnable是接口；Thread本身是实现了Runnable接口的类。我们知道“一个类只能有一个父类，但是却能实现多个接口”，因此Runnable具有更好的扩展性。此外，Runnable还可以用于“资源的共享”。即，多个线程都是基于某一个Runnable对象建立的，它们会共享Runnable对象上的资源。通常，建议通过“Runnable”实现多线程！ Future介绍Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。 Future类位于java.util.concurrent包下；在Future接口中声明了5个方法，下面依次解释每个方法的作用： cancel方法用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务，如果设置true，则表示可以取消正在执行过程中的任务。如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false；如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true。 isCancelled方法表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true。 isDone方法表示任务是否已经完成，若任务完成，则返回true； get()方法用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回； get(long timeout, TimeUnit unit)用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null。 也就是说Future提供了三种功能： 1）判断任务是否完成； 2）能够中断任务； 3）能够获取任务执行结果。 因为Future只是一个接口，所以是无法直接用来创建对象使用的，因此就有了下面的FutureTask。 FutureTask介绍FutureTask是一种可以取消的异步的计算任务。它的计算是通过Callable实现的，可以把它理解为是可以返回结果的Runnable。 使用FutureTask的优势有： 可以获取线程执行后的返回结果； 提供了超时控制功能。 它实现了Runnable接口和Future接口 什么是异步计算呢？也就是说，在让该任务执行时，不需要一直等待其运行结束返回结果，而是可以先去处理其他的事情，然后再获取返回结果。例如你想下载一个很大的文件，这时很耗时的操作，没必要一直等待着文件下载完，你可以先去吃个饭，然后再回来看下文件是否下载完成，如果下载完成就可以使用了，否则还需要继续等待。 FutureTask的状态FutureTask内部有这样几种状态： 1234567private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6; 看名字应该很好理解了，当创建一个FutureTask对象是，初始的状态是NEW，在运行时状态会转换，有4中状态的转换过程： NEW -&gt; COMPLETING -&gt; NORMAL：正常执行并返回； NEW -&gt; COMPLETING -&gt; EXCEPTIONAL：执行过程中出现了异常； NEW -&gt; CANCELLED；执行前被取消； NEW -&gt; INTERRUPTING -&gt; INTERRUPTED：取消时被中断。 使用FutureTask下面看一下具体的使用过程：FutureTask实现了Runnable接口，所以需要实现run方法 1234567891011121314151617public class FutureTaskTest &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ExecutorService executor = Executors.newSingleThreadExecutor(); FutureTask&lt;Integer&gt; future = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; int result = 0; for (int i = 0; i &lt; 100; i++) &#123; result += i; &#125; return result; &#125; &#125;); executor.execute(future); System.out.println(future.get()); &#125;&#125; FutureTask构造方法FutureTask有两个构造方法： 12345678910public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable&#125;public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable&#125; 第二种构造方法传入一个Runnable对象和一个返回值对象，因为Runnable是没有返回值的，所以要通过result参数在执行完之后返回结果。 run方法FutureTask实现了Runnable接口，所以需要实现run方法。 run方法的执行过程 只有state为NEW的时候才执行任务； 执行前要设置runner为当前线程，使用CAS来设置是为了防止竞争； 如果任务执行成功，任务状态从NEW转换为COMPLETING，如果执行正常，设置最终状态为NORMAL；如果执行中出现了异常，设置最终状态为EXCEPTIONAL； 唤醒并删除Treiber Stack中的所有节点； 如果调用了cancel(true)方法进行了中断，要确保在run方法执行结束前的状态是INTERRUPTED。 这里涉及到3个比较重要的方法：setException，set和handlePossibleCancellationInterrupt。 get方法12345678910111213141516public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125;public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; if (unit == null) throw new NullPointerException(); int s = state; if (s &lt;= COMPLETING &amp;&amp; (s = awaitDone(true, unit.toNanos(timeout))) &lt;= COMPLETING) throw new TimeoutException(); return report(s);&#125; 这两个方法类似，首先判断状态，如果s &lt;= COMPLETING，说明任务已经执行完毕，但set方法或setException方法还未执行结束（还未设置状态为NORMAL或EXCEPTIONAL），这时需要将当前线程添加到waiters中并阻塞。 第二种get提供了超时功能，如果在规定时间内任务还未执行完毕或者状态还是COMPLETING，则获取结果超时，抛出TimeoutException。而第一种get会一直阻塞直到state &gt; COMPLETING。 FutureTask总结FutureTask的执行过程和获取返回值的过程，要注意以下几个地方： FutureTask是线程安全的，在多线程下任务也只会被执行一次； 注意在执行时各种状态的切换； get方法调用时，如果任务没有结束，要阻塞当前线程，法阻塞的线程会保存在一个Treiber Stack中； get方法超时功能如果超时未获取成功，会抛出TimeoutException； 注意在取消时的线程中断，在run方法中一定要保证结束时的状态是INTERRUPTED，否则在cancel方法中可能没有执行interrupt，造成中断的泄露。 Executor框架接口Executor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架，目的是提供一种将”任务提交”与”任务如何运行”分离开来的机制。 J.U.C中有三个Executor接口： Executor：一个运行新任务的简单接口； ExecutorService：扩展了Executor接口。添加了一些用来管理执行器生命周期和任务生命周期的方法； ScheduledExecutorService：扩展了ExecutorService。支持Future和定期执行任务。 Executor接口123public interface Executor &#123; void execute(Runnable command);&#125; Executor接口只有一个execute方法，用来替代通常创建或启动线程的方法。例如，使用Thread来创建并启动线程的代码如下： 12Thread t = new Thread();t.start(); 使用Executor来启动线程执行任务的代码如下： 12Thread t = new Thread();executor.execute(t); 对于不同的Executor实现，execute()方法可能是创建一个新线程并立即启动，也有可能是使用已有的工作线程来运行传入的任务，也可能是根据设置线程池的容量或者阻塞队列的容量来决定是否要将传入的线程放入阻塞队列中或者拒绝接收传入的线程。 ExecutorService接口ExecutorService接口继承自Executor接口，提供了管理终止的方法，以及可为跟踪一个或多个异步任务执行状况而生成 Future 的方法。增加了shutDown()，shutDownNow()，invokeAll()，invokeAny()和submit()等方法。如果需要支持即时关闭，也就是shutDownNow()方法，则任务需要正确处理中断。 ScheduledExecutorService接口ScheduledExecutorService扩展ExecutorService接口并增加了schedule方法。调用schedule方法可以在指定的延时后执行一个Runnable或者Callable任务。ScheduledExecutorService接口还定义了按照指定时间间隔定期执行任务的scheduleAtFixedRate()方法和scheduleWithFixedDelay()方法。 Java线程池：ThreadPoolExecutorThreadPoolExecutor继承自AbstractExecutorService，也是实现了ExecutorService接口。 线程池的运行状态线程池一共有五种状态, 分别是: RUNNING ：能接受新提交的任务，并且也能处理阻塞队列中的任务； SHUTDOWN：关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务。在线程池处于 RUNNING 状态时，调用 shutdown()方法会使线程池进入到该状态。（finalize() 方法在执行过程中也会调用shutdown()方法进入该状态）； STOP：不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程。在线程池处于 RUNNING 或 SHUTDOWN 状态时，调用 shutdownNow() 方法会使线程池进入到该状态； TIDYING：如果所有的任务都已终止了，workerCount (有效线程数) 为0，线程池进入该状态后会调用 terminated() 方法进入TERMINATED 状态。 TERMINATED：在terminated() 方法执行完后进入该状态，默认terminated()方法中什么也没有做。 进入TERMINATED的条件如下： 线程池不是RUNNING状态； 线程池状态不是TIDYING状态或TERMINATED状态； 如果线程池状态是SHUTDOWN并且workerQueue为空； workerCount为0； 设置TIDYING状态成功。 下图为线程池的状态转换过程： ThreadPoolExecutor构造方法123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 构造方法中的字段含义如下： corePoolSize：核心线程数量，当有新任务在execute()方法提交时，会执行以下判断： 如果运行的线程少于 corePoolSize，则创建新线程来处理任务，即使线程池中的其他线程是空闲的； 如果线程池中的线程数量大于等于 corePoolSize 且小于 maximumPoolSize，则只有当workQueue满时才创建新的线程去处理任务； 如果设置的corePoolSize 和 maximumPoolSize相同，则创建的线程池的大小是固定的，这时如果有新任务提交，若workQueue未满，则将请求放入workQueue中，等待有空闲的线程去从workQueue中取任务并处理； 如果运行的线程数量大于等于maximumPoolSize，这时如果workQueue已经满了，则通过handler所指定的策略来处理任务； 所以，任务提交时，判断的顺序为 corePoolSize –&gt; workQueue –&gt; maximumPoolSize。 maximumPoolSize：最大线程数量； workQueue：等待队列，当任务提交时，如果线程池中的线程数量大于等于corePoolSize的时候，把该任务封装成一个Worker对象放入等待队列； workQueue ：保存等待执行的任务的阻塞队列，当提交一个新的任务到线程池以后, 线程池会根据当前线程池中正在运行着的线程的数量来决定对该任务的处理方式，主要有以下几种处理方式: 直接切换：这种方式常用的队列是SynchronousQueue，但现在还没有研究过该队列，这里暂时还没法介绍； 使用无界队列：一般使用基于链表的阻塞队列LinkedBlockingQueue。如果使用这种方式，那么线程池中能够创建的最大线程数就是corePoolSize，而maximumPoolSize就不会起作用了。当线程池中所有的核心线程都是RUNNING状态时，这时一个新的任务提交就会放入等待队列中。 使用有界队列 ：一般使用ArrayBlockingQueue。使用该方式可以将线程池的最大线程数量限制为maximumPoolSize，这样能够降低资源的消耗，但同时这种方式也使得线程池对线程的调度变得更困难，因为线程池和队列的容量都是有限的值，所以要想使线程池处理任务的吞吐率达到一个相对合理的范围，又想使线程调度相对简单，并且还要尽可能的降低线程池对资源的消耗，就需要合理的设置这两个数量。 如果要想降低系统资源的消耗（包括CPU的使用率，操作系统资源的消耗，上下文环境切换的开销等）, 可以设置较大的队列容量和较小的线程池容量, 但这样也会降低线程处理任务的吞吐量。 如果提交的任务经常发生阻塞，那么可以考虑通过调用 setMaximumPoolSize() 方法来重新设定线程池的容量。 如果队列的容量设置的较小，通常需要将线程池的容量设置大一点，这样CPU的使用率会相对的高一些。但如果线程池的容量设置的过大，则在提交的任务数量太多的情况下，并发量会增加，那么线程之间的调度就是一个要考虑的问题，因为这样反而有可能降低处理任务的吞吐量。 keepAliveTime：线程池维护线程所允许的空闲时间。当线程池中的线程数量大于corePoolSize的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了keepAliveTime； threadFactory：它是ThreadFactory类型的变量，用来创建新线程。默认使用Executors.defaultThreadFactory() 来创建线程。使用默认的ThreadFactory来创建线程时，会使新创建的线程具有相同的NORM_PRIORITY优先级并且是非守护线程，同时也设置了线程的名称。 handler ：它是RejectedExecutionHandler类型的变量，表示线程池的饱和策略。如果阻塞队列满了并且没有空闲的线程，这时如果继续提交任务，就需要采取一种策略处理该任务。线程池提供了4种策略： AbortPolicy：直接抛出异常，这是默认策略； CallerRunsPolicy：用调用者所在的线程来执行任务； DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务； DiscardPolicy：直接丢弃任务； execute方法execute()方法用来提交任务 在执行execute()方法时如果状态一直是RUNNING时，执行过程如下： 如果workerCount &lt; corePoolSize，则创建并启动一个线程来执行新提交的任务； 如果workerCount &gt;= corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中； 如果workerCount &gt;= corePoolSize &amp;&amp; workerCount &lt; maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务； 如果workerCount &gt;= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。 这里要注意一下addWorker(null, false);，也就是创建一个线程，但并没有传入任务，因为任务已经被添加到workQueue中了，所以worker在执行的时候，会直接从workQueue中获取任务。所以，在workerCountOf(recheck) == 0时执行addWorker(null, false);也是为了保证线程池在RUNNING状态下必须要有一个线程来执行任务。 execute方法执行流程如下： addWorker方法addWorker方法的主要工作是在线程池中创建一个新的线程并执行，firstTask参数 用于指定新增的线程执行的第一个任务，core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize 123private boolean addWorker(Runnable firstTask, boolean core) &#123; ...&#125; 启动时会调用Worker类中的run方法，Worker本身实现了Runnable接口，所以一个Worker类型的对象也是一个线程。 Worker类（这是一个类）线程池中的每一个线程被封装成一个Worker对象，ThreadPool维护的其实就是一组Worker对象 123456789101112private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; //构造方法 Worker(Runnable firstTask) &#123; setState(-1); // -1：禁止在执行任务前对线程进行中断 this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; /** 运行方法*/ public void run() &#123; runWorker(this); &#125;&#125; Worker类继承了AQS，并实现了Runnable接口，注意其中的firstTask和thread属性：firstTask用它来保存传入的任务；thread是在调用构造方法时通过ThreadFactory来创建的线程，是用来处理任务的线程。 在调用构造方法时，需要把任务传入，这里通过getThreadFactory().newThread(this);来新建一个线程，newThread方法传入的参数是this，因为Worker本身继承了Runnable接口，也就是一个线程，所以一个Worker对象在启动的时候会调用Worker类中的run方法。 Worker继承了AQS，使用AQS来实现独占锁的功能。为什么不使用ReentrantLock来实现呢？可以看到tryAcquire方法，它是不允许重入的，而ReentrantLock是允许重入的： lock方法一旦获取了独占锁，表示当前线程正在执行任务中； 如果正在执行任务，则不应该中断线程； 如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断； 线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态； 之所以设置为不可重入，是因为我们不希望任务在调用像setCorePoolSize这样的线程池控制方法时重新获取锁。如果使用ReentrantLock，它是可重入的，这样如果在任务中调用了如setCorePoolSize这类线程池控制的方法，会中断正在运行的线程。 所以，Worker继承自AQS，用于判断线程是否空闲以及是否可以被中断。 线程池的监控通过线程池提供的参数进行监控。线程池里有一些属性在监控线程池的时候可以使用 getTaskCount：线程池已经执行的和未执行的任务总数； getCompletedTaskCount：线程池已完成的任务数量，该值小于等于taskCount； getLargestPoolSize：线程池曾经创建过的最大线程数量。通过这个数据可以知道线程池是否满过，也就是达到了maximumPoolSize； getPoolSize：线程池当前的线程数量； getActiveCount：当前线程池中正在执行任务的线程数量。 通过这些方法，可以对线程池进行监控，在ThreadPoolExecutor类中提供了几个空方法，如beforeExecute方法，afterExecute方法和terminated方法，可以扩展这些方法在执行前或执行后增加一些新的操作，例如统计线程池的执行任务的时间等，可以继承自ThreadPoolExecutor来进行扩展。 线程池进阶：ScheduledThreadPoolExecutor自JDK1.5开始，JDK提供了ScheduledThreadPoolExecutor类来支持周期性任务的调度。在这之前的实现需要依靠Timer和TimerTask或者其它第三方工具来完成。但Timer有不少的缺陷： Timer是单线程模式； 如果在执行任务期间某个TimerTask耗时较久，那么就会影响其它任务的调度； Timer的任务调度是基于绝对时间的，对系统时间敏感； Timer不会捕获执行TimerTask时所抛出的异常，由于Timer是单线程，所以一旦出现异常，则线程就会终止，其他任务也得不到执行。 ScheduledThreadPoolExecutor继承ThreadPoolExecutor来重用线程池的功能，它的实现方式如下： 将任务封装成ScheduledFutureTask对象，ScheduledFutureTask基于相对时间，不受系统时间的改变所影响； ScheduledFutureTask实现了java.lang.Comparable接口和java.util.concurrent.Delayed接口，所以有两个重要的方法：compareTo和getDelay。compareTo方法用于比较任务之间的优先级关系，如果距离下次执行的时间间隔较短，则优先级高；getDelay方法用于返回距离下次任务执行时间的时间间隔； ScheduledThreadPoolExecutor定义了一个DelayedWorkQueue，它是一个有序队列，会通过每个任务按照距离下次执行时间间隔的大小来排序； ScheduledFutureTask继承自FutureTask，可以通过返回Future对象来获取执行的结果。 通过如上的介绍，可以对比一下Timer和ScheduledThreadPoolExecutor： Timer ScheduledThreadPoolExecutor 单线程 多线程 单个任务执行时间影响其他任务调度 多线程，不会影响 基于绝对时间 基于相对时间 一旦执行任务出现异常不会捕获，其他任务得不到执行 多线程，单个任务的执行不会影响其他线程 所以，在JDK1.5之后，应该没什么理由继续使用Timer进行任务调度了。 ScheduledThreadPoolExecutor的构造方法ScheduledThreadPoolExecutor有3中构造方法： 12345678910111213141516public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), handler);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler);&#125; 因为ScheduledThreadPoolExecutor继承自ThreadPoolExecutor，所以这里都是调用的ThreadPoolExecutor类的构造方法。 第一种构造方法示例： 123scheduler = new ScheduledThreadPoolExecutor(20, threadFactory("BDP-Default-Scheduler-Thread-", true)) scheduler.setMaximumPoolSize(20) scheduler.setKeepAliveTime(5, TimeUnit.MINUTES) scheduleAtFixedRate方法该方法设置了执行周期，下一次执行时间相当于是上一次的执行时间加上period，它是采用已固定的频率来执行任务： 123456public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) &#123; ...&#125; 总结ScheduedThreadPoolExecutor的实现，主要介绍了以下方面： ScheduledThreadPoolExecutor继承自ThreadPoolExecutor，所以它也是一个线程池，也有coorPoolSize和workQueue，ScheduledThreadPoolExecutor特殊的地方在于，自己实现了优先工作队列DelayedWorkQueue； ScheduedThreadPoolExecutor实现了ScheduledExecutorService，所以就有了任务调度的方法，如schedule，scheduleAtFixedRate和scheduleWithFixedDelay，同时注意他们之间的区别； 内部类ScheduledFutureTask继承自FutureTask，实现了任务的异步执行并且可以获取返回结果。同时也实现了Delayed接口，可以通过getDelay方法获取将要执行的时间间隔； 周期任务的执行其实是调用了FutureTask类中的runAndReset方法，每次执行完不设置结果和状态。 详细分析了DelayedWorkQueue的数据结构，它是一个基于最小堆结构的优先队列，并且每次出队时能够保证取出的任务是当前队列中下次执行时间最小的任务。同时注意一下优先队列中堆的顺序，堆中的顺序并不是绝对的，但要保证子节点的值要比父节点的值要大，这样就不会影响出队的顺序。 总体来说，ScheduedThreadPoolExecutor的重点是要理解下次执行时间的计算，以及优先队列的出队、入队和删除的过程，这两个是理解ScheduedThreadPoolExecutor的关键。]]></content>
      <tags>
        <tag>-Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tcp-http-socket区别]]></title>
    <url>%2F2019%2F11%2F19%2Ftcp-http-socket%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[HTTP、TCP和Socket的概念和原理及其区别一、HTTPHTTP简介 ①HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。②HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。③HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。它于1990年提出，经过几年的使用与发展，得到不断地完善和扩展。目前在WWW中使用的是HTTP/1.0的第六版，HTTP/1.1的规范化工作正在进行之中，而且HTTP-NG(Next Generation of HTTP)的建议已经提出。④HTTP协议工作于客户端-服务端架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。 HTTP的主要特点主要特点 1、简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 2、灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 3.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 4.无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 5、支持B/S及C/S模式。 HTTP的理解（此段摘抄于 Http协议与TCP协议简单理解后续）一、 TCP协议对应于传输层，而HTTP协议对应于应用层，从本质上来说，二者没有可比性。Http协议是建立在TCP协议基础之上的，当浏览器需要从服务器获取网页数据的时候，会发出一次Http请求。Http会通过TCP建立起一个到服务器的连接通道，当本次请求的数据完毕后，Http会立即将TCP连接断开，这个过程是很短的。所以Http连接是一种短连接，是一种无状态的连接。所谓的无状态，是指浏览器每次向服务器发起请求的时候，不是通过一个连接，而是每次都建立一个新的连接。如果是一个连接的话，服务器进程中就能保持住这个连接并且在内存中记住一些信息状态。而每次请求结束后，连接就关闭，相关的内容就释放了，所以记不住任何状态，成为无状态连接。 二、 随着时间的推移，html页面变得复杂了，里面可能嵌入了很多图片，这时候每次访问图片都需要建立一次tcp连接就显得低效了。因此Keep-Alive被提出用来解决效率低的问题。从HTTP/1.1起，默认都开启了Keep-Alive，保持连接特性，简单地说，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。虽然这里使用TCP连接保持了一段时间，但是这个时间是有限范围的，到了时间点依然是会关闭的，所以我们还把其看做是每次连接完成后就会关闭。后来，通过Session, Cookie等相关技术，也能保持一些用户的状态。但是还是每次都使用一个连接，依然是无状态连接 三、 为什么Http是无状态的短连接呢？而TCP是有状态的长连接？Http不是建立在TCP的基础上吗，为什么还能是短连接？现在明白了，Http就是在每次请求完成后就把TCP连接关了，所以是短连接。而我们直接通过Socket编程使用TCP协议的时候，因为我们自己可以通过代码区控制什么时候打开连接什么时候关闭连接，只要我们不通过代码把连接关闭，这个连接就会在客户端和服务端的进程中一直存在，相关状态数据会一直保存着。 四、 比较形象的描述：HTTP是轿车，提供了封装或者显示数据的具体形式;Socket是发动机，提供了网络通信的能力。对于从C#编程的角度来讲，为了方便，你可以直接选择已经制造好的轿车Http来与服务器交互。但是有时候往往因为环境因素或者其他的一些定制的请求，必须要使用TCP协议，这时就需要使用Socket编程，然后自己去处理获取的数据。就像是你用已有的发动机，自己造了一辆卡车，去从服务器交互。 HTTP都把TCP作为底层的传输协议。HTTP客户首先发起建立与服务器TCP连接。一旦建立连接，浏览器进程和服务器进程就可以通过各自的套接字来访问TCP。如前所述，客户端套接字是客户进程和TCP连接之间的“门”，服务器端套接字是服务器进程和同一TCP连接之间的“门”。客户往自己的套接字发送HTTP请求消息，也从自己的套接字接收HTTP响应消息。类似地，服务器从自己的套接字接收HTTP请求消息，也往自己的套接字发送HTTP响应消息。客户或服务器一旦把某个消息送入各自的套接字，这个消息就完全落入TCP的控制之中。TCP给HTTP提供一个可靠的数据传输服务;这意味着由客户发出的每个HTTP请求消息最终将无损地到达服务器，由服务器发出的每个HTTP响应消息最终也将无损地到达客户。 HTTP的请求方法根据HTTP标准，HTTP请求可以使用多种请求方法。 HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法。 HTTP1.1新增了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT 方法。 12345678GET 请求指定的页面信息，并返回实体主体。HEAD 类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。PUT 从客户端向服务器传送的数据取代指定的文档的内容。DELETE 请求服务器删除指定的页面。CONNECT HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。OPTIONS 允许客户端查看服务器的性能。TRACE 回显服务器收到的请求，主要用于测试或诊断。 HTTP的工作原理HTTP协议定义Web客户端如何从Web服务器请求Web页面，以及服务器如何把Web页面传送给客户端。HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。 以下是 HTTP 请求/响应的步骤： 123456789101112131415161718192021221、客户端连接到Web服务器 一个HTTP客户端，通常是浏览器，与Web服务器的HTTP端口（默认为80）建立一个TCP套接字连接。2、发送HTTP请求 通过TCP套接字，客户端向Web服务器发送一个文本的请求报文，一个请求报文由请求行、请求头部、空行和请求数据 四部分组成。3、服务器接受请求并返回HTTP响应 Web服务器解析请求，定位请求资源。服务器将资源复本写到TCP套接字，由客户端读取。一个响应由状态行、响应头部、 空行和响应数据4部分组成。4、释放连接[TCP连接](http://www.jianshu.com/p/ef892323e68f) 若connection 模式为close，则服务器主动关闭[TCP连接](http://www.jianshu.com/p/ef892323e68f)， 客户端被动关闭连接，释放[TCP连接](http://www.jianshu.com/p/ef892323e68f);若connection 模式为 keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求;5、客户端浏览器解析HTML内容 客户端浏览器首先解析状态行，查看表明请求是否成功的状态代码。然后解析每一个响应头，响应头告知以下为若干字节的 HTML文档和文档的字符集。客户端浏览器读取响应数据HTML，根据HTML的语法对其进行格式化，并在浏览器窗口中显示。 例如：在浏览器地址栏键入URL，按下回车之后会经历以下流程： 1、浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址; 2、解析出 IP 地址后，根据该 IP 地址和默认端口 80，和服务器建立[TCP连接] (http://www.jianshu.com/p/ef892323e68f); 3、浏览器发出读取文件(URL 中域名后面部分对应的文件)的HTTP 请求，该请求报文作为 [TCP 三次握手](http://www.jianshu.com/p/ef892323e68f)的第三个报文的数据发送给服务器; 4、服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器; 5、释放 [TCP连接](http://www.jianshu.com/p/ef892323e68f); 6、浏览器将该 html 文本并显示内容; 二、TCP协议TCP协议主要是在传输层，三次握手四次挥手①三次握手在TCP/IP协议中，TCP协议通过三次握手建立一个可靠的连接 三次握手 123456第一次握手：客户端尝试连接服务器，向服务器发送syn包（同步序列编号Synchronize Sequence Numbers）， syn=j，客户端进入SYN_SEND状态等待服务器确认第二次握手：服务器接收客户端syn包并确认（ack=j+1），同时向客户端发送一个SYN包（syn=k），即SYN+ACK包， 此时服务器进入SYN_RECV状态第三次握手：第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕， 客户端和服务器进入ESTABLISHED状态，完成三次握手 ②四次挥手由于TCP连接时全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭，下图描述的即是如此。 123456第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。 第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号）， Server进入CLOSE_WAIT状态。 第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。 第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1， Server进入CLOSED状态，完成四次挥手。 四次挥手 三、Scoket1、socket概念套接字（socket）是通信的基石，是支持TCP/IP协议的网络通信的基本操作单元。它是网络通信过程中端点的抽象表示，包含进行网络通信必须的五种信息：连接使用的协议，本地主机的IP地址，本地进程的协议端口，远地主机的IP地址，远地进程的协议端口。 一个Socket是一对IP地址和端口。 Socket可以看成在两个程序进行通讯连接中的一个端点，一个程序将一段信息写入Socket中，该Socket将这段信息发送给另外一个Socket中，使这段信息能传送到其他程序中。 2、socket的作用应用层通过传输层进行数据通信时，TCP和UDP会遇到同时为多个应用程序进程提供并发服务的问题。为了区别不同的应用程序进程和连接，许多计算机操作系统为应用程序与TCP／IP协议交互提供了称为套接字(Socket)的接口，区分不同应用程序进程间的网络通信和连接。 3、socket的原理3.1 socket的实现方式生成套接字，主要有3个参数：通信的目的IP地址、使用的传输层协议(TCP或UDP)和使用的端口号。Socket原意是“插座”。通过将这3个参数结合起来，与一个“插座”Socket绑定，应用层就可以和传输层通过套接字接口，区分来自不同应用程序进程或网络连接的通信，实现数据传输的并发服务。 Host A上的程序A将一段信息写入Socket中，Socket的内容被Host A的网络管理软件访问，并将这段信息通过Host A的网络接口卡发送到Host B，Host B的网络接口卡接收到这段信息后，传送给Host B的网络管理软件，网络管理软件将这段信息保存在Host B的Socket中，然后程序B才能在Socket中阅读这段信息。 3.2 Socket连接的实现方式要通过互联网进行通信，至少需要一对套接字，一个运行于客户机端，称之为ClientSocket，另一个运行于服务器端，称之为serverSocket。 根据连接启动的方式以及本地套接字要连接的目标，套接字之间的连接过程可以分为三个步骤：服务器监听，客户端请求，连接确认。 123456服务器监听：是服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态。客户端请求：是指由客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须 首先描述它要连接的服务器的套接字，指出服务器端套接字的地址和端口号，然后就向服务器端套接字提出连接请求。连接确认 ：是指当服务器端套接字监听到或者说接收到客户端套接字的连接请求，它就响应客户端套接字的请求， 建立一个新的线程，把服务器端套接字的描述发给客户端，一旦客户端确认了此描述，连接就建立好了。 而服务器端套接字继续处于监听状态，继续接收其他客户端套接字的连接请求。 3.3 Socket与TCP/IP的关系 创建Socket连接时，可以指定使用的传输层协议，Socket可以支持不同的传输层协议（TCP或UDP），当使用TCP协议进行连接时，该Socket连接就是一个TCP连接。socket则是对TCP/IP协议的封装和应用（程序员层面上）。也可以说，TPC/IP协议是传输层协议，主要解决数据 如何在网络中传输，而HTTP是应用层协议，主要解决如何包装数据。关于TCP/IP和HTTP协议的关系，网络有一段比较容易理解的介绍：“我们在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如 果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议，应用层协议有很多，比如HTTP、FTP、TELNET等，也 可以自己定义应用层协议。WEB使用HTTP协议作应用层协议，以封装HTTP文本信息，然后使用TCP/IP做传输层协议将它发到网络上。”我们平时说的最多的socket是什么呢，实际上socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口（API），通过Socket，我们才能使用TCP/IP协议。 实际上，Socket跟TCP/IP协议没有必然的联系。Socket编程接口在设计的时候，就希望也能适应其他的网络协议。所以说，Socket的出现 只是使得程序员更方便地使用TCP/IP协议栈而已，是对TCP/IP协议的抽象，从而形成了我们知道的一些最基本的函数接口，比如create、 listen、connect、accept、send、read和write等等。网络有一段关于socket和TCP/IP协议关系的说法比较容易理解：“TCP/IP只是一个协议栈，就像操作系统的运行机制一样，必须要具体实现，同时还要提供对外的操作接口。这个就像操作系统会提供标准的编程接口，比如win32编程接口一样，TCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口。”实际上，传输层的TCP是基于网络层的IP协议的，而应用层的HTTP协议又是基于传输层的TCP协议的，而Socket本身不算是协议，就像上面所说，它只是提供了一个针对TCP或者UDP编程的接口。socket是对端口通信开发的工具,它要更底层一些. 3.4 Socket与HTTP的关系 由于通常情况下Socket连接就是TCP连接，因此Socket连接一旦建立，通信双方即可开始相互发送数据内容，直到双方连接断开。但在实际网络应用中，客户端到服务器之间的通信往往需要穿越多个中间节点，例如路由器、网关、防火墙等，大部分防火墙默认会关闭长时间处于非活跃状态的连接而导致 Socket 连接断连，因此需要通过轮询告诉网络，该连接处于活跃状态。而HTTP连接使用的是“请求—响应”的方式，不仅在请求时需要先建立连接，而且需要客户端向服务器发出请求后，服务器端才能回复数据。 很多情况下，需要服务器端主动向客户端推送数据，保持客户端与服务器数据的实时与同步。此时若双方建立的是Socket连接，服务器就可以直接将数据传送给客户端；若双方建立的是HTTP连接，则服务器需要等到客户端发送一次请求后才能将数据传回给客户端，因此，客户端定时向服务器端发送连接请求，不仅可以保持在线，同时也是在“询问”服务器是否有新的数据，如果有就将数据传给客户端。 http协议是应用层的协义 有个比较形象的描述：HTTP是轿车，提供了封装或者显示数据的具体形式；Socket是发动机，提供了网络通信的能力。 总结：从上面的详细了解HTTP、TCP和Socket的概念和原理及其区别，相信对这三者有一个了解和熟悉。]]></content>
      <tags>
        <tag>-协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新特征-Lambda表达式与Stream-API]]></title>
    <url>%2F2019%2F11%2F18%2FJava8%E6%96%B0%E7%89%B9%E5%BE%81-Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%B8%8EStream-API%2F</url>
    <content type="text"><![CDATA[Java8 新特性 速度更快 更换了数据结构，内存结构（JVM） *代码更少了（Lambda表达式） * *强大的Stream API * 便于并行 fork join (串行切换并行) 最大化减少空指针异常 Optional Lambda表达式 在说 Lambda 之前，首先要说的是函数式接口。这个可以说是为了 Lambda 表达式而存在的一个东西。那么什么是函数式接口？ 函数式接口定义： 接口中只有一个抽象接口。 像 java.util.function 下的所有接口都是函数式接口。Java1.8提供@FunctionalInterface检测一个接口是否是一个函数式接口。 “-&gt;” 是 lambda 表达式的符号 左侧表示函数式接口中抽象方法的参数列表，右侧表示你对这个方法的实现 四大函数式接口我们一般对函数式接口的使用的时候，都会对其进行封装。 消费性接口​ Consumer 只有一个抽象方法名为 accept，参数列表只有一个泛型t，无返回值。参数的数据类型有类决定 1234567891011121314/** * @ClassName ConsumerTest * @Description 消费型接口， 消费字符串字段 打印输出 **/public class ConsumerTest &#123; public static void main(String[] args) &#123; test("hello",x-&gt; System.out.println(x)); &#125; public static &lt;T&gt; void test(T t, Consumer&lt;T&gt; consumer) &#123; consumer.accept(t); &#125;&#125; 输出：hello 如果需要多个参数列表的话，也可以在 java.util.function 包下找到相应的函数式接口 比如 ObjLongConsumer。其他的可以自行查看 供给型接口Supplier 只有一个抽象方法名为 get，参数列表为空，有返回值，返回值得数据类型为T。 123456789101112131415/** * @ClassName SupplerTest * @Description 供给型接口 字符串拼接 **/public class SupplerTest &#123; public static void main(String[] args) &#123; String hello = test("hello ", () -&gt; "word!"); System.out.println(hello); &#125; public static String test(String str,Supplier&lt;String&gt; supplier)&#123; return str + supplier.get(); &#125;&#125; 输出为：hello word! 如果需要返回得数据为基本数据类型，可以在 java.util.function 包下找到相应的函数式接口 比如：getAsLong 其他的可以自行查看 函数型接口​ Function&lt;T, R&gt; 只有一个抽象方法名为 apply，参数列表只有一个参数为T，有返回值，返回值的数据类型为R。（借鉴scala学习） 1234567891011121314151617/** * @ClassName FunctionTest * @Description 函数式接口 将字符串转换成大写的 **/public class FunctionTest &#123; public static void main(String[] args) &#123; String test = test("hello", x -&gt; x.toUpperCase()); System.out.println(test); &#125; public static String test(String str , Function&lt;String,String&gt; function)&#123; return function.apply(str); &#125;&#125; 输出为：HELLO 如果需要多个入参，然后又返回值的话，可以在 java.util.function 包下找到相应的函数式接口 比如 BiFunction。其他的可以自行查看 断言型接口​ 断言型又名判断型。 Predicate 只有一个抽象方法名为 test，参数列表只有一个参数为 T，有返回值，返回值类型为 boolean。 12345678910111213141516/** * @ClassName PredicateTest * @Description 断言型接口，判断字符串大小是否大于6 * @Author ouyangkang * @Date 2019-02-18 16:16 **/public class PredicateTest &#123; public static void main(String[] args) &#123; boolean hello = test("hello", x -&gt; x.length() &gt; 6); System.out.println(hello); &#125; public static boolean test(String str, Predicate&lt;String&gt; predicate)&#123; return predicate.test(str); &#125;&#125;复制代码 输出为： false Stream API​ Stream 作为 Java 8 的一大亮点，它与 java.io 包里的 InputStream 和 OutputStream 是完全不同的概念。Stream中间操作，多个中间操作可以连接起来形成一个流水线，除非流水线上触发了终止操作，否则中间不会执行任何处理！而终止操作时会一次性全部处理，称为惰性处理。要进行流操作首先要获取流。有4中方法可以获取流。 集合获取流 通过集合系列提供的stream方法和 parallelStream()（并行流）方法获取流 12345public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); // 常用获取流的方式 Stream&lt;Integer&gt; stream = list.stream();&#125; 2.通过Arrays.stream() 将数组转换成流 12345public static void main(String[] args) &#123; int[] a = new int[]&#123;1,2,3,4&#125;; IntStream stream = Arrays.stream(a); &#125; 3.通过Stream.of的方法创建流 123public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3);&#125; 4.创建无限流 123public static void main(String[] args) &#123; Stream&lt;Integer&gt; iterate = Stream.iterate(0, x -&gt; x + 2);&#125; 所有的对流的操作可以分为4种，分别为筛选与分片，映射，排序，终结（归约，收集） 中间操作主要有以下方法（此类型方法返回的都是Stream）：map (mapToInt, flatMap 等)、 filter、 distinct、 sorted、 peek、 limit、 skip、 parallel、 sequential、 unordered 终止操作主要有以下方法：forEach、 forEachOrdered、 toArray、 reduce、 collect、 min、 max、 count、 anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 iterator 筛选与分片操作有 filter ,distant,limit,skip。 filter ： 过滤操作,方法参数为*断言型接口 * 1234public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3); stream.filter(x-&gt;x != 2).forEach(x-&gt; System.out.println(x)); &#125; 输出： 1213 distinct ： 去重操作，方法无参数 limit ： 获取前几条数据，*方法参数为long * skip ： 跳过前多少条数据，然后获取后面所有的。方法参数为long 映射常用操作有 map ，flatMap。 map: 对原数据进行处理，并返回处理后的数据。 方法参数为函数型接口 1234public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3); stream.map(x-&gt;x*2).forEach(System.out::println); &#125; 输出： 123246 flatMap ： 使原来流种的原有数据一个一个整合在另一个流中。方法参数为函数型接口，但是返回值为流 12345public static void main(String[] args) &#123; List&lt;String&gt; list = Arrays.asList("a", "b", "c"); List&lt;String&gt; list2 = Arrays.asList("f","d"); list.stream().flatMap(x-&gt;list2.stream().map(y-&gt; x + y)).forEach(System.out::println);&#125; 排序常用操作有sort自然排序，合sort参数为排序器的定制排序 自然排序 1234public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3); stream.sorted().forEach(System.out::println); &#125; 输出： 123123 定制排序（(x,y)-&gt;-Integer.compare(x,y)） 12345 public static void main(String[] args) &#123; Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3); stream.sorted((x,y)-&gt;-Integer.compare(x,y)).forEach(System.out::println); &#125;复制代码 输出： 123321 终止操作 allMatch 检查是否匹配所有元素 方法参数为断言型接口 anyMatch 检查是否匹配所有元素 方法参数为断言型接口 noneMatch 检查是否没有匹配所有元素 方法参数为断言型接口 findFirst 返回第一个元素 无方法参数 findAny 返回当前流的任意元素 无方法参数 count 返回流中的元素总个数 无方法参数 max 返回流的最大值 无方法参数 min 返回流中的最小值 无方法参数 归约reduce : 归约 – 可以将流中的元素反复结合起来，得到一个值 12345public static void main(String[] args) &#123; List&lt;Integer&gt; list1 = Arrays.asList(1,2,3,4,5,6,7,8,9,10); Integer reduce = list1.stream().reduce(11, (x, y) -&gt; x + y); System.out.println(reduce); &#125; 输出 ： 66 收集​ 这个是非常常用的一个操作。 将流装换为其他形式。接收到一个Collector接口的实现，用于给Stream中的元素汇总的方法。用collect方法进行收集。方法参数为Collector。Collector可以由Collectors中的toList()，toSet(),toMap(Function(T,R) key,Function(T,R) value)等静态方法实现。 toList() 返回一个 Collector ，它将输入元素 List到一个新的 List 。 toMap(Function&lt;? super T,? extends K&gt; keyMapper, Function&lt;? super T,? extends U&gt; valueMapper) 返回一个 Collector ，它将元素累加到一个 Map ，其键和值是将所提供的映射函数应用于输入元素的结果。 toSet() 返回一个 Collector ，将输入元素 Set到一个新的 Set 。 eg: User类 1234567891011121314151617181920@Data@ToStringpublic class User &#123; private String name; private Integer age; private Integer salary;&#125; public static void main(String[] args) &#123; List&lt;User&gt; users = Arrays.asList(new User("张三", 19, 1000), new User("张三", 58, 2000), new User("李四", 38, 3000), new User("赵五", 48, 4000) ); List&lt;String&gt; collect = users.stream().map(x -&gt; x.getName()).collect(Collectors.toList()); Set&lt;String&gt; collect1 = users.stream().map(x -&gt; x.getName()).collect(Collectors.toSet()); Map&lt;Integer, String&gt; collect2 = users.stream().collect(Collectors.toMap(x -&gt; x.getAge(), x -&gt; x.getName())); System.out.println(collect); System.out.println(collect1); System.out.println(collect2); &#125; 输出： 123[张三, 张三, 李四, 赵五][李四, 张三, 赵五]&#123;48=赵五, 19=张三, 38=李四, 58=张三&#125; 分组​ Collectors.groupingBy()方法是 返回 Collector “由基团”上的类型的输入元件操作实现 T ，根据分类功能分组元素。这个是非常常用的操作。 比如你要对名字相同的进行分组。 groupingBy(Function&lt;? super T,? extends K&gt; classifier) eg: 123456789public static void main(String[] args) &#123; List&lt;User&gt; users = Arrays.asList(new User("张三", 19, 1000), new User("张三", 58, 2000), new User("李四", 38, 3000), new User("赵五", 48, 4000) ); Map&lt;String, List&lt;User&gt;&gt; collect3 = users.stream().collect(Collectors.groupingBy(x -&gt; x.getName())); System.out.println(collect3);&#125; 输出：{李四=[User{name=’李四’, age=38, salary=3000}], 张三=[User{name=’张三’, age=19, salary=1000}, User{name=’张三’, age=58, salary=2000}], 赵五=[User{name=’赵五’, age=48, salary=4000}]} 当然还有其他的一些比较复杂的分组操作，实际代码看业务来进行实现。 总结​ java8中的lambda表达式可能一开始用的时候还不是很熟悉，但是只要熟悉了，你会发现非常的好用，而且lambda表达式结合stream API可以进行编写自己的工具类。在平常项目中可以非常的省时间，提高写代码的效率。我现在给出一个List转Map的工具类。 123456789101112131415161718192021222324252627282930public class CollectionStream &#123; public static void main(String[] args) &#123; List&lt;User&gt; users = Arrays.asList(new User("张三", 19, 1000), new User("张三", 58, 2000), new User("李四", 38, 3000), new User("赵五", 48, 4000) ); Map&lt;Integer, Integer&gt; map = listToMap(users, x -&gt; x.getAge(), x -&gt; x.getSalary()); System.out.println(map); &#125; /** * @Description list 转map key不能相同 ，如果相同会报错。 方法对 源数据，key，value过滤null。 * @param source 源数据 * @param key * @param value * @return java.util.Map&lt;K,V&gt; **/ public static &lt;DTO, K, V&gt; Map&lt;K, V&gt; listToMap(List&lt;DTO&gt; source, Function&lt;? super DTO, ? extends K&gt; key, Function&lt;? super DTO, ? extends V&gt; value) &#123; Objects.requireNonNull(source, "source not null"); Objects.requireNonNull(key, "key not null"); Objects.requireNonNull(value, "value not null"); Map&lt;K, V&gt; map = source.stream() .filter(dto -&gt; dto != null) .filter(dto -&gt; key.apply(dto) != null) .filter(dto -&gt; value.apply(dto) != null) .collect(Collectors.toMap(key, value)); return map; &#125;&#125;]]></content>
      <tags>
        <tag>-lambda -Stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[观察者模式]]></title>
    <url>%2F2019%2F10%2F29%2F%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[模式定义观察者模式是对象行为模式，又叫发布-订阅模式（publish/subscribe）模式，源-监视器模式（source/Listener)模式。 观察者模式定义了一种一对多的依赖关系，让多个观察者对象同事监听某一个主题对象，这个主题对象在状态上发生变化时，会通知所有观察者对象，使他们能够做出相应的操作。 模式结构软件系统中，常常因为一个对象的状态发生改变时，某些其他对象做出相应的改变，做到这一点的设计方案有很多，但为了系统稳定性，选择低耦合的观察者模式，有助于系统的复用，保证高度协作。 模式描述意图：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 主要解决：一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。 何时使用：一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。 如何解决：使用面向对象技术，可以将这种依赖关系弱化。 关键代码：在抽象类里有一个 ArrayList 存放观察者们。 使用场景： 一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将这些方面封装在独立的对象中使它们可以各自独立地改变和复用。 一个对象的改变将导致其他一个或多个对象也发生改变，而不知道具体有多少对象将发生改变，可以降低对象之间的耦合度。 一个对象必须通知其他对象，而并不知道这些对象是谁。 需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 角色 抽象主题（Subject)角色：抽象主题角色把所有对观察者对象的引用保存在一个聚集（比如ArrayList)里，每一个主题都可以有任何数量的观察者。抽象主题提供一个接口（抽象类)，可以增加和删除观察者，抽象主题角色又叫抽象被观察者（Observable)角色。 具体主题（ConcreteSubject)角色：将有关状态存入具体的观察者对象；在具体主题的内部状态改变时，给所有登录订阅过的观察者发送通知。具体主题对象又叫具体被观察者（Concrete Observable）角色。 抽象观察者(Observer)角色：给所有的具体观察者定义一个接口，在得到主题的通知时更新自己，这个接口叫做更新接口。 具体观察者（Concrete Observer）角色：存储与主题的状态自恰的状态，具体观察者实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题相协调，具体观察者可以保持一个指向具体主题对象的引用。 实现代码示例： 抽象主题类 12345678910111213141516171819202122232425262728293031public abstract class Subject &#123; /** * 用来保存注册的观察者对象 */ private List&lt;Observer&gt; list = new ArrayList&lt;Observer&gt;(); /** * 注册观察者对象 * @param observer 观察者对象 */ public void attach(Observer observer)&#123; list.add(observer); System.out.println("Attached an observer"); &#125; /** * 删除观察者对象 * @param observer 观察者对象 */ public void detach(Observer observer)&#123; list.remove(observer); &#125; /** * 通知所有注册的观察者对象 */ public void nodifyObservers(String newState)&#123; for(Observer observer : list)&#123; //推模式下，需要传入状态 //拉模式下，不需要传入状态 observer.update(newState); &#125; &#125;&#125; 具体主题角色类： 1234567891011121314public class ConcreteSubject extends Subject&#123; private String state; public String getState() &#123; return state; &#125; public void change(String newState)&#123; state = newState; System.out.println("主题状态为：" + state); //状态发生改变，通知各个观察者 //在推模式下，需要传入参数 //拉模式下，不需要传入参数 this.nodifyObservers(state);//调用父类定义方法 &#125;&#125; 抽象观察者角色类： 1234567public interface Observer &#123; /** * 更新接口 * @param state 更新的状态 */ public void update(String state);&#125; 具体观察者角色类： 123456789101112public class ConcreteObserver implements Observer &#123; //观察者的状态 private String observerState; @Override public void update(String state) &#123; /** * 更新观察者的状态，使其与目标的状态保持一致 */ observerState = state; System.out.println("状态为："+observerState); &#125;&#125; 客户端： 123456789101112public class Client &#123; public static void main(String[] args) &#123; //创建主题对象 ConcreteSubject subject = new ConcreteSubject(); //创建观察者对象 Observer observer = new ConcreteObserver(); //将观察者对象登记到主题对象上 subject.attach(observer); //改变主题对象的状态 subject.change("new state"); &#125;&#125; 推模式和拉模式推模式上面的例子就是典型的推模式，主题对象向观察者推送详细信息。 拉模式主题对象在通知观察者的时候，只传递少量信息。如果观察者需要更具体的信息，由观察者主动到主题对象中获取，相当于是观察者从主题对象中拉数据。一般这种模型的实现中，会把主题对象自身通过update()方法传递给观察者，这样在观察者需要获取数据的时候，就可以通过这个引用来获取了。 调用观察者的方法时，不需要传入参数 观察者模式与订阅模式 观察者注册到目标；目标发生改变时，调用观察者方法 订阅者把自己想订阅的事件注册到调度中心，当该事件触发时候，发布者发布该事件到调度中心（顺带上下文），由调度中心统一调度订阅者注册到调度中心的处理代码 总结 从两张图片可以看到，最大的区别是调度的地方。 虽然两种模式都存在订阅者和发布者（具体观察者可认为是订阅者、具体目标可认为是发布者），但是观察者模式是由具体目标调度的，而发布/订阅模式是统一由调度中心调的，所以观察者模式的订阅者与发布者之间是存在依赖的，而发布/订阅模式则不会。 两种模式都可以用于松散耦合，改进代码管理和潜在的复用。]]></content>
      <tags>
        <tag>-设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基本注解]]></title>
    <url>%2F2019%2F10%2F28%2FJava%E5%9F%BA%E6%9C%AC%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Annotation的概念与作用元数据（MeteData）也就是Annotation，这是一种代码里的特殊标志，可在编译，类加载，运行时被读取。 Annotation就像修饰符一样，可用于修饰包，类，构造器，方法， 成员变量，参数，局部变量的声明，这些信息被存储到Annotation的“name=value”对中 Annotation是一个接口，程序通过反射来获取指定程序元素的Annotation对象，然后通过Annotation对象来获取注释里的元数据 基本Annotation 四种基本的Annotation如下： @Override @Deprecated @SuppressWarinings @SafeVarargs @Override注解的功能与用法@Override用来制定方法覆盖度，强制一个子类必须覆盖父类的方法；用于避免普通子类没覆盖父类抽象方法，方法名写错 @Deprecated注解的功能与用法@Deprecated用于表示某个程序元素（方法，类等）已过时，当使用过时类，方法时，会发出警告信息 @SuppressWarinings注解的功能与用法@SuppressWarinings指示被该Annotation修饰的程序元素（以及该程序元素的所有子元素）取消显示指定的编译器错误 @SafeVarargs注解的功能与用法@SafeVarargs用于解决“堆污染”警告 “堆污染”：当把一个不带泛型的对象赋值给一个带泛型的变量时，往往会产生堆污染 JDK的元Annotation上面四个基本注解是在java.lang包下的， 此外还在java.lang.annotation包下提供4个Meta Annotation，这四个Annotation都用于修饰其他的Annotation的定义 @Retention @Target @Document @Inherited @Retention注解的功能与用法@Retention只能用于修饰一个Annotation定义，指定被修饰的Annotation可以保留多长时间 @Retention包含一个RetentionPolicy类型的value成员变量，使用@Retention必须为改对象指定值 value值分别有： RetentionPolicy.CLASS:默认值，记录在class文件中 RetentionPolicy.RUNTIME:JVM保留该Annotation，程序可以通过反射获取该Annotation信息 RetentionPolicy.SOURCE:保留源代码中，编译器丢弃该Annotation @Target注解的功能与用法@Target用于修饰一个Annotation定义，用于指定被修饰的Annotation能用于修饰哪些程序单元 value值分别有： ElementType.ANNOTATION_TYPE:指定该策略的Annotation只能用于修饰Annotation ElementType.CONSTRUCTOR:只能修饰构造器 ElementType.FIFLD:只能修饰成员变量 ElementType.LOCAL_VARIABLE:只能修饰局部变量 ElementType.METHOD:修饰方法定义 ElementType.PACKAGE:修饰包的定义 ElementType.PARAETER:修饰参数 ElementType.TYPE:可以修饰类、接口（包括注解类型）或枚举定义 @Document注解的功能与用法@Document用于该Annotation将被javadoc工具提取成文档 @Inherited注解的功能与用法@Inherited元Annotation指定被它修饰的Annotation将具有继承性。 如果某个类用包含@Inherited的Annotation，则该子类将自动也使用该Annotation 自定义Annotation定义一个新的Annotation类型使用@interface关键字。 1234public @interface TESTAnnotation&#123; ...&#125; 可定义Annotation的成员变量，并且该变量可以指定初始值，用关键字default 12345public @interface MyTag&#123; String name() default "zhengkai"; int age() default 18; &#125; 该Annotation定义俩个成员变量，并且已经有初始值 **当开发者使用Annotation修饰类，方法，Filed等成员之后，这些Annotation并不会生效，必须有开发者提供相应的工具来提取并处理Annotation信息 运行时Annotationjava.lang.reflect包下提供了获取Annotation的AnnotationElenment接口，程序可调用如下三个方法获取Annotation信息 getAnnotation(Class annotationClass)：获得程序元素的注解，不存在返回null Annotations[]：获取程序元素上所有的注解 isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass):判断该程序元素是否存在注解]]></content>
      <tags>
        <tag>-注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive数据仓库基础知识]]></title>
    <url>%2F2019%2F10%2F22%2FHive%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[数据仓库Hive产生背景MapReduce编程门槛高，无法及时应对需求的变更 传统RDBMS（关系型数据库）人员的需求，HDFS上的文件并没有schema的概念 可通过Hive进行大数据的处理 Hive概述有Facebook开源，用于解决海量结构化日志的数据统计问题 构建在Hadoop之上的数据仓库（计算能力，存储能力，可应付数据的暴增） Hive提供的SQL查询语言：HQL 底层支撑多种不同的执行引擎 Hive底层执行引擎支持：MR/Tez/Spark（用户不感知） ###为什么要使用Hive 简单，容易上手 为超大数据集设计的计算/扩展能力 同一的元数据管理：Hive数据是存放在HDFS上，元数据信息（记录数据(HDFS数据)的数据）是存放在MySQL中 SQL on Hadoop:Hive,Spark,SQL,impala… Hive是一个离线框架，不适合实时查询 Hive体系架构Hive 在Hadoop生态中的位置 体系架构图： client：shell、thrift/jdbc(server/jdbc)、webUI(HUE/Zeppelin) metastore:==&gt;MySQL database:name/location/owner... table:name、location、owner、column、name/type...Hive：写SQL翻译成MapReduce，放入到Hadoop Hive部署架构 测试环境 客户端把SQL提交Hive引擎，元数据信息可存放在Derby中（只能进行单客户端的操作，就是单session）即使是测试环境也不推荐使用，因此只能选择MySQL 生产环境：为了防止MySQL错误导致无法进行获取元数据信息，因此得有主备MySQL，主备MySQL会进行切换。（解决MySQL单点问题） Hadoop集群：DN、NM、NN、RM Hive提交到RM上，Hadpoop集群有很多节点，Hive是一个客户端，并不涉及集群的概念 Hive与RDBMS的区别 支持的：都支持分布式 区别的：Hive不适合立马进行查询 Hive部署及快速入门包：hive-1.*.0cdh.5 *. *tar-gz *bin目录：脚本 *conf目录：配置 1 下载 2解压的 ~/app 3添加Hive-HOME到系统环境变量 4修改配置 5拷贝MySQL驱动包 6预先下载MySQL数据库 Hive DDL详解可以创建一张表，把数据加入到表中，对数据的各种维度的分析 create/delete/alter… Hive数据抽象/结构 database HDFS一个目录 table HDFS一个目录 data文件 partition分区表 HDFS一个目录 bucket分桶 HDFS一个文件 创建数据库1234CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name [COMMENT database_comment] [LOCATIO hdfs_path] [WITH DBPROPERTIES (property_name=property_value,...)]; 创建表12345678910111213CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name [(col_name data_type[COMMENT col_comment], ... [constraint_specification])] [COMMENT table_comment] [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] [ROW FORMAT row_format] [STORED AS file_format] [LOCATION hdfs_path] [TBLPROPERTIES (property_name=property_value, ...)] [AS select_statement];CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name LIKE existing_table_or_view_name [LOCATION hdfs_path]; 各项参数说明： 1CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常，一般也可以不加这个IF NOT EXISTS语句，最多抛出错误。 2 [constraint_specification]可选项： [ PRIMARY KEY|UNIQUE|NOT NULL|DEFAULT [default_value] 3 [COMMENT table_comment] 可选项：COMMENT 后面跟的字符串是给表字段或者表内容添加注释说明的 4 [PARTITIONED BY ] 可选项：PARTITIONED BY其实是给表做分区，决定了表是否是分区表。（Hive中所谓分区表就是将表里新增加一个字段，就是分区的名字，这样你在操作表中的数据时，可以按分区字段进行过滤） 5 [CLUSTERED BY ]可选项：CLUSTERED BY对于每一个表（table）或者分区， Hive可以进一步组织成桶，也就是说桶是更为细粒度的数据范围划分。Hive也针对某一列进行桶的组织。Hive采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中 6 [ROW FORMAT]可选项：存储表格式 7 [STORED AS] 可选项：hive存储的三种文件格式 8 [LOCATION AS] 可选项：LOCATION 其实是定义hive表的数据在hdfs上的存储路径，一般管理表（内部表不不要自定义），但是如果定义的是外部表，则需要直接指定一个路径。实际上不指定也没事，会使用默认路径 部分详解： 使用PARTITIONED BY子句创建分区表。一个表可以具有一个或多个分区列，并为分区列中的每个不同值组合创建一个单独的数据目录。此外，可以使用CLUSTERED BY列对表或分区进行存储，并且可以通过SORT BY列在该存储区中对数据进行排序。这样可以提高某些查询的性能。 eg: 12345678CREATE TABLE page_view(viewTime INT, userid BIGINT, page_url STRING, referrer_url STRING, ip STRING COMMENT &apos;IP Address of the User&apos;) COMMENT &apos;This is the page view table&apos; PARTITIONED BY(dt STRING, country STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\001&apos;STORED AS SEQUENCEFILE; 上面的语句创建带有viewTime，userid，page_url，referrer_url和ip列（包括注释）的page_view表。该表也被分区，数据存储在序列文件中,文件中的数据格式由ctrl-A分隔字段，由换行分隔行。 重命名表1ALTER TABLE table_name RENAME TO new_table_name; ####更改表属性 1`ALTER TABLE table_name SET TBLPROPERTIES table_properties;` `table_properties:`` ``: (property_name = property_value, property_name = property_value, ... )` table_properties : (property_name = property_value, property_name = property_value, … ) TBLPROPERTIES:允许您使用自己的元数据键/值对标记表定义;还存在一些预定义的表属性，由Hive自动添加和管理的last_modified_user和last_modified_time。 修改表注释：要更改表的注释，您必须更改的comment属性TBLPROPERTIES： 1`ALTER TABLE table_name SET TBLPROPERTIES (``&apos;comment&apos;` `= new_comment);` 重命名现有表的列1`ALTER TABLE old_table_name REPLACE COLUMNS (col1 TYPE, ...);` 将列添加到现有表1ALTER TABLE tab1 ADD COLUMNS (c1 INT COMMENT &apos;a new int column&apos;, c2 STRING DEFAULT &apos;def val&apos;); 删除表1`DROP TABLE pv_users;` 删除表分区(更改表以删除分区)：1`ALTER TABLE pv_users DROP PARTITION (ds=``&apos;2008-08-08&apos;``)` Hive查询操作记录在Select中，而插入操作记录在将数据从查询插入Hive表和从查询将数据写入文件系统中。 简单查询1`INSERT OVERWRITE TABLE user_active``SELECT user.*``FROM user``WHERE user.active = ``1``;` 请注意，与SQL不同，我们总是将结果插入表中。也可以将其转储到本地文件中。 也可以在Beeline 或Hive CLI中运行以下查询 ： 123SELECT user.*FROM userWHERE user.active = ``1``; 基于分区的查询1`INSERT OVERWRITE TABLE xyz_com_page_views``SELECT page_views.*``FROM page_views``WHERE page_views.date &gt;= ``&apos;2008-03-01&apos;` `AND page_views.date &lt;= ``&apos;2008-03-31&apos;` `AND`` ``page_views.referrer_url like ``&apos;%xyz.com&apos;``;` 系统根据分区列上的where子句条件自动确定要在查询中使用的分区。例如，为了获取域xyz.com引用的03/2008月份的所有page_views 请注意，此处使用page_views.date，因为该表（上面）是使用PARTITIONED BY（date DATETIME，country STRING）定义的；如果您给分区命名不同，请不要期望.date发挥您的想法！ 连接查询1234INSERT OVERWRITE TABLE pv_usersSELECT pv.*, u.gender, u.ageFROM user u JOIN page_view pv ON (pv.userid = u.id)WHERE pv.date = &apos;2008-03-03&apos;; 可以使用LEFT OUTER，RIGHT OUTER或FULL OUTER关键字限定联接，以指示外部联接的类型（保留的左侧，保留的右侧或两侧保留） 检查另一个表中是否存在键，用户可以使用LEFT SEMI JOIN]]></content>
      <tags>
        <tag>-Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[swagger2学习]]></title>
    <url>%2F2019%2F10%2F16%2Fswagger2%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[一、Swagger简介背景​ 在现在的开发流程中，为了最大程度实现前后端的分离，通常后端接口只提供数据接口，由前端通过Ajax请求从后端获取数据并进行渲染再展示给用户。我们用的最多的方式就是后端会返回给前端一个JSON字符串，前端解析JSON字符串生成JavaScript的对象，然后再做处理。 演化非Restful接口的支持 一个方法对应于一个端口方法映射，通常只有GET/POST方法对应CRUD，后期维护成本大，通常标签有： ​ @Controller 标识一个类为控制器。 @RequestMapping URL的映射。 @ResponseBody 返回结果转换为JSON字符串。 @RequestBody 表示接收JSON格式字符串参数。 Restful API设计 Restful API是一种编程风格，比起传统的通过get/post方法的接口设计，Restful API的设计则通过HTTP的方法来表示CRUD相关的操作。 123456接口URL | HTTP方法 | 接口说明-------| -------- |-------/article | POST | 保存文章/article/&#123;id&#125; | GET | 查询文章列表/article/&#123;id&#125; | DELETE | 删除文章/article/&#123;id&#125; | PUT | 修改文章 区别： ​ ①类上通常使用@RestController注解（spring4提供），表示返回Json数据的注解，支持Restful控制器。 ​ ②/article/{id}具有三个相同的URL映射，这在@Controller标识的类中是不允许出现的，而这通过method来进行区分，produces的作用是表示返回结果的类型是JSON。 ③@PathVariable这个注解（Spring MVC提供），作用是表示该变量的值是从访问路径中获取。 简介Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。总体目标是使客户端和文件系统作为服务器以同样的速度来更新。文件的方法，参数和模型紧密集成到服务器端的代码，允许API来始终保持同步。Swagger 让部署管理和使用功能强大的API从未如此简单。 二、Swagger与Spring boot集成①、导入相应jar包12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt; ②、基本信息配置12345678910111213141516171819202122232425262728293031323334353637@Configuration@EnableSwagger2public class SwaggerConfig &#123; @Bean public Docket docket()&#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() //当前包路径 .apis(RequestHandlerSelectors.basePackage("com.bmsoft.dc.dodp")) .paths(PathSelectors.any()).build(); &#125; @Bean public Docket docket1()&#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .groupName("caozifu") .select() .apis(RequestHandlerSelectors.basePackage("com.bmsoft.dc.dodp")) .paths(PathSelectors.any()).build(); &#125; /** * 构建api文档的详细信息函数 * */ private ApiInfo apiInfo()&#123; return new ApiInfoBuilder() //页面标题 .title("离线开发平台Restful接口管理") //版本号 .version("1.0") //描述 .description("API 描述") .build(); &#125;&#125; 标签说明： @Configuration是表示这是一个配置类，是JDK自带的注解 @EnableSwagger2的作用是启用Swagger2相关功能。 ​ 配置类里面我么实例化了一个Docket对象，这个对象主要包括三个方面的信息： ​ （1）整个API的描述信息，即ApiInfo对象包括的信息，这 部分信息会在页面上展示。 （2）指定生成API文档的包名。 （3）指定生成API的路径。按路径生成API可支持四种模式：任何路径都生成(any)、任何路径都不生成 (none)以及正则匹配(regex)和ant 模式匹配四种方式 ③、编写方法及其参数描述​ 编写相应的方法，并应方法中做出相应的参数描述，具体标签有： @ApiOperation 用在方法上，说明方法的作用，每一个url资源的定义,使用方式： 属性名称 备注 value url的路径值 ​ *tags 接口的标签，相同标签的接口会在一个标签页下展示。 notes 接口详细说明，展示在接口的详情页。 httpMethod 支持的HTTP的方法。 @ApiImplicitParams，@ApiImplicitParam的容器，可包含多个@ApiImplicitParam注解 @ApiImplicitParam，请求参数属性配置： 属性名称 备注 name 参数名称 value 参数说明 required 是否必须 dataType 数据类型 @ApiResponse，返回结果属性配置： 属性名称 备注 code 返回结果的编码 message 返回结果的说明 response 返回结果对应的类 示例 12345678910111213@ApiOperation(value = &quot;更新文章&quot;, notes = &quot;更新文章内容&quot;, tags = &quot;Article&quot;,httpMethod = &quot;PUT&quot;) @ApiImplicitParams(&#123; @ApiImplicitParam(name = &quot;id&quot;, value = &quot;文章ID&quot;, required = true, dataType = &quot;Long&quot;), @ApiImplicitParam(name = &quot;title&quot;, value = &quot;文章标题&quot;, required = false, dataType = &quot;String&quot;), @ApiImplicitParam(name = &quot;summary&quot;, value = &quot;文章摘要&quot;, required = false, dataType = &quot;String&quot;), @ApiImplicitParam(name = &quot;status&quot;, value = &quot;发布状态&quot;, required = false, dataType = &quot;Integer&quot;) &#125;) @RequestMapping(value = &quot;/article/&#123;id&#125;&quot;, method = PUT, produces = &quot;application/json&quot;) public WebResponse&lt;?&gt; updateArticle(@PathVariable Long id,@RequestBody Article article)&#123; article.setId(id); articleService.updateArticle(article); return WebResponse.getSuccessResponse(new HashMap&lt;&gt;()); &#125; 启动Spring boot，然后访问：http://127.0.0.1:8080/swagger-ui.html即可看到如下结果 页面显示： 其他常用标签 @API注解:用在类上，说明该类的作用。可以标记一个Controller类做为swagger 文档资源 12&gt; @Api(value = "/user", description = "Operations about user")&gt; 属性名称 备注 value url的路径值 tags 如果设置这个值、value的值会被覆盖 description 对api资源的描述 description 对api资源的描述 @ApiModel：描述一个Model的信息（这种一般用在post创建的时候，使用@RequestBody这样的场景，请求参数无法使用 @ApiModelProperty：描述一个model的属性]]></content>
      <tags>
        <tag>-swagger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis-plus学习]]></title>
    <url>%2F2019%2F10%2F14%2Fmybatis-plus%E4%B8%AA%E4%BA%BA%E8%A7%81%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[MyBatis-Plus（简称 MP）是一个 MyBatis 的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。mybatis-plus的特性​ ①无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑​ ②损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作​ ③强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求​ ④支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错​ ⑤支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题​ ⑥支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作​ ⑦支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ）​ ⑧内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用​ ⑨内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询​ ⑩分页插件支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer2005、SQLServer 等多种数据库 主要核心知识：Mapper CRUD接口说明: 通用 CRUD 封装BaseMapper接口，为 Mybatis-Plus 启动时自动解析实体表关系映射转换为 Mybatis 内部对象注入容器 泛型 T 为任意实体对象 参数 Serializable 为任意类型主键 Mybatis-Plus 不推荐使用复合主键约定每一张表都有自己的唯一 id 主键 对象 Wrapper 为 条件构造器 实际上是在Mybatis的mapper扫描文件进行了CURD增强， CRUD方法基本是insert、delete（ById,ByMap、BatchIds)、 update（ById)、select（ById、BathchIds、ByMap、One、Count、List、Maps、Objs、Page、MapsPage) 基本是通过Id,条件进行CRUD Service CRUD接口说明: 通用 Service CRUD 封装IService接口，进一步封装 CRUD 采用 get 查询单行 remove 删除 list 查询集合 page 分页 前缀命名方式区分 Mapper 层避免混淆， 泛型 T 为任意实体对象 建议如果存在自定义通用 Service 方法的可能，请创建自己的 IBaseService 继承 Mybatis-Plus 提供的基类 对象 Wrapper 为 条件构造器 条件构造器说明: 介绍 上图绿色框为抽象类abstract 蓝色框为正常class类，可new对象 黄色箭头指向为父子类关系，箭头指向为父类 方法入参boolean condition表示该条件是否加入最后生成的sql中 方法均为从上往下补全个别boolean类型的入参,默认为true 出现的泛型Param均为Wrapper的子类实例(均具有AbstractWrapper的所有方法) 方法在入参中出现的R为泛型,在普通wrapper中是String,在LambdaWrapper中是函数(例:Entity::getId,Entity为实体类,getId为字段id的getMethod) 方法入参中的R column均表示数据库字段,当R具体类型为String时则为数据库字段名(字段名是数据库关键字的自己用转义符包裹!)!而不是实体类数据字段名!!!,另当R具体类型为SFunction时项目runtime不支持eclipse自家的编译器!!! 举例均为使用普通wrapper,入参为Map和List的均以json形式表现! 使用中如果入参的Map或者List为空,则不会加入最后生成的sql中!!! 有任何疑问就点开源码看,看不懂函数的lambda 表达式详解 QueryWrapper###说明:继承自 AbstractWrapper ,自身的内部属性 entity 也用于生成 where 条件及 LambdaQueryWrapper, 可以通过 new QueryWrapper().lambda() 方法获取 SELECT 123select(String... sqlSelect)select(Predicate&lt;TableFieldInfo&gt; predicate)select(Class&lt;T&gt; entityClass, Predicate&lt;TableFieldInfo&gt; predicate) 设置查询字段 说明: 以上方分法为两类.第二类方法为:过滤查询字段(主键除外),入参不包含 class 的调用前需要wrapper内的entity属性有值! 这两类方法重复调用以最后一次为准 例: select(&quot;id&quot;, &quot;name&quot;, &quot;age&quot;) 例: select(i -&gt; i.getProperty().startsWith(&quot;test&quot;)) 使用MP入门： ①定义一个JavaBean对象，用于封装数据库信息 ②定义一个（BeanName)Mapper接口，该接口继承BaseMapper 并传入相对应的Bean对象 ③可直接在查询地方定义一个查询构造器Wrapper实现类（QueryWrapper或LambdaQueryWrapper）用于复杂查询，将其传入实例化（容器中拿）的mapper的方法条件中，获取查询后的数据。]]></content>
      <tags>
        <tag>-mybatis-plus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virtualBox 进行Net后SSH注意事项]]></title>
    <url>%2F2019%2F10%2F05%2FvirtualBox-%E8%BF%9B%E8%A1%8CNet%E5%90%8ESSH%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[因为学习需要，为了更加便捷，抛弃了使用笨重的VMware，而选择了轻携的Oracle virtualBox，但是恶梦也是从这里开始了，倒腾了半天，也总算解决了这个问题！ 首先声明：这个问题针对校园网锐捷客户端而言，锐捷不允许多IP，在倒腾了一会后，发现如果选择桥接模式，再进行不同物理网卡与虚拟网卡进行Internet网络共享后，锐捷客户端总是抛断网搞破坏，因此只能选择，Net连接（在VMware中也是选择Net连接 的我，对Net方式较为熟悉） 恶性循环： 如果选择桥接模式，只能ping通主机，无法ping通其他IP与域名 如果选择 桥接，且进行物理网卡与虚拟网卡（需下载）进行Internet网络共享，则锐捷断网警告 如果选择Net连接，网络正常ping通，但主机ssh访问虚拟机受限。 本着熟悉入手，减少配置，选择了第三点，用Net进行网络配置 在virtualBox NAT 模式下，主机ssh访问虚拟机配置,总是显示失败 选择虚拟机-&gt;设置-&gt;网络-&gt;高级-&gt;端口转发： 协议：TCP 主机IP:127.0.0.1 主机端口：1234 子系统IP：（虚拟机IP） 子系统端口：22（SSH监听端口） 完成配置后，在主机上确认是否已启动1234端口监听： 登录成功：]]></content>
      <tags>
        <tag>-virtualBox -知识漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leecodede_139单词拆分]]></title>
    <url>%2F2019%2F10%2F04%2FLeecodede-139%E5%8D%95%E8%AF%8D%E6%8B%86%E5%88%86%2F</url>
    <content type="text"><![CDATA[给定一个非空字符串 s 和一个包含非空单词列表的字典 wordDict*，判定 *s 是否可以被空格拆分为一个或多个在字典中出现的单词。 说明： 拆分时可以重复使用字典中的单词。 你可以假设字典中没有重复的单词。 示例 1： 输入: s = “leetcode”, wordDict = [“leet”, “code”]输出: true*解释: 返回 true 因为 “leetcode” 可以被拆分成 “leet code” 示例 2： 输入: s = “applepenapple”, wordDict = [“apple”, “pen”]输出: true解释: 返回 true 因为 “applepenapple” 可以被拆分成 “apple pen apple”。 注意你可以重复使用字典中的单词。 示例 3： 输入: s = “catsandog”, wordDict = [“cats”, “dog”, “sand”, “and”, “cat”]输出: false-* 该题可以采用暴力法 、广度优先搜索、动态规划 实际上三者都有一个共同点，即：应该先找出前半部分是否含有，再进行递归或者递推 动态规划三要素：（初始）状态，状态转移方程，终止条件 其实动态规划套路就是记忆存储，自底递推，找到状态转移 但是这道题，可以想象其实可以把一个单词（而不是一个下标），当初一个状态，来进行状态的转移 eg: catdog—&gt;cat(true)+dog(exit) 12345678910111213141516171819class Solution &#123; public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123; Set&lt;String&gt; set=new HashSet(wordDict); boolean[] dp=new boolean[s.length()+1]; dp[0]=true; //注意界限：i&lt;=s.length() for(int i=0;i&lt;=s.length();i++)&#123; for(int j=0;j&lt;i;j++)&#123; //想象成：dp[leet]+contains(code) ? true if(dp[j] &amp;&amp; set.contains(s.substring(j,i)))&#123; dp[i]=true; break; &#125; &#125; &#125; return dp[s.length()]; &#125; &#125; Leecode官方： 这个方法的想法是对于给定的字符串（ss）可以被拆分成子问题 s1s1 和 s2s2 。如果这些子问题都可以独立地被拆分成符合要求的子问题，那么整个问题 ss 也可以满足。也就是，如果 “\text{catsanddog}catsanddog” 可以拆分成两个子字符串 “\text{catsand}catsand” 和 “\text{dog}dog” 。子问题 “\text{catsand}catsand” 可以进一步拆分成 “\text{cats}cats” 和 “\text{and}and” ，这两个独立的部分都是字典的一部分，所以 “\text{catsand}catsand” 满足题意条件，再往前， “\text{catsand}catsand” 和 “\text{dog}dog” 也分别满足条件，所以整个字符串 “\text{catsanddog}catsanddog” 也满足条件。 现在，我们考虑 \text{dp}dp 数组求解的过程。我们使用 n+1n+1 大小数组的 \text{dp}dp ，其中 nn 是给定字符串的长度。我们也使用 2 个下标指针 ii 和 jj ，其中 ii 是当前字符串从头开始的子字符串（s’s）的长度， jj 是当前子字符串（s’s ′）的拆分位置，拆分成 s’(0,j)s ′ (0,j) 和 s’(j+1,i)s ′ (j+1,i) 。 为了求出 \text{dp}dp 数组，我们初始化 \text{dp}[0]dp[0] 为 \text{true}true ，这是因为空字符串总是字典的一部分。 \text{dp}dp 数组剩余的元素都初始化为 \text{false}false 。 我们用下标 ii 来考虑所有从当前字符串开始的可能的子字符串。对于每一个子字符串，我们通过下标 jj 将它拆分成 s1’s1 ′ 和 s2’s2 ′ （注意 ii 现在指向 s2’s2 ′ 的结尾）。为了将 \text{dp}[i]dp[i] 数组求出来，我们依次检查每个 \text{dp}[j]dp[j] 是否为 \text{true}true ，也就是子字符串 s1’s1 ′ 是否满足题目要求。如果满足，我们接下来检查 s2’s2 ′ 是否在字典中。如果包含，我们接下来检查 s2’s2 ′是否在字典中，如果两个字符串都满足要求，我们让 \text{dp}[i]dp[i] 为 \text{true}true ，否则令其为 \text{false}false 。]]></content>
      <tags>
        <tag>-Leecode -算法思路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二篇博客]]></title>
    <url>%2F2019%2F10%2F04%2F%E7%AC%AC%E4%BA%8C%E7%AF%87%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[第一次写博客，希望能记录学习的点点滴滴 来年春招力争大厂offer上岸 第二篇博客]]></content>
      <tags>
        <tag>-hexo</tag>
      </tags>
  </entry>
</search>
