<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java基本注解]]></title>
    <url>%2F2019%2F10%2F28%2FJava%E5%9F%BA%E6%9C%AC%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Annotation的概念与作用元数据（MeteData）也就是Annotation，这是一种代码里的特殊标志，可在编译，类加载，运行时被读取。 Annotation就像修饰符一样，可用于修饰包，类，构造器，方法， 成员变量，参数，局部变量的声明，这些信息被存储到Annotation的“name=value”对中 Annotation是一个接口，程序通过反射来获取指定程序元素的Annotation对象，然后通过Annotation对象来获取注释里的元数据 基本Annotation 四种基本的Annotation如下： @Override @Deprecated @SuppressWarinings @SafeVarargs @Override注解的功能与用法@Override用来制定方法覆盖度，强制一个子类必须覆盖父类的方法；用于避免普通子类没覆盖父类抽象方法，方法名写错 @Deprecated注解的功能与用法@Deprecated用于表示某个程序元素（方法，类等）已过时，当使用过时类，方法时，会发出警告信息 @SuppressWarinings注解的功能与用法@SuppressWarinings指示被该Annotation修饰的程序元素（以及该程序元素的所有子元素）取消显示指定的编译器错误 @SafeVarargs注解的功能与用法@SafeVarargs用于解决“堆污染”警告 “堆污染”：当把一个不带泛型的对象赋值给一个带泛型的变量时，往往会产生堆污染 JDK的元Annotation上面四个基本注解是在java.lang包下的， 此外还在java.lang.annotation包下提供4个Meta Annotation，这四个Annotation都用于修饰其他的Annotation的定义 @Retention @Target @Document @Inherited @Retention注解的功能与用法@Retention只能用于修饰一个Annotation定义，指定被修饰的Annotation可以保留多长时间 @Retention包含一个RetentionPolicy类型的value成员变量，使用@Retention必须为改对象指定值 value值分别有： RetentionPolicy.CLASS:默认值，记录在class文件中 RetentionPolicy.RUNTIME:JVM保留该Annotation，程序可以通过反射获取该Annotation信息 RetentionPolicy.SOURCE:保留源代码中，编译器丢弃该Annotation @Target注解的功能与用法@Target用于修饰一个Annotation定义，用于指定被修饰的Annotation能用于修饰哪些程序单元 value值分别有： ElementType.ANNOTATION_TYPE:指定该策略的Annotation只能用于修饰Annotation ElementType.CONSTRUCTOR:只能修饰构造器 ElementType.FIFLD:只能修饰成员变量 ElementType.LOCAL_VARIABLE:只能修饰局部变量 ElementType.METHOD:修饰方法定义 ElementType.PACKAGE:修饰包的定义 ElementType.PARAETER:修饰参数 ElementType.TYPE:可以修饰类、接口（包括注解类型）或枚举定义 @Document注解的功能与用法@Document用于该Annotation将被javadoc工具提取成文档 @Inherited注解的功能与用法@Inherited元Annotation指定被它修饰的Annotation将具有继承性。 如果某个类用包含@Inherited的Annotation，则该子类将自动也使用该Annotation 自定义Annotation定义一个新的Annotation类型使用@interface关键字。 1234public @interface TESTAnnotation&#123; ...&#125; 可定义Annotation的成员变量，并且该变量可以指定初始值，用关键字default 12345public @interface MyTag&#123; String name() default "zhengkai"; int age() default 18; &#125; 该Annotation定义俩个成员变量，并且已经有初始值 **当开发者使用Annotation修饰类，方法，Filed等成员之后，这些Annotation并不会生效，必须有开发者提供相应的工具来提取并处理Annotation信息 运行时Annotationjava.lang.reflect包下提供了获取Annotation的AnnotationElenment接口，程序可调用如下三个方法获取Annotation信息 getAnnotation(Class annotationClass)：获得程序元素的注解，不存在返回null Annotations[]：获取程序元素上所有的注解 isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass):判断该程序元素是否存在注解]]></content>
      <tags>
        <tag>-注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive数据仓库基础知识]]></title>
    <url>%2F2019%2F10%2F22%2FHive%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[数据仓库Hive产生背景MapReduce编程门槛高，无法及时应对需求的变更 传统RDBMS（关系型数据库）人员的需求，HDFS上的文件并没有schema的概念 可通过Hive进行大数据的处理 Hive概述有Facebook开源，用于解决海量结构化日志的数据统计问题 构建在Hadoop之上的数据仓库（计算能力，存储能力，可应付数据的暴增） Hive提供的SQL查询语言：HQL 底层支撑多种不同的执行引擎 Hive底层执行引擎支持：MR/Tez/Spark（用户不感知） ###为什么要使用Hive 简单，容易上手 为超大数据集设计的计算/扩展能力 同一的元数据管理：Hive数据是存放在HDFS上，元数据信息（记录数据(HDFS数据)的数据）是存放在MySQL中 SQL on Hadoop:Hive,Spark,SQL,impala… Hive是一个离线框架，不适合实时查询 Hive体系架构Hive 在Hadoop生态中的位置 体系架构图： client：shell、thrift/jdbc(server/jdbc)、webUI(HUE/Zeppelin) metastore:==&gt;MySQL database:name/location/owner... table:name、location、owner、column、name/type...Hive：写SQL翻译成MapReduce，放入到Hadoop Hive部署架构 测试环境 客户端把SQL提交Hive引擎，元数据信息可存放在Derby中（只能进行单客户端的操作，就是单session）即使是测试环境也不推荐使用，因此只能选择MySQL 生产环境：为了防止MySQL错误导致无法进行获取元数据信息，因此得有主备MySQL，主备MySQL会进行切换。（解决MySQL单点问题） Hadoop集群：DN、NM、NN、RM Hive提交到RM上，Hadpoop集群有很多节点，Hive是一个客户端，并不涉及集群的概念 Hive与RDBMS的区别 支持的：都支持分布式 区别的：Hive不适合立马进行查询 Hive部署及快速入门包：hive-1.*.0cdh.5 *. *tar-gz *bin目录：脚本 *conf目录：配置 1 下载 2解压的 ~/app 3添加Hive-HOME到系统环境变量 4修改配置 5拷贝MySQL驱动包 6预先下载MySQL数据库 Hive DDL详解可以创建一张表，把数据加入到表中，对数据的各种维度的分析 create/delete/alter… Hive数据抽象/结构 database HDFS一个目录 table HDFS一个目录 data文件 partition分区表 HDFS一个目录 bucket分桶 HDFS一个文件 创建数据库1234CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name [COMMENT database_comment] [LOCATIO hdfs_path] [WITH DBPROPERTIES (property_name=property_value,...)]; 创建表12345678910111213CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name [(col_name data_type[COMMENT col_comment], ... [constraint_specification])] [COMMENT table_comment] [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] [ROW FORMAT row_format] [STORED AS file_format] [LOCATION hdfs_path] [TBLPROPERTIES (property_name=property_value, ...)] [AS select_statement];CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name LIKE existing_table_or_view_name [LOCATION hdfs_path]; 各项参数说明： 1CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常，一般也可以不加这个IF NOT EXISTS语句，最多抛出错误。 2 [constraint_specification]可选项： [ PRIMARY KEY|UNIQUE|NOT NULL|DEFAULT [default_value] 3 [COMMENT table_comment] 可选项：COMMENT 后面跟的字符串是给表字段或者表内容添加注释说明的 4 [PARTITIONED BY ] 可选项：PARTITIONED BY其实是给表做分区，决定了表是否是分区表。（Hive中所谓分区表就是将表里新增加一个字段，就是分区的名字，这样你在操作表中的数据时，可以按分区字段进行过滤） 5 [CLUSTERED BY ]可选项：CLUSTERED BY对于每一个表（table）或者分区， Hive可以进一步组织成桶，也就是说桶是更为细粒度的数据范围划分。Hive也针对某一列进行桶的组织。Hive采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中 6 [ROW FORMAT]可选项：存储表格式 7 [STORED AS] 可选项：hive存储的三种文件格式 8 [LOCATION AS] 可选项：LOCATION 其实是定义hive表的数据在hdfs上的存储路径，一般管理表（内部表不不要自定义），但是如果定义的是外部表，则需要直接指定一个路径。实际上不指定也没事，会使用默认路径 部分详解： 使用PARTITIONED BY子句创建分区表。一个表可以具有一个或多个分区列，并为分区列中的每个不同值组合创建一个单独的数据目录。此外，可以使用CLUSTERED BY列对表或分区进行存储，并且可以通过SORT BY列在该存储区中对数据进行排序。这样可以提高某些查询的性能。 eg: 12345678CREATE TABLE page_view(viewTime INT, userid BIGINT, page_url STRING, referrer_url STRING, ip STRING COMMENT &apos;IP Address of the User&apos;) COMMENT &apos;This is the page view table&apos; PARTITIONED BY(dt STRING, country STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\001&apos;STORED AS SEQUENCEFILE; 上面的语句创建带有viewTime，userid，page_url，referrer_url和ip列（包括注释）的page_view表。该表也被分区，数据存储在序列文件中,文件中的数据格式由ctrl-A分隔字段，由换行分隔行。 重命名表1ALTER TABLE table_name RENAME TO new_table_name; ####更改表属性 1`ALTER TABLE table_name SET TBLPROPERTIES table_properties;` `table_properties:`` ``: (property_name = property_value, property_name = property_value, ... )` table_properties : (property_name = property_value, property_name = property_value, … ) TBLPROPERTIES:允许您使用自己的元数据键/值对标记表定义;还存在一些预定义的表属性，由Hive自动添加和管理的last_modified_user和last_modified_time。 修改表注释：要更改表的注释，您必须更改的comment属性TBLPROPERTIES： 1`ALTER TABLE table_name SET TBLPROPERTIES (``&apos;comment&apos;` `= new_comment);` 重命名现有表的列1`ALTER TABLE old_table_name REPLACE COLUMNS (col1 TYPE, ...);` 将列添加到现有表1ALTER TABLE tab1 ADD COLUMNS (c1 INT COMMENT &apos;a new int column&apos;, c2 STRING DEFAULT &apos;def val&apos;); 删除表1`DROP TABLE pv_users;` 删除表分区(更改表以删除分区)：1`ALTER TABLE pv_users DROP PARTITION (ds=``&apos;2008-08-08&apos;``)` Hive查询操作记录在Select中，而插入操作记录在将数据从查询插入Hive表和从查询将数据写入文件系统中。 简单查询1`INSERT OVERWRITE TABLE user_active``SELECT user.*``FROM user``WHERE user.active = ``1``;` 请注意，与SQL不同，我们总是将结果插入表中。也可以将其转储到本地文件中。 也可以在Beeline 或Hive CLI中运行以下查询 ： 123SELECT user.*FROM userWHERE user.active = ``1``; 基于分区的查询1`INSERT OVERWRITE TABLE xyz_com_page_views``SELECT page_views.*``FROM page_views``WHERE page_views.date &gt;= ``&apos;2008-03-01&apos;` `AND page_views.date &lt;= ``&apos;2008-03-31&apos;` `AND`` ``page_views.referrer_url like ``&apos;%xyz.com&apos;``;` 系统根据分区列上的where子句条件自动确定要在查询中使用的分区。例如，为了获取域xyz.com引用的03/2008月份的所有page_views 请注意，此处使用page_views.date，因为该表（上面）是使用PARTITIONED BY（date DATETIME，country STRING）定义的；如果您给分区命名不同，请不要期望.date发挥您的想法！ 连接查询1234INSERT OVERWRITE TABLE pv_usersSELECT pv.*, u.gender, u.ageFROM user u JOIN page_view pv ON (pv.userid = u.id)WHERE pv.date = &apos;2008-03-03&apos;; 可以使用LEFT OUTER，RIGHT OUTER或FULL OUTER关键字限定联接，以指示外部联接的类型（保留的左侧，保留的右侧或两侧保留） 检查另一个表中是否存在键，用户可以使用LEFT SEMI JOIN]]></content>
      <tags>
        <tag>-Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[swagger2学习]]></title>
    <url>%2F2019%2F10%2F16%2Fswagger2%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[一、Swagger简介背景​ 在现在的开发流程中，为了最大程度实现前后端的分离，通常后端接口只提供数据接口，由前端通过Ajax请求从后端获取数据并进行渲染再展示给用户。我们用的最多的方式就是后端会返回给前端一个JSON字符串，前端解析JSON字符串生成JavaScript的对象，然后再做处理。 演化非Restful接口的支持 一个方法对应于一个端口方法映射，通常只有GET/POST方法对应CRUD，后期维护成本大，通常标签有： ​ @Controller 标识一个类为控制器。 @RequestMapping URL的映射。 @ResponseBody 返回结果转换为JSON字符串。 @RequestBody 表示接收JSON格式字符串参数。 Restful API设计 Restful API是一种编程风格，比起传统的通过get/post方法的接口设计，Restful API的设计则通过HTTP的方法来表示CRUD相关的操作。 123456接口URL | HTTP方法 | 接口说明-------| -------- |-------/article | POST | 保存文章/article/&#123;id&#125; | GET | 查询文章列表/article/&#123;id&#125; | DELETE | 删除文章/article/&#123;id&#125; | PUT | 修改文章 区别： ​ ①类上通常使用@RestController注解（spring4提供），表示返回Json数据的注解，支持Restful控制器。 ​ ②/article/{id}具有三个相同的URL映射，这在@Controller标识的类中是不允许出现的，而这通过method来进行区分，produces的作用是表示返回结果的类型是JSON。 ③@PathVariable这个注解（Spring MVC提供），作用是表示该变量的值是从访问路径中获取。 简介Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务。总体目标是使客户端和文件系统作为服务器以同样的速度来更新。文件的方法，参数和模型紧密集成到服务器端的代码，允许API来始终保持同步。Swagger 让部署管理和使用功能强大的API从未如此简单。 二、Swagger与Spring boot集成①、导入相应jar包12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt; ②、基本信息配置12345678910111213141516171819202122232425262728293031323334353637@Configuration@EnableSwagger2public class SwaggerConfig &#123; @Bean public Docket docket()&#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() //当前包路径 .apis(RequestHandlerSelectors.basePackage("com.bmsoft.dc.dodp")) .paths(PathSelectors.any()).build(); &#125; @Bean public Docket docket1()&#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .groupName("caozifu") .select() .apis(RequestHandlerSelectors.basePackage("com.bmsoft.dc.dodp")) .paths(PathSelectors.any()).build(); &#125; /** * 构建api文档的详细信息函数 * */ private ApiInfo apiInfo()&#123; return new ApiInfoBuilder() //页面标题 .title("离线开发平台Restful接口管理") //版本号 .version("1.0") //描述 .description("API 描述") .build(); &#125;&#125; 标签说明： @Configuration是表示这是一个配置类，是JDK自带的注解 @EnableSwagger2的作用是启用Swagger2相关功能。 ​ 配置类里面我么实例化了一个Docket对象，这个对象主要包括三个方面的信息： ​ （1）整个API的描述信息，即ApiInfo对象包括的信息，这 部分信息会在页面上展示。 （2）指定生成API文档的包名。 （3）指定生成API的路径。按路径生成API可支持四种模式：任何路径都生成(any)、任何路径都不生成 (none)以及正则匹配(regex)和ant 模式匹配四种方式 ③、编写方法及其参数描述​ 编写相应的方法，并应方法中做出相应的参数描述，具体标签有： @ApiOperation 用在方法上，说明方法的作用，每一个url资源的定义,使用方式： 属性名称 备注 value url的路径值 ​ *tags 接口的标签，相同标签的接口会在一个标签页下展示。 notes 接口详细说明，展示在接口的详情页。 httpMethod 支持的HTTP的方法。 @ApiImplicitParams，@ApiImplicitParam的容器，可包含多个@ApiImplicitParam注解 @ApiImplicitParam，请求参数属性配置： 属性名称 备注 name 参数名称 value 参数说明 required 是否必须 dataType 数据类型 @ApiResponse，返回结果属性配置： 属性名称 备注 code 返回结果的编码 message 返回结果的说明 response 返回结果对应的类 示例 12345678910111213@ApiOperation(value = &quot;更新文章&quot;, notes = &quot;更新文章内容&quot;, tags = &quot;Article&quot;,httpMethod = &quot;PUT&quot;) @ApiImplicitParams(&#123; @ApiImplicitParam(name = &quot;id&quot;, value = &quot;文章ID&quot;, required = true, dataType = &quot;Long&quot;), @ApiImplicitParam(name = &quot;title&quot;, value = &quot;文章标题&quot;, required = false, dataType = &quot;String&quot;), @ApiImplicitParam(name = &quot;summary&quot;, value = &quot;文章摘要&quot;, required = false, dataType = &quot;String&quot;), @ApiImplicitParam(name = &quot;status&quot;, value = &quot;发布状态&quot;, required = false, dataType = &quot;Integer&quot;) &#125;) @RequestMapping(value = &quot;/article/&#123;id&#125;&quot;, method = PUT, produces = &quot;application/json&quot;) public WebResponse&lt;?&gt; updateArticle(@PathVariable Long id,@RequestBody Article article)&#123; article.setId(id); articleService.updateArticle(article); return WebResponse.getSuccessResponse(new HashMap&lt;&gt;()); &#125; 启动Spring boot，然后访问：http://127.0.0.1:8080/swagger-ui.html即可看到如下结果 页面显示： 其他常用标签 @API注解:用在类上，说明该类的作用。可以标记一个Controller类做为swagger 文档资源 12&gt; @Api(value = "/user", description = "Operations about user")&gt; 属性名称 备注 value url的路径值 tags 如果设置这个值、value的值会被覆盖 description 对api资源的描述 description 对api资源的描述 @ApiModel：描述一个Model的信息（这种一般用在post创建的时候，使用@RequestBody这样的场景，请求参数无法使用 @ApiModelProperty：描述一个model的属性]]></content>
      <tags>
        <tag>-swagger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis-plus学习]]></title>
    <url>%2F2019%2F10%2F14%2Fmybatis-plus%E4%B8%AA%E4%BA%BA%E8%A7%81%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[MyBatis-Plus（简称 MP）是一个 MyBatis 的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。mybatis-plus的特性​ ①无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑​ ②损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作​ ③强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求​ ④支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错​ ⑤支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题​ ⑥支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作​ ⑦支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ）​ ⑧内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用​ ⑨内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询​ ⑩分页插件支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer2005、SQLServer 等多种数据库 主要核心知识：Mapper CRUD接口说明: 通用 CRUD 封装BaseMapper接口，为 Mybatis-Plus 启动时自动解析实体表关系映射转换为 Mybatis 内部对象注入容器 泛型 T 为任意实体对象 参数 Serializable 为任意类型主键 Mybatis-Plus 不推荐使用复合主键约定每一张表都有自己的唯一 id 主键 对象 Wrapper 为 条件构造器 实际上是在Mybatis的mapper扫描文件进行了CURD增强， CRUD方法基本是insert、delete（ById,ByMap、BatchIds)、 update（ById)、select（ById、BathchIds、ByMap、One、Count、List、Maps、Objs、Page、MapsPage) 基本是通过Id,条件进行CRUD Service CRUD接口说明: 通用 Service CRUD 封装IService接口，进一步封装 CRUD 采用 get 查询单行 remove 删除 list 查询集合 page 分页 前缀命名方式区分 Mapper 层避免混淆， 泛型 T 为任意实体对象 建议如果存在自定义通用 Service 方法的可能，请创建自己的 IBaseService 继承 Mybatis-Plus 提供的基类 对象 Wrapper 为 条件构造器 条件构造器说明: 介绍 上图绿色框为抽象类abstract 蓝色框为正常class类，可new对象 黄色箭头指向为父子类关系，箭头指向为父类 方法入参boolean condition表示该条件是否加入最后生成的sql中 方法均为从上往下补全个别boolean类型的入参,默认为true 出现的泛型Param均为Wrapper的子类实例(均具有AbstractWrapper的所有方法) 方法在入参中出现的R为泛型,在普通wrapper中是String,在LambdaWrapper中是函数(例:Entity::getId,Entity为实体类,getId为字段id的getMethod) 方法入参中的R column均表示数据库字段,当R具体类型为String时则为数据库字段名(字段名是数据库关键字的自己用转义符包裹!)!而不是实体类数据字段名!!!,另当R具体类型为SFunction时项目runtime不支持eclipse自家的编译器!!! 举例均为使用普通wrapper,入参为Map和List的均以json形式表现! 使用中如果入参的Map或者List为空,则不会加入最后生成的sql中!!! 有任何疑问就点开源码看,看不懂函数的lambda 表达式详解 QueryWrapper###说明:继承自 AbstractWrapper ,自身的内部属性 entity 也用于生成 where 条件及 LambdaQueryWrapper, 可以通过 new QueryWrapper().lambda() 方法获取 SELECT 123select(String... sqlSelect)select(Predicate&lt;TableFieldInfo&gt; predicate)select(Class&lt;T&gt; entityClass, Predicate&lt;TableFieldInfo&gt; predicate) 设置查询字段 说明: 以上方分法为两类.第二类方法为:过滤查询字段(主键除外),入参不包含 class 的调用前需要wrapper内的entity属性有值! 这两类方法重复调用以最后一次为准 例: select(&quot;id&quot;, &quot;name&quot;, &quot;age&quot;) 例: select(i -&gt; i.getProperty().startsWith(&quot;test&quot;)) 使用MP入门： ①定义一个JavaBean对象，用于封装数据库信息 ②定义一个（BeanName)Mapper接口，该接口继承BaseMapper 并传入相对应的Bean对象 ③可直接在查询地方定义一个查询构造器Wrapper实现类（QueryWrapper或LambdaQueryWrapper）用于复杂查询，将其传入实例化（容器中拿）的mapper的方法条件中，获取查询后的数据。]]></content>
      <tags>
        <tag>-mybatis-plus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virtualBox 进行Net后SSH注意事项]]></title>
    <url>%2F2019%2F10%2F05%2FvirtualBox-%E8%BF%9B%E8%A1%8CNet%E5%90%8ESSH%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[因为学习需要，为了更加便捷，抛弃了使用笨重的VMware，而选择了轻携的Oracle virtualBox，但是恶梦也是从这里开始了，倒腾了半天，也总算解决了这个问题！ 首先声明：这个问题针对校园网锐捷客户端而言，锐捷不允许多IP，在倒腾了一会后，发现如果选择桥接模式，再进行不同物理网卡与虚拟网卡进行Internet网络共享后，锐捷客户端总是抛断网搞破坏，因此只能选择，Net连接（在VMware中也是选择Net连接 的我，对Net方式较为熟悉） 恶性循环： 如果选择桥接模式，只能ping通主机，无法ping通其他IP与域名 如果选择 桥接，且进行物理网卡与虚拟网卡（需下载）进行Internet网络共享，则锐捷断网警告 如果选择Net连接，网络正常ping通，但主机ssh访问虚拟机受限。 本着熟悉入手，减少配置，选择了第三点，用Net进行网络配置 在virtualBox NAT 模式下，主机ssh访问虚拟机配置,总是显示失败 选择虚拟机-&gt;设置-&gt;网络-&gt;高级-&gt;端口转发： 协议：TCP 主机IP:127.0.0.1 主机端口：1234 子系统IP：（虚拟机IP） 子系统端口：22（SSH监听端口） 完成配置后，在主机上确认是否已启动1234端口监听： 登录成功：]]></content>
      <tags>
        <tag>-virtualBox -知识漏洞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leecodede_139单词拆分]]></title>
    <url>%2F2019%2F10%2F04%2FLeecodede-139%E5%8D%95%E8%AF%8D%E6%8B%86%E5%88%86%2F</url>
    <content type="text"><![CDATA[给定一个非空字符串 s 和一个包含非空单词列表的字典 wordDict*，判定 *s 是否可以被空格拆分为一个或多个在字典中出现的单词。 说明： 拆分时可以重复使用字典中的单词。 你可以假设字典中没有重复的单词。 示例 1： 输入: s = “leetcode”, wordDict = [“leet”, “code”]输出: true*解释: 返回 true 因为 “leetcode” 可以被拆分成 “leet code” 示例 2： 输入: s = “applepenapple”, wordDict = [“apple”, “pen”]输出: true解释: 返回 true 因为 “applepenapple” 可以被拆分成 “apple pen apple”。 注意你可以重复使用字典中的单词。 示例 3： 输入: s = “catsandog”, wordDict = [“cats”, “dog”, “sand”, “and”, “cat”]输出: false-* 该题可以采用暴力法 、广度优先搜索、动态规划 实际上三者都有一个共同点，即：应该先找出前半部分是否含有，再进行递归或者递推 动态规划三要素：（初始）状态，状态转移方程，终止条件 其实动态规划套路就是记忆存储，自底递推，找到状态转移 但是这道题，可以想象其实可以把一个单词（而不是一个下标），当初一个状态，来进行状态的转移 eg: catdog—&gt;cat(true)+dog(exit) 12345678910111213141516171819class Solution &#123; public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123; Set&lt;String&gt; set=new HashSet(wordDict); boolean[] dp=new boolean[s.length()+1]; dp[0]=true; //注意界限：i&lt;=s.length() for(int i=0;i&lt;=s.length();i++)&#123; for(int j=0;j&lt;i;j++)&#123; //想象成：dp[leet]+contains(code) ? true if(dp[j] &amp;&amp; set.contains(s.substring(j,i)))&#123; dp[i]=true; break; &#125; &#125; &#125; return dp[s.length()]; &#125; &#125; Leecode官方： 这个方法的想法是对于给定的字符串（ss）可以被拆分成子问题 s1s1 和 s2s2 。如果这些子问题都可以独立地被拆分成符合要求的子问题，那么整个问题 ss 也可以满足。也就是，如果 “\text{catsanddog}catsanddog” 可以拆分成两个子字符串 “\text{catsand}catsand” 和 “\text{dog}dog” 。子问题 “\text{catsand}catsand” 可以进一步拆分成 “\text{cats}cats” 和 “\text{and}and” ，这两个独立的部分都是字典的一部分，所以 “\text{catsand}catsand” 满足题意条件，再往前， “\text{catsand}catsand” 和 “\text{dog}dog” 也分别满足条件，所以整个字符串 “\text{catsanddog}catsanddog” 也满足条件。 现在，我们考虑 \text{dp}dp 数组求解的过程。我们使用 n+1n+1 大小数组的 \text{dp}dp ，其中 nn 是给定字符串的长度。我们也使用 2 个下标指针 ii 和 jj ，其中 ii 是当前字符串从头开始的子字符串（s’s）的长度， jj 是当前子字符串（s’s ′）的拆分位置，拆分成 s’(0,j)s ′ (0,j) 和 s’(j+1,i)s ′ (j+1,i) 。 为了求出 \text{dp}dp 数组，我们初始化 \text{dp}[0]dp[0] 为 \text{true}true ，这是因为空字符串总是字典的一部分。 \text{dp}dp 数组剩余的元素都初始化为 \text{false}false 。 我们用下标 ii 来考虑所有从当前字符串开始的可能的子字符串。对于每一个子字符串，我们通过下标 jj 将它拆分成 s1’s1 ′ 和 s2’s2 ′ （注意 ii 现在指向 s2’s2 ′ 的结尾）。为了将 \text{dp}[i]dp[i] 数组求出来，我们依次检查每个 \text{dp}[j]dp[j] 是否为 \text{true}true ，也就是子字符串 s1’s1 ′ 是否满足题目要求。如果满足，我们接下来检查 s2’s2 ′ 是否在字典中。如果包含，我们接下来检查 s2’s2 ′是否在字典中，如果两个字符串都满足要求，我们让 \text{dp}[i]dp[i] 为 \text{true}true ，否则令其为 \text{false}false 。]]></content>
      <tags>
        <tag>-Leecode -算法思路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二篇博客]]></title>
    <url>%2F2019%2F10%2F04%2F%E7%AC%AC%E4%BA%8C%E7%AF%87%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[第一次写博客，希望能记录学习的点点滴滴 来年春招力争大厂offer上岸 第二篇博客]]></content>
      <tags>
        <tag>-hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F10%2F04%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
